---
title: "Reconhecendo padr√µes usando a base de dados Space Titanic"
format: html
execute:
  cache: true
---

Imagine que voc√™ √© um cientista de dados respons√°vel por entender os perfis dos passageiros da nave Space Titanic, que viajava em dire√ß√£o a uma col√¥nia espacial. Infelizmente, parte da tripula√ß√£o desapareceu misteriosamente e agora queremos entender se havia padr√µes ocultos entre os passageiros que possam explicar esse desfecho.

A base de dados Space Titanic, inspirada no cl√°ssico Titanic e dispon√≠vel no [`Kaggle`](https://www.kaggle.com), ser√° utilizada para trabalharmos t√©cnicas de clusteriza√ß√£o n√£o supervisionada, que nos permitem:

- üîç Descobrir grupos de passageiros com perfis semelhantes;

- üß† Analisar comportamentos e caracter√≠sticas emergentes em cada grupo;

- üìä Auxiliar em decis√µes estrat√©gicas para personaliza√ß√£o de servi√ßos, seguran√ßa de bordo e planejamento de miss√µes futuras.


## Pacotes utilizados 

```{r, message=FALSE, warning=FALSE}
load <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg))
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
} 

## Pacotes utilizados nessa an√°lise

packages = c("tidyverse",'tidymodels', 'tidyclust', 'dbscan', 'meanShiftR', 'kohonen', 'doParallel', 'tictoc', 'tidyr', 'purrr', 'cluster', 'umap', 'funModeling', 'clue', 'janitor', 'mclust', 'tictoc', 'future', 'doFuture', 'progressr', 'FactoMineR', 'factoextra', 'vegan', 'clusterCrit')
load(packages)
```


## Leitura dos dados
 
```{r}
dados = rio::import("https://raw.githubusercontent.com/tiagomartin/est125/refs/heads/main/dados/space_titanic.csv")
dados %>% 
  glimpse()
```

```{r}
dados %>% df_status()
```


```{r}
set.seed(12345)  # Escolha um n√∫mero fixo qualquer
```


De an√°lises anteriores, propomos as seguintes novas vari√°veis

```{r message=FALSE, warning=FALSE}
# Engenharia de vari√°veis
dados = dados %>%
  separate(Cabin, c("CabinDeck", "CabinNum", "CabinSide"), sep = "/", remove = TRUE) %>% 
  separate(PassengerId, c("PassGroup", "nGroup"), sep = "_", remove = TRUE) %>% 
  mutate(CabinDeck = as.factor(CabinDeck),
         CabinSide = as.factor(CabinSide), 
         PassGroup = as.numeric(PassGroup))
```


## Receita de pr√©-processamento

```{r}
receita = recipe(~ ., data = dados) %>%
  step_rm(Name, Transported) %>%
  step_mutate(across(where(is.character), as.factor)) %>%
  step_mutate(
    GroupSize = as.integer(purrr::map_dbl(PassGroup, ~ sum(PassGroup == .x))),
    IsAlone = ifelse(GroupSize==1, 1, 0) %>% as.factor(),
    CabinNum = as.numeric(CabinNum),
    nGroup = as.numeric(nGroup),
    VIP = as.factor(VIP),
    CryoSleep = ifelse((RoomService > 0 | FoodCourt > 0 | ShoppingMall > 0 | Spa > 0 | VRDeck > 0), tidyr::replace_na(CryoSleep, FALSE),TRUE),
    CryoSleep = as.factor(CryoSleep)) %>% 
  step_impute_knn(CryoSleep, neighbors = 2, impute_with = imp_vars(PassGroup, CabinDeck, CabinNum, CabinSide)) %>% 
  step_mutate(
    RoomService = ifelse(CryoSleep==TRUE, tidyr::replace_na(RoomService, 0),RoomService),
    FoodCourt = ifelse(CryoSleep==TRUE, tidyr::replace_na(FoodCourt, 0),FoodCourt),
    ShoppingMall = ifelse(CryoSleep==TRUE, tidyr::replace_na(ShoppingMall, 0), ShoppingMall),
    Spa = ifelse(CryoSleep==TRUE, tidyr::replace_na(Spa, 0), Spa),
    VRDeck = ifelse(CryoSleep==TRUE, tidyr::replace_na(VRDeck, 0), VRDeck)
  ) %>% 
  step_impute_knn(RoomService, FoodCourt, ShoppingMall, Spa, VRDeck, neighbors = 2, 
                  impute_with = imp_vars(PassGroup, CabinDeck, CabinNum, CabinSide)) %>%
  step_impute_bag(Age, VIP, CryoSleep, Destination, HomePlanet, CabinDeck, CabinNum, 
                  CabinSide) %>%
  step_mutate(across(RoomService:VRDeck, ~ log10(. + 1))) %>% 
  step_mutate(despesasSuperfluas = RoomService + Spa + VRDeck,
              despesasBasicas = FoodCourt + ShoppingMall,
              Isearth = ifelse(HomePlanet=='Earth', 1, 0) %>% as.factor(),
              Iskid = ifelse(Age < 14, 1, 0) %>% as.factor()) %>% 
  step_rm(PassGroup) %>%
  step_corr(all_numeric_predictors(), threshold = 0.95) %>%  # Remove colineares
  step_dummy(all_nominal_predictors()) %>%
  step_normalize(all_numeric_predictors()) %>% 
  step_nzv(all_predictors())
```



## Pr√©-processamento fora do tuning

```{r}
prep_dados <- prep(receita)
dados_prep <- bake(prep_dados, new_data = NULL)
```


```{r}
dados_prep %>% 
  glimpse()
```

## Verificando a Estrutura de Agrupamento com PCA

Antes de aplicar algoritmos de clusteriza√ß√£o, √© essencial compreender a estrutura de correla√ß√£o intr√≠nseca dos dados, ou seja, se os dados realmente apresentam ind√≠cios de agrupamentos naturais. Uma das formas mais eficazes e intuitivas de verificar isso √© por meio de uma an√°lise explorat√≥ria baseada em An√°lise de Componentes Principais (PCA).

A PCA reduz a dimensionalidade dos dados ao projet√°-los em um novo sistema de eixos ortogonais (as componentes principais) que maximizam a vari√¢ncia explicada. Ao analisar os dados projetados nas duas primeiras componentes principais, √© poss√≠vel visualizar poss√≠veis agrupamentos naturais, outliers e sobreposi√ß√µes.

Essa visualiza√ß√£o tamb√©m permite:

- Avaliar a separabilidade dos grupos esperados;

- Identificar vari√°veis que mais contribuem para a estrutura dos dados;

- Decidir se faz sentido aplicar t√©cnicas de clusteriza√ß√£o.

```{r}
pca_result <- prcomp(dados_prep, center = TRUE, scale. = TRUE)
fviz_pca_ind(pca_result, col.ind = "grey70") 
```


## Defini√ß√£o dos modelos K-means e Hier√°rquico

Antes de ajustarmos os modelos de clusteriza√ß√£o, √© necess√°rio definir suas configura√ß√µes por meio dos *model specifications* no framework `tidymodels`, utilizando o pacote `tidyclust`. Essa etapa permite estabelecer os principais par√¢metros do modelo, como o n√∫mero de grupos a ser ajustado (`tune()`), o mecanismo de execu√ß√£o (`engine`) e o modo de opera√ß√£o (`partition` para m√©todos de agrupamento).

Atualmente, o pacote `tidyclust` oferece suporte apenas a dois algoritmos de clusteriza√ß√£o: **K-means** e **Clusteriza√ß√£o Hier√°rquica Aglomerativa**. A seguir, criamos as especifica√ß√µes para esses dois m√©todos:

- `kmeans_spec`: define o modelo K-means, que busca particionar os dados em grupos minimizando a variabilidade interna de cada cluster.

- `hclust_spec`: define o modelo hier√°rquico, com liga√ß√£o do tipo `ward.D`, que constr√≥i agrupamentos de forma incremental buscando minimizar o aumento da vari√¢ncia total entre grupos.


```{r}
kmeans_spec <- k_means(num_clusters = tune()) %>%
  set_engine("stats") %>%
  set_mode("partition")

hclust_spec <- hier_clust(num_clusters = tune(), linkage_method = "ward.D2") %>%
  set_engine("stats") %>%
  set_mode("partition")
```


Ambas as especifica√ß√µes usam o motor `stats`, que corresponde √†s implementa√ß√µes nativas do R. Essas defini√ß√µes servir√£o como base para a constru√ß√£o dos *workflows* de clusteriza√ß√£o, permitindo a valida√ß√£o cruzada e o ajuste autom√°tico do n√∫mero ideal de grupos com base nos dados analisados.

## Tuning com valida√ß√£o cruzada

Com as especifica√ß√µes dos modelos definidas, o pr√≥ximo passo consiste na constru√ß√£o dos *workflows* e na execu√ß√£o do processo de ajuste dos hiperpar√¢metros, neste caso, o n√∫mero de clusters.

Primeiramente, utilizamos a fun√ß√£o `vfold_cv()` para gerar um esquema de valida√ß√£o cruzada com 5 parti√ß√µes, garantindo uma avalia√ß√£o robusta da performance dos modelos em diferentes subconjuntos dos dados (`dados_prep`).

```{r}
folds_prep <- vfold_cv(dados_prep, v = 5)
```

Em seguida, criamos dois *workflows*, um para o modelo K-means e outro para o modelo Hier√°rquico. Ambos s√£o configurados para usar todos os preditores dispon√≠veis na base de dados `(~ .)` e incorporam suas respectivas especifica√ß√µes (`kmeans_spec` e `hclust_spec`).


```{r}
wf_kmeans <- workflow() %>% add_model(kmeans_spec) %>% add_formula(~ .)
wf_hclust <- workflow() %>% add_model(hclust_spec) %>% add_formula(~ .)
```

O grid de valores para o hiperpar√¢metro `num_clusters` √© definido entre 2 e 10, permitindo que o processo de tuning explore diferentes poss√≠veis quantidades de agrupamentos.

```{r}
grid <- tibble(num_clusters = 2:6)
```

Por fim, aplicamos a fun√ß√£o `tune_cluster()` para cada modelo, realizando o ajuste do n√∫mero de clusters com base na m√©trica de avalia√ß√£o silhueta m√©dia (`silhouette_avg`), uma medida amplamente utilizada para quantificar a qualidade dos agrupamentos formados. Essa m√©trica avalia o qu√£o bem cada ponto est√° agrupado com seus vizinhos em compara√ß√£o com outros clusters.

Esse processo nos permitir√° comparar o desempenho dos modelos e selecionar o n√∫mero ideal de grupos de forma sistem√°tica e fundamentada.

```{r}
# 1. Plano com paralelismo
plan(multisession, workers = parallel::detectCores() - 1)
registerDoFuture()

handlers("txtprogressbar")  # ou "progress"

tic()
with_progress({
res_kmeans <- tune_cluster(
  wf_kmeans,
  resamples = folds_prep,
  grid = grid,
  metrics = cluster_metric_set(silhouette_avg)
)
})

with_progress({
res_hclust <- tune_cluster(
  wf_hclust,
  resamples = folds_prep,
  grid = grid,
  metrics = cluster_metric_set(silhouette_avg)
)
})
toc()
```

## Resultados e melhor modelo

Ap√≥s a execu√ß√£o do processo de tuning com valida√ß√£o cruzada, o pr√≥ximo passo √© identificar o n√∫mero ideal de clusters para cada modelo com base na m√©trica de avalia√ß√£o escolhida, neste caso, a silhueta m√©dia (`silhouette_avg`). Essa m√©trica indica qu√£o bem as observa√ß√µes est√£o agrupadas: valores pr√≥ximos de 1 sugerem melhor separa√ß√£o entre os grupos.


```{r}
melhor_kmeans <- select_best(res_kmeans, metric = "silhouette_avg")
melhor_hclust <- select_best(res_hclust, metric = "silhouette_avg")
```


Utilizamos a fun√ß√£o `select_best()` para extrair, de forma autom√°tica, o valor de `num_clusters` que resultou na melhor performance para cada modelo. Em seguida, atualizamos as especifica√ß√µes dos modelos K-means e Hier√°rquico com o n√∫mero de clusters √≥timo encontrado.


```{r}
kmeans_final <- k_means(num_clusters = melhor_kmeans$num_clusters) %>%
  set_engine("stats") %>%
  set_mode("partition")

hclust_final <- hier_clust(num_clusters = melhor_hclust$num_clusters, linkage_method = "ward.D") %>%
  set_engine("stats") %>%
  set_mode("partition")
```

Com os modelos atualizados, recriamos os *workflows* finais utilizando a fun√ß√£o `update_model()`, garantindo que cada *workflow* reflita o melhor n√∫mero de grupos encontrado durante o tuning.


```{r}
workflow_final_kmeans <- wf_kmeans %>%
  update_model(kmeans_final)

workflow_final_hclust <- wf_hclust %>%
  update_model(hclust_final)
```


Por fim, ajustamos os modelos finais aos dados completos (`dados_prep`) utilizando a fun√ß√£o `fit()`. As predi√ß√µes geradas (`predict()`) nos fornecem os r√≥tulos de cluster para cada observa√ß√£o, permitindo identificar a qual grupo cada indiv√≠duo foi atribu√≠do. Esses r√≥tulos s√£o armazenados nas vari√°veis `grupos_kmeans` e `grupos_hierarquico`, que ser√£o posteriormente utilizados para interpreta√ß√£o e visualiza√ß√£o dos padr√µes encontrados.

```{r}
modelo_final_kmeans <- fit(workflow_final_kmeans, data = dados_prep)
grupos_kmeans <- as.factor(predict(modelo_final_kmeans, new_data = dados_prep)$.pred_cluster)

modelo_final_hclust <- fit(workflow_final_hclust, data = dados_prep)
grupos_hierarquico <- as.factor(predict(modelo_final_hclust, new_data = dados_prep)$.pred_cluster)
```


Esse processo assegura que os modelos finais utilizados para an√°lise estejam otimizados em rela√ß√£o √† estrutura dos dados e fundamentados em uma m√©trica de qualidade apropriada para tarefas de clusteriza√ß√£o.

## Visualiza√ß√£o de Grupos Gerados via PCA

Em tarefas de clusteriza√ß√£o, √© comum gerar agrupamentos com base em medidas de similaridade ou dist√¢ncia entre observa√ß√µes. No entanto, como os dados frequentemente t√™m muitas vari√°veis (ou dimens√µes), torna-se desafiador visualizar e interpretar os agrupamentos diretamente no espa√ßo original.

Para lidar com esse problema, uma t√©cnica amplamente utilizada √© a An√°lise de Componentes Principais (`PCA`). A `PCA` transforma os dados originais em um novo sistema de coordenadas formado por componentes principais, isto √©, combina√ß√µes lineares das vari√°veis originais que maximizam a vari√¢ncia explicada. As duas primeiras componentes geralmente capturam a maior parte da estrutura dos dados, possibilitando uma visualiza√ß√£o bidimensional informativa.


```{r}
fviz_pca_ind(
  pca_result,
  geom.ind = "point",
  col.ind = grupos_kmeans,
  palette = "Set2",
  addEllipses = TRUE,
  legend.title = "Grupo",
  title = "Visualiza√ß√£o dos Grupos Formados no Espa√ßo das Componentes Principais"
)

fviz_pca_ind(
  pca_result,
  geom.ind = "point",
  col.ind = grupos_hierarquico,
  palette = "Set2",
  addEllipses = TRUE,
  legend.title = "Grupo",
  title = "Visualiza√ß√£o dos Grupos Formados no Espa√ßo das Componentes Principais"
)
```

Ao projetar os dados nesse plano PCA e colorir os pontos de acordo com os grupos gerados por um algoritmo de clusteriza√ß√£o, conseguimos:

- Visualizar a separa√ß√£o (ou sobreposi√ß√£o) entre os grupos;

- Avaliar a qualidade da segmenta√ß√£o de forma intuitiva;

- Identificar outliers ou observa√ß√µes amb√≠guas;

- Validar visualmente se h√° coer√™ncia entre os agrupamentos e a estrutura intr√≠nseca dos dados.

Al√©m disso, o uso de elipses de confian√ßa pode refor√ßar a no√ß√£o de centralidade e dispers√£o de cada grupo, tornando a visualiza√ß√£o ainda mais interpret√°vel.



## Tuning manual de DBSCAN, MeanShift e SOM


Diferentemente dos m√©todos K-means e Hierarchical Clustering, que podem ser facilmente integrados ao framework `tidyclust` e ajustados automaticamente via valida√ß√£o cruzada com `tune_cluster()`, os algoritmos DBSCAN, MeanShift e Redes SOM exigem uma abordagem manual de tuning dos hiperpar√¢metros. Isso se deve a caracter√≠sticas espec√≠ficas desses modelos e √†s limita√ß√µes atuais das interfaces automatizadas.



### Tuning de DBSCAN

Como o algoritmo DBSCAN n√£o possui uma etapa autom√°tica de ajuste de hiperpar√¢metros integrada ao `tidyclust`, √© necess√°rio realizar o tuning manual dos dois par√¢metros fundamentais do modelo:

- `eps`: raio de vizinhan√ßa que define a densidade m√≠nima em torno de um ponto;

- `minPts`: n√∫mero m√≠nimo de pontos necess√°rio para formar uma regi√£o densa (n√∫cleo do cluster).

Para facilitar esse processo, definimos a fun√ß√£o `avaliar_dbscan()`, que recebe diferentes combina√ß√µes de `eps` e `minPts` e avalia o desempenho do modelo com base na m√©dia do √≠ndice de silhueta, uma m√©trica que quantifica o qu√£o bem cada observa√ß√£o est√° agrupada.


```{r}
avaliar_dbscan <- function(eps, minPts, dados) {
  modelo <- dbscan::dbscan(dados, eps = eps, minPts = minPts)

  # Remove ru√≠do (cluster 0)
  grupos <- modelo$cluster
  grupos_validos <- grupos[grupos != 0]
  n_clusters <- length(unique(grupos_validos))

  # Calcular a silhueta apenas se houver pelo menos dois grupos distintos (al√©m de ru√≠do)
  if (n_clusters > 1) {
    sil <- silhouette(grupos, dist(dados))
    media_sil <- mean(sil[, 3], na.rm = TRUE)
  } else {
    media_sil <- NA_real_
  }

  tibble(
    eps = eps,
    minPts = minPts,
    n_clusters = n_clusters,
    silhueta = media_sil
  )
}
```


Essa abordagem permite montar uma `grid` de busca com diferentes valores de `eps` e `minPts`, testando v√°rias combina√ß√µes para selecionar aquela que maximiza a separa√ß√£o entre os clusters e minimiza a presen√ßa de ru√≠do.


```{r}
# Grid de hiperpar√¢metros
eps_grid <- seq(3.0, 4.0, by = 0.1)
minPts_grid <- seq(10, 30, by = 2)   # M√≠nimo de pontos mais restritivo
```

Seguindo, construimos um grid de par√¢metros por meio da fun√ß√£o `expand.grid()`, combinando todos os valores poss√≠veis de `eps` e `minPts` definidos previamente nas vari√°veis `eps_grid` e `minPts_grid`. Utilizamos a fun√ß√£o `pmap_dfr()` (do pacote `purrr`) para aplicar a fun√ß√£o `avaliar_dbscan()` a cada combina√ß√£o da grid. O argumento `.progress =` permite o acompanhamento da execu√ß√£o, √∫til especialmente em grades extensas.


```{r}
tic()
dbscan_results <- expand.grid(eps = eps_grid, minPts = minPts_grid) %>%
  mutate(silhouette = pmap_dfr(list(eps, minPts), avaliar_dbscan, dados = dados_prep, .progress = FALSE)) %>%
  drop_na() %>%
  arrange(desc(silhouette$silhueta))
toc()
```

Os resultados s√£o ordenados em ordem decrescente de acordo com a silhueta m√©dia, permitindo identificar rapidamente os conjuntos de par√¢metros que produziram os melhores agrupamentos em termos de coes√£o e separa√ß√£o dos grupos.

```{r}
melhor_dbscan <- dbscan_results %>%
  filter(!is.na(silhouette$silhueta), silhouette$n_clusters == 3) %>%
  arrange(desc(silhouette$silhueta)) %>%
  slice(1) %>%
  pull(silhouette)
```

Com os valores ideais de `eps` e `minPts` em m√£os, ajustamos o modelo DBSCAN final sobre os dados completos (`dados_prep`). Os r√≥tulos de cluster atribu√≠dos pelo modelo s√£o armazenados em `grupos_dbscan`, e podem assumir os valores 1, 2, 3 para os grupos v√°lidos e 0 para os pontos classificados como ru√≠do.

```{r}
modelo_dbscan <- dbscan(dados_prep, eps = melhor_dbscan$eps, minPts = melhor_dbscan$minPts)
grupos_dbscan <- as.factor(modelo_dbscan$cluster)
```


Para facilitar a interpreta√ß√£o visual dos agrupamentos encontrados, utilizamos novamente a proje√ß√£o PCA.

```{r}
fviz_pca_ind(
  pca_result,
  geom.ind = "point",
  col.ind = grupos_dbscan,
  palette = "Set2",
  addEllipses = TRUE,
  legend.title = "Grupo",
  title = "Visualiza√ß√£o dos Grupos Formados no Espa√ßo das Componentes Principais"
)
```



### Tuning de MeanShift

O algoritmo **MeanShift** √© um m√©todo de clusteriza√ß√£o baseado em densidade que n√£o exige a defini√ß√£o pr√©via do n√∫mero de clusters. No entanto, seu desempenho √© altamente sens√≠vel √† escolha do par√¢metro `bandwidth`, que determina o raio de influ√™ncia ao redor de cada ponto para estimar os modos da distribui√ß√£o dos dados.

Como o `tidyclust` ainda n√£o oferece suporte nativo ao MeanShift, a defini√ß√£o do melhor modelo deve ser feita manual e empiricamente, avaliando diferentes valores de `bandwidth`.

Para isso, implementamos duas fun√ß√µes: A fun√ß√£o `avaliar_meanshift()`, que aplica o algoritmo `meanShiftR::meanShift()` a uma matriz de dados com um vetor de `bandwidth` (um valor para cada vari√°vel)

```{r}
avaliar_meanshift <- function(bandwidth, dados) {
  # Aplica o MeanShift com o vetor de bandwidth
  modelo <- meanShiftR::meanShift(dados, bandwidth = bandwidth)

  # Grupos
  grupos <- modelo$assignment + 1

  # Verifica se h√° mais de um grupo
  if (length(unique(grupos)) < 2) {
    return(tibble(
      bandwidth = list(bandwidth),
      silhueta = NA_real_,
      n_clusters = 1
    ))
  }

  # Calcula silhueta
  sil <- silhouette(grupos, dist(dados))
  sil_media <- mean(sil[, 3])

  # Retorna tibble
  tibble(
    bandwidth = list(bandwidth),
    silhueta = sil_media,
    n_clusters = length(unique(grupos))
  )
}
```

E a fun√ß√£o `tuning_meanshift()`, que gera uma grid de vetores de `bandwidth` multiplicando o desvio padr√£o de cada vari√°vel por uma sequ√™ncia de fatores escalares (de 1.5 a 5.0). Para cada vetor de `bandwidth`, aplicamos a fun√ß√£o `avaliar_meanshift()` e armazenamos os resultados, possibilitando identificar a combina√ß√£o que resulta na melhor estrutura de agrupamento com base na silhueta m√©dia.

```{r}
tuning_meanshift <- function(dados) {
  # Grid de escalas maiores para reduzir o n√∫mero de grupos
  sd_vars <- apply(dados, 2, sd)
  escalas <- seq(1.5, 5, by = 0.1)
  bw_grid <- lapply(escalas, function(e) e * sd_vars)

  # Avalia cada vetor de bandwidth
  resultados <- purrr::map_dfr(bw_grid, ~avaliar_meanshift(.x, dados))

  return(resultados)
}
```

O objeto final `resultado` cont√©m todas as combina√ß√µes testadas e suas respectivas performances, servindo de base para a escolha do `bandwidth` ideal para o modelo MeanShift.

```{r}
tic()
resultado <- tuning_meanshift(as.matrix(dados_prep))
toc()
```


Ap√≥s testarmos diversas combina√ß√µes de `bandwidth` utilizando a fun√ß√£o `tuning_meanshift()`, o pr√≥ximo passo consiste em selecionar a melhor configura√ß√£o para o modelo MeanShift com base na silhueta m√©dia.

```{r}
melhor_bw <- resultado %>%
  filter(!is.na(silhueta), n_clusters > 1) %>%
  arrange(desc(silhueta)) %>%
  slice(1) %>%
  pull(bandwidth) %>%
  .[[1]]


modelo_meanshift <- meanShift(as.matrix(dados_prep), bandwidth = melhor_bw)
grupos_meanshift <- as.factor(modelo_meanshift$assignment)
```


Os r√≥tulos de cluster obtidos pelo modelo s√£o ent√£o utilizados para construir uma visualiza√ß√£o bidimensional via PCA, facilitando a interpreta√ß√£o visual dos agrupamentos. No gr√°fico gerado, cada ponto representa uma observa√ß√£o, posicionada de acordo com os escores das componentes e colorida segundo o cluster ao qual pertence.


```{r}
fviz_pca_ind(
  pca_result,
  geom.ind = "point",
  col.ind = grupos_meanshift,
  palette = "Set2",
  addEllipses = TRUE,
  legend.title = "Grupo",
  title = "Visualiza√ß√£o dos Grupos Formados no Espa√ßo das Componentes Principais"
)
```


### Tuning de Redes SOM (Kohonen)

Diferentemente de m√©todos cl√°ssicos como K-means, as Redes de Kohonen (SOM ‚Äì Self-Organizing Maps) formam agrupamentos de forma n√£o supervisionada a partir de uma grade de neur√¥nios, cuja estrutura (dimens√£o, topologia, taxa de aprendizado, n√∫mero de itera√ß√µes) impacta diretamente a qualidade dos grupos formados.

Como o pacote `tidyclust` ainda n√£o oferece suporte direto para SOMs, o processo de tuning dos hiperpar√¢metros deve ser feito manualmente. Para isso, foi criada a fun√ß√£o `avaliar_som()`, que recebe os principais hiperpar√¢metros do modelo e avalia sua performance de clusteriza√ß√£o por meio do √≠ndice de silhueta m√©dia.

```{r}
avaliar_som <- function(xdim, ydim, topo, rlen, alpha, dados) {
  grid <- somgrid(xdim = xdim, ydim = ydim, topo = topo)
  
  modelo <- som(
    X = dados,
    grid = grid,
    rlen = rlen,
    alpha = alpha,
    keep.data = TRUE
  )
  
  grupos <- modelo$unit.classif
  
  if (length(unique(grupos)) < 2) {
    return(tibble(
      xdim = xdim,
      ydim = ydim,
      topo = topo,
      rlen = rlen,
      alpha = paste(alpha, collapse = "-"),
      silhueta = NA_real_,
      n_clusters = length(unique(grupos))
    ))
  }
  
  sil <- silhouette(grupos, dist(dados))
  sil_media <- mean(sil[, 3])
  
  tibble(
    xdim = xdim,
    ydim = ydim,
    topo = topo,
    rlen = rlen,
    alpha = paste(alpha, collapse = "-"),
    silhueta = sil_media,
    n_clusters = length(unique(grupos))
  )
}
```

Antes de iniciar o ajuste de modelos SOM, √© necess√°rio definir uma grid de busca com diferentes combina√ß√µes de hiperpar√¢metros, permitindo explorar sistematicamente o impacto de cada configura√ß√£o na qualidade dos agrupamentos formados.

```{r}
xdim_vals <- 2:5
ydim_vals <- 2:5
topo_vals <- c("rectangular", "hexagonal")
rlen_vals <- c(50, 100, 200, 400)
alpha_vals <- list(c(0.05, 0.01), c(0.1, 0.01), c(0.15, 0.01), c(0.2, 0.01))

grid_som <- expand.grid(
  xdim = xdim_vals,
  ydim = ydim_vals,
  topo = topo_vals,
  rlen = rlen_vals,
  alpha = I(alpha_vals),  # evita descompactar a lista
  stringsAsFactors = FALSE 
)
```

O c√≥digo acima constr√≥i o grid utilizando a fun√ß√£o `expand.grid()`, combinando os principais par√¢metros que controlam o comportamento da rede SOM:

- `xdim` e `ydim`: definem as dimens√µes da grade de neur√¥nios (por exemplo, uma grade 3x3 possui 9 unidades de sa√≠da). Grades maiores permitem maior resolu√ß√£o nos agrupamentos, mas podem aumentar a complexidade e o risco de overfitting.

- `topo`: especifica a topologia da grade, podendo ser:
    -  `rectangular`: disposi√ß√£o cl√°ssica dos neur√¥nios em linhas e colunas.
    - `hexagonal`: cada neur√¥nio possui mais vizinhos imediatos, o que suaviza a transi√ß√£o entre clusters.

- `rlen`: define o n√∫mero de itera√ß√µes de treinamento da rede. Quanto maior o valor, maior o tempo de treinamento, mas tamb√©m a chance de converg√™ncia mais est√°vel.

- `alpha`: um vetor com dois valores que especificam a taxa de aprendizado inicial e final. Taxas maiores aceleram o aprendizado no in√≠cio, mas podem comprometer a estabilidade; taxas menores favorecem ajustes mais precisos no final do treinamento.


Uma observa√ß√£o importante para o par√¢metro `alpha` √© que ele √© passada como uma lista (`I(alpha_vals)`) para garantir que cada vetor `c(valor_inicial, valor_final)` seja tratado como uma unidade indivis√≠vel durante a expans√£o da grid. Isso evita que o `expand.grid()` desfa√ßa os pares de taxas de aprendizado.

O objeto `grid_som` resultante cont√©m todas as poss√≠veis combina√ß√µes entre os valores de cada hiperpar√¢metro, e ser√° utilizado para ajustar e avaliar diferentes modelos SOM via a fun√ß√£o `avaliar_som()`.

```{r}
tic()
resultado_som <- pmap_dfr(
  grid_som,
  function(xdim, ydim, topo, rlen, alpha) {
    avaliar_som(xdim, ydim, topo, rlen, alpha, dados = as.matrix(dados_prep))
  }
)
toc()
```


Ap√≥s a avalia√ß√£o das diversas combina√ß√µes de hiperpar√¢metros, selecionamos agora a melhor configura√ß√£o da rede SOM com base nos seguintes crit√©rios:

- Forma√ß√£o de no m√°ximo 5 clusters, evitando segmenta√ß√µes excessivamente fragmentadas.

- Maior silhueta m√©dia, indicando uma boa separa√ß√£o e coes√£o entre os grupos formados.

```{r}
melhor_som <- resultado_som %>%
  filter(n_clusters <= 5) %>%
  arrange(desc(silhueta)) %>%
  slice(1)
```

Com os par√¢metros selecionados, configuramos a grade de neur√¥nios com `somgrid()`, especificando o n√∫mero de neur√¥nios (`xdim` √ó `ydim`) e a topologia (`topo`). Em seguida, o modelo SOM √© ajustado com:

- Os dados preparados (`dados_prep`);

- O n√∫mero de √©pocas de treinamento (`rlen`);

- A taxa de aprendizado inicial e final (`alpha`), convertida novamente de texto para vetor num√©rico.

```{r}
grid <- somgrid(xdim = melhor_som$xdim, ydim = melhor_som$ydim, topo = melhor_som$topo)

modelo_som <- kohonen::som(
  X = as.matrix(dados_prep),
  grid = grid,
  rlen = melhor_som$rlen,
  alpha = as.numeric(strsplit(melhor_som$alpha, "-")[[1]]),
  keep.data = TRUE
)
```


A sa√≠da `modelo_som$unit.classif` fornece os neur√¥nios vencedores (clusters) para cada observa√ß√£o, representando os grupos aos quais os dados foram atribu√≠dos.

```{r}
grupos_som <- modelo_som$unit.classif
```


Para interpretar os resultados, aplicamos uma proje√ß√£o PCA sobre os dados e colorimos os pontos com base nos grupos atribu√≠dos pela rede SOM. 

```{r}
fviz_pca_ind(
  pca_result,
  geom.ind = "point",
  col.ind = factor(grupos_som),
  palette = "Set2",
  addEllipses = TRUE,
  legend.title = "Grupo",
  title = "Visualiza√ß√£o dos Grupos Formados no Espa√ßo das Componentes Principais"
)
```



## An√°lise dos Clusters

Ap√≥s aplicar diferentes algoritmos de clusteriza√ß√£o aos dados (K-means, DBSCAN, MeanShift, SOM e Hier√°rquico), √© importante avaliar o grau de concord√¢ncia entre os agrupamentos gerados por cada m√©todo. Para isso, utilizamos o √çndice Rand Ajustado (ARI ‚Äì Adjusted Rand Index), uma m√©trica amplamente usada para comparar parti√ß√µes, corrigindo a aleatoriedade esperada por acaso.

Para isso, criamos o objeto `lista_grupos`, que armazena os vetores de r√≥tulos atribu√≠dos por cada m√©todo aos dados.

```{r}
lista_grupos <- list(
  kmeans = grupos_kmeans,
  dbscan = grupos_dbscan,
  meanshift = grupos_meanshift,
  som = grupos_som,
  hierarquico = grupos_hierarquico
)
```

```{r}
# Conta o n√∫mero de grupos √∫nicos gerados por cada m√©todo
tabela_num_grupos <- purrr::map_int(lista_grupos, ~ n_distinct(.x)) %>%
  tibble::enframe(name = "Metodo", value = "Numero_de_Grupos")

# Exibe a tabela
tabela_num_grupos
```


Utilizando a fun√ß√£o `combn()`, criamos todas as combina√ß√µes poss√≠veis de dois algoritmos para comparar seus agrupamentos entre si. Para cada par de m√©todos, aplicamos a fun√ß√£o `adjustedRandIndex()` (do pacote `mclust`), que retorna um valor entre:

- 1: agrupamentos id√™nticos;

- 0: agrupamentos n√£o mais concordantes do que o esperado ao acaso;

- < 0: discord√¢ncia inferior ao esperado aleatoriamente.

```{r}
# Gerar todas as combina√ß√µes de pares de m√©todos
comparacao_ari <- combn(names(lista_grupos), 2, simplify = FALSE, FUN = function(par) {
  ari_val <- adjustedRandIndex(lista_grupos[[par[1]]], lista_grupos[[par[2]]])
  tibble(
    metodo1 = par[1],
    metodo2 = par[2],
    ARI = ari_val
  )
}) %>%
  bind_rows() %>%
  arrange(desc(ARI))

# Visualizar resultados
comparacao_ari
```


## Valida√ß√£o Estat√≠stica dos Agrupamentos

Podemos observar que os algoritmos que aparentemente apresentaram as melhores separa√ß√µes em nossa base de dados foram o K-means e as redes SOM. Embora o K-means seja amplamente conhecido por sua velocidade e facilidade de interpreta√ß√£o, ele assume que os grupos possuem forma aproximadamente esf√©rica e tamanho similar, o que pode limitar sua aplicabilidade em dados com estruturas mais complexas. Por outro lado, o SOM √© uma t√©cnica baseada em aprendizado n√£o supervisionado que preserva rela√ß√µes topol√≥gicas e permite visualizar agrupamentos de forma intuitiva, sendo particularmente √∫til em bases com n√£o linearidades ou alta dimensionalidade.


A partir de agora, √© fundamental ir al√©m da interpreta√ß√£o visual e realizar uma avalia√ß√£o estat√≠stica formal da validade dos grupos formados.

Nesta etapa, buscamos responder √† seguinte pergunta:

> "Os grupos encontrados pelos m√©todos de clusteriza√ß√£o representam subdivis√µes estatisticamente distintas com base nas vari√°veis originais dos dados?"



Para essa finalidade, a PERMANOVA (Permutational Multivariate Analysis of Variance) √© uma t√©cnica robusta e amplamente utilizada. A PERMANOVA avalia a exist√™ncia de heterogeneidade entre grupos com base em uma matriz de dist√¢ncias (como dist√¢ncias euclidianas ou de Gower), ao inv√©s de depender de pressupostos fortes como normalidade multivariada e homogeneidade das vari√¢ncias, como ocorre na MANOVA tradicional. A l√≥gica do teste baseia-se em permuta√ß√µes aleat√≥rias dos r√≥tulos dos grupos, calculando a distribui√ß√£o emp√≠rica da estat√≠stica F sob a hip√≥tese nula de que n√£o h√° diferen√ßa entre os grupos.

```{r}
# Definir n√∫mero de n√∫cleos (ex: todos menos 1)
n_cores <- parallel::detectCores() - 1

# Registrar o cluster
cl <- makeCluster(n_cores)
registerDoParallel(cl)

# Verificar se grupos est√£o no formato adequado
grupos_kmeans <- as.factor(grupos_kmeans)

# Calcular a matriz de dist√¢ncias (ou usar diretamente no adonis2)
dist_matrix <- dist(dados_prep, method = "euclidean")

# Executar PERMANOVA com paraleliza√ß√£o
tic()
resultado_permanova <- adonis2(
  formula = dist_matrix ~ grupos_kmeans,
  permutations = how(nperm = 999, blocks = NULL),  # ou aumentar nperm = 5000+
  parallel = cl
)
toc()
# Encerrar cluster
stopCluster(cl)

# Exibir o resultado
resultado_permanova
```



```{r}
# Definir n√∫mero de n√∫cleos (ex: todos menos 1)
n_cores <- parallel::detectCores() - 1

# Registrar o cluster
cl <- makeCluster(n_cores)
registerDoParallel(cl)

# Verificar se grupos est√£o no formato adequado
grupos_som <- as.factor(grupos_som)

# Calcular a matriz de dist√¢ncias (ou usar diretamente no adonis2)
dist_matrix <- dist(dados_prep, method = "euclidean")

# Executar PERMANOVA com paraleliza√ß√£o
tic()
resultado_permanova <- adonis2(
  formula = dist_matrix ~ grupos_som,
  permutations = how(nperm = 999, blocks = NULL),  # ou aumentar nperm = 5000+
  parallel = cl
)
toc()
# Encerrar cluster
stopCluster(cl)

# Exibir o resultado
resultado_permanova
```

Podemos observar que ambos os agrupamentos s√£o estatisticamente significativos (valor-p < 0.001), indicando que h√° estrutura nos dados, ou seja, os grupos n√£o s√£o aleat√≥rios. O agrupamento por SOM com 4 grupos explica mais variabilidade (29,9%) da estrutura de dist√¢ncias do que o K-means com 3 grupos (21,6%). O valor de F tamb√©m √© maior para o SOM (1233.1 vs. 1196.1), o que refor√ßa a qualidade da separa√ß√£o em 4 grupos.


```{r}
# DBI exige labels inteiros
labels_som <- as.integer(grupos_som)

labels_km <- as.integer(grupos_kmeans)

dados_matrix <- as.matrix(dados_prep)

# Calcular √≠ndice Davies-Bouldin
dbi_result <- intCriteria(traj = dados_matrix, part = labels_som, crit = "all")
dbi_result_km <- intCriteria(traj = dados_matrix, part = labels_km, crit = "all")

# Exibir resultado
dbi_result$davies_bouldin
dbi_result$silhouette

dbi_result_km$davies_bouldin
dbi_result_km$silhouette

fviz_silhouette(silhouette(labels_som, dist(dados_prep)))
fviz_silhouette(silhouette(labels_km, dist(dados_prep)))
```

Com base nos valores para o √≠ndice de Davies-Bouldin (DBI) e √≠ndice de Silhueta, podemos fazer a seguinte interpreta√ß√£o comparativa entre dois m√©todos de clusteriza√ß√£o


| M√©trica            | SOM       | K-means | Melhor M√©todo |
| ------------------ | --------- | ------- | ------------- |
| Davies-Bouldin (‚Üì) | **1.91**  | 2.23    | ‚úÖ **SOM**     |
| Silhueta (‚Üë)       | **0.180** | 0.128   | ‚úÖ **SOM**     |


Podemos observar que as redes SOM apresentam desempenho superior, possuindo menor DBI (1.91), o que indica que os clusters est√£o mais compactos e bem separados em compara√ß√£o ao K-means. Al√©m disso, apresenta maior √≠ndice de Silhueta (0.180), o que sugere que os indiv√≠duos est√£o mais bem alocados dentro de seus clusters com rela√ß√£o √† dist√¢ncia entre clusters.

Vale ressaltar que os valores do √≠ndice de Silhueta est√£o pr√≥ximos de 0.1‚Äì0.2, o que indica clusters pouco definidos. Pode haver sobreposi√ß√£o entre grupos, indicando que talvez os dados n√£o possuam estrutura de agrupamento forte.


## Perfis dos grupos gerados

```{r warning=FALSE, message=FALSE}
dados_com_grupos <- dados_prep %>%
  mutate(grupo_som = factor(grupos_som))

resumo_grupos <- dados_com_grupos %>%
  group_by(grupo_som) %>%
  summarise(across(where(is.numeric), mean, na.rm = TRUE)) %>%
  pivot_longer(-grupo_som, names_to = "variavel", values_to = "media")

ggplot(resumo_grupos, aes(x = variavel, y = media, color = grupo_som, group = grupo_som)) +
  geom_line() + geom_point() +
  theme_minimal() +
  labs(title = "Perfis M√©dios por Vari√°vel e Grupo (SOM)", x = "", y = "M√©dia") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


No gr√°fico acima, cada linha representa um dos 4 grupos gerados pela rede SOM (grupo_som de 1 a 4). O eixo x traz as vari√°veis originais da base de dados, enquanto que o eixo y representa a m√©dia padronizada de cada vari√°vel dentro de cada grupo. As diferen√ßas entre as linhas ao longo do eixo x indicam vari√°veis que mais distinguem os grupos.

Com base no gr√°fico, destacam-se como importantes na separa√ß√£o entre os grupos SOM:

| Vari√°vel                                    | Observa√ß√£o                                                                         |
| ------------------------------------------- | ---------------------------------------------------------------------------------- |
| `ShoppingMall`                              | Grupo 1 tem valores visivelmente mais altos.                                       |
| `RoomService`, `Spa`, `VRDeck`              | Claramente mais elevados no **grupo 1**, pr√≥ximos de zero ou negativos nos outros. |
| `FoodCourt`                                 | Tamb√©m destaca o grupo 1 com pico alto.                                            |
| `IsAlone_X1`                                | Forte separa√ß√£o: grupo 3 com valor m√≠nimo, grupo 1 e 4 mais elevados.              |
| `HomePlanet_Earth`                          | Grupo 2 se diferencia nitidamente dos demais.                                      |
| `HomePlanet_Mars`                           | Grupo 1 com valor fortemente negativo (quase -1), indicando aus√™ncia.              |
| `Destination_TRAPPIST-1e`                   | Varia√ß√£o clara entre os grupos, sobretudo entre 1 e 3.                             |
| `CryoSleep_TRUE.`                           | Separa√ß√£o vis√≠vel entre grupos 1/3 e 2/4.                                          |
| `CabinDeck_B`, `CabinDeck_C`, `CabinDeck_F` | Alguns grupos t√™m picos bem distintos, sugerindo uso diferente das cabines.        |


### Interpreta√ß√£o geral dos grupos

- **Grupo 1:** parece composto por passageiros com alto consumo de servi√ßos (`RoomService`, `Spa`, `VRDeck`, `FoodCourt`, `ShoppingMall`), geralmente n√£o dormindo em `CryoSleep`, e com valores extremos em v√°rias vari√°veis.
  - **Perfil:** Passageiros mais velhos, ativos, soci√°veis, consumidores de servi√ßos, n√£o em criogenia, principalmente da Terra e viajando para TRAPPIST-1e.

- **Grupo 2:** mostra valores mais centrados, destaca-se por `HomePlanet_Earth` e padr√µes mais equilibrados.
  - **Perfil:** Grupo moderado, com pouca atividade em servi√ßos pagos, viagem equilibrada entre sozinhos e acompanhados, origem majorit√°ria da Terra, mas n√£o se destacam por extremos.


- **Grupo 3:** possui v√°rios valores m√©dios negativos, baixa presen√ßa de servi√ßos, e maior chance de estar sozinho (`IsAlone`).
  - **Perfil:** Passageiros com perfil econ√¥mico, viagem solit√°ria, em criogenia, oriundos de Marte, com destino alternativo.

- **Grupo 4:** flutua, mas tem valores mais elevados em algumas categorias como `CabinDeck_E` e `VRDeck`.
  - **Perfil:** Grupo com forte localiza√ß√£o em Deck G, com uso moderado de servi√ßos e perfil h√≠brido, sem comportamento extremo.

O gr√°fico evidencia que vari√°veis relacionadas ao consumo de servi√ßos, plano de viagem (`HomePlanet`/`Destination`) e caracter√≠sticas de cabine s√£o as principais respons√°veis pela separa√ß√£o dos grupos SOM. Isso demonstra que a SOM foi eficaz em capturar padr√µes de comportamento e perfil de passageiros.