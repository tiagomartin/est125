---
title: "Criando um sistema de recomendação baseado em regras de associação usando a base de dados Space Titanic"
format: html
execute:
  cache: true
---


Já pararam para pensar em como o Netflix sugere o próximo filme ou o Spotify acerta em cheio na sua playlist semanal? Por trás dessas "mágicas", existem algoritmos poderosos. Hoje, vamos desvendar um deles: as regras de associação.

Nesta análise, vamos mergulhar na base de dados Space Titanic do Kaggle para construir um sistema de recomendação simples, mas eficaz, baseado no famoso algoritmo Apriori.


## O que são Regras de Associação?

As regras de associação são uma técnica de aprendizado de máquina não supervisionado usada para descobrir relações interessantes entre itens em um grande conjunto de dados. Pense em uma cesta de compras de supermercado: se um cliente compra pão e manteiga, qual a probabilidade de ele também comprar geleia?

Uma regra de associação é expressa na forma:

$$A \Longrightarrow B$$


em que $A$ e $B$ são conjuntos de itens. $A$ é chamado de antecedente e $B$ é o consequente. Para avaliar a força de uma regra, usamos três métricas principais:

- **Suporte (sup):** A proporção de transações que contêm tanto o antecedente quanto o consequente. Um suporte alto indica que a combinação de itens é frequente no conjunto de dados.

$$sup(A∪B)= \dfrac{\text{Número de transações com A e B}}{\text{Número total de transações}}$$ 

- **Confiança (conf):** A probabilidade de um item $B$ ser comprado, dado que um item $A$ já foi comprado.

$$conf(A \Longrightarrow B) = \dfrac{sup(A∪B)}{sup(A)}$$


- **Lift:** A métrica mais interessante para regras de associação! O lift mede o quão mais provável é que $B$ seja comprado quando $A$ é comprado, em comparação com a probabilidade de $B$ ser comprado sozinho.
    - Se Lift > 1, a presença de $A$ aumenta a probabilidade de $B$.
    - Se Lift = 1, $A$ e $B$ são independentes.
    - Se Lift < 1, a presença de $A$ diminui a probabilidade de $B$.


$$Lift(A \Longrightarrow B) = \dfrac{conf(A \Longrightarrow B)}{sup(B)} = \dfrac{sup(A∪B)}{sup(A) \times sup(B)}$$


## O Algoritmo Apriori

O algoritmo Apriori é a espinha dorsal da mineração de regras de associação. Ele funciona em duas etapas principais:

1. **Encontrar Conjuntos de Itens Frequentes:** O algoritmo identifica conjuntos de itens que aparecem juntos com uma frequência maior que um suporte mínimo pré-definido. Para evitar a explosão de combinações, ele usa a propriedade "anti-monotônica": se um conjunto de itens não é frequente, nenhum de seus superconjuntos pode ser frequente.

2. **Gerar Regras de Associação:** A partir dos conjuntos de itens frequentes, ele gera regras de associação e calcula as métricas de confiança e lift.


## Mãos à obra: Construindo nosso Sistema no R


Vamos usar a base de dados do Kaggle Space Titanic. Nosso objetivo é criar um "sistema de recomendação" para prever quais características (por exemplo, status de transporte, acomodação) estão associadas umas às outras. Para isso, precisamos transformar nossos dados em um formato de transações, onde cada linha é um "cesto de compras" do passageiro.


## Pacotes utilizados 

```{r, message=FALSE, warning=FALSE}
load <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg))
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
} 

## Pacotes utilizados nessa análise

packages = c("tidyverse", "tidymodels", "arules", "arulesViz", "funModeling", "tictoc", "future", "doFuture", "progressr", "recommenderlab")
load(packages)
```


## Leitura dos dados
 
```{r}
dados = read.csv("https://raw.githubusercontent.com/tiagomartin/est125/refs/heads/main/dados/space_titanic.csv", na.strings = "") %>% 
  na.omit()

dados %>%
  glimpse()
```


```{r message=FALSE, warning=FALSE}
# Engenharia de variáveis
dados = dados %>%
  separate(Cabin, c("CabinDeck", "CabinNum", "CabinSide"), sep = "/", remove = TRUE) %>% 
  mutate(CabinDeck = as.factor(CabinDeck),
         CabinSide = as.factor(CabinSide))
```


Antes de iniciarmos a modelagem, é essencial que os dados estejam no formato correto. O algoritmo Apriori, que usamos para regras de associação, trabalha exclusivamente com dados categóricos. Algumas variáveis originais, como `Age`, `RoomService` e `Spa`, são contínuas e precisam ser transformadas. Para isso, usamos a função `recipe()` encadeada ao pacote `tidymodels` para definir nosso *blueprint* de pré-processamento. 



```{r}
# Criar a receita para o pré-processamento
recipe_obj <- recipe(Transported ~ ., data = dados) %>%

  # Transformar 'Age' em categorias (Jovem, Adulto, Idoso)
  step_mutate(Age_cat = ifelse(Age < 18, "Jovem", 
                               ifelse(Age <= 50, "Adulto", "Idoso")), 
    RoomService_cat = ifelse(RoomService <= quantile(RoomService, 0.33), "Baixo", 
                             ifelse(RoomService <= quantile(RoomService, 0.66), "Médio", "Alto")),
    FoodCourt_cat = ifelse(FoodCourt <= quantile(FoodCourt, 0.33), "Baixo", 
                           ifelse(FoodCourt <= quantile(FoodCourt, 0.66), "Médio", "Alto")),
    ShoppingMall_cat = ifelse(ShoppingMall <= quantile(ShoppingMall, 0.33), "Baixo", 
                              ifelse(ShoppingMall <= quantile(ShoppingMall, 0.66), "Médio", "Alto")),
    Spa_cat = ifelse(Spa <= quantile(Spa, 0.33), "Baixo", 
                     ifelse(Spa <= quantile(Spa, 0.66), "Médio", "Alto")),
    VRDeck_cat = ifelse(VRDeck <= quantile(VRDeck, 0.33), "Baixo", 
                        ifelse(VRDeck <= quantile(VRDeck, 0.66), "Médio", "Alto"))
  ) %>% 
  step_rm(Name, PassengerId, CabinNum, Age, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck) %>% 
  step_string2factor(all_string()) 
```

Após definirmos nosso plano de pré-processamento com o `recipe`, a próxima etapa é aplicar esse plano aos nossos dados. O objeto `recipe_obj` que criamos anteriormente é, na verdade, uma "receita" de como cozinhar os dados, mas os dados ainda não foram "cozinhados". É aqui que entram as funções `prep()` e `bake()`.

1. `prep(recipe_obj, training = dados):` Esta função é o coração do processo. Ela prepara a receita, o que significa que ela "aprende" as transformações a partir dos seus dados de treinamento. Por exemplo, ao rodar o `prep`, a receita vai calcular os quantis para as variáveis `RoomService`, `FoodCourt`, etc., com base na distribuição dos dados (`training = dados`). Esse passo garante que as transformações sejam consistentes em todos os seus conjuntos de dados (treino e teste), evitando vazamento de informações.

2. `bake(dados_processados, new_data = NULL):` Com a receita já preparada, a função `bake` aplica as transformações aos dados. No nosso caso, ao passar `new_data = NULL`, estamos pedindo para aplicar as transformações ao mesmo conjunto de dados que foi usado no `prep`.

```{r}
# Preparar e aplicar a receita no conjunto de dados
dados_processados <- prep(recipe_obj, training = dados)

# Aplicar a receita no conjunto de dados
dados_transf <- bake(dados_processados, new_data = NULL)

dados_transf %>% glimpse()
```

Ao final, a variável `dados_transf` conterá um novo dataframe com todas as transformações aplicadas: as variáveis contínuas foram discretizadas, as colunas desnecessárias foram removidas e as variáveis de texto foram convertidas para fatores. A chamada `glimpse()` nos permite dar uma olhada rápida na nova estrutura dos dados, confirmando que tudo foi processado conforme o esperado e que agora estamos prontos para aplicar o algoritmo Apriori. O pacote `arules`, que contém o algoritmo Apriori, exige que os dados estejam em um formato específico: um objeto de transações. A função `as()` aplicada ao nosso dataframe `dados_transf` e especificada como `transactions` transforma cada linha do dataframe em uma "cesta de compras" e cada coluna em um "item". 

```{r}
# Converter o dataset processado para o formato de transações
dados_transacoes <- as(dados_transf, "transactions")
```

Podemos então, visualizar as primeiras transações e ter certeza de que a conversão foi feita corretamente.

```{r}
# Verificando as primeiras transações
inspect(dados_transacoes[1:3])
```

Por fim, geramos um gráfico que mostra a frequência dos itens mais comuns. Essa visualização é crucial para entender a distribuição dos nossos dados e nos ajuda a definir um valor de `support` adequado para o algoritmo Apriori. Itens muito raros não formarão regras fortes, então é bom ver quais são os mais frequentes.

```{r}
itemFrequencyPlot(dados_transacoes, topN = 20, type = "relative")
```


Analisando o gráfico, podemos tirar algumas conclusões importantes sobre os passageiros do Space Titanic:

- **Itens Mais Frequentes:** O item mais frequente de longe é `VIP=False`. Isso significa que a grande maioria dos passageiros não era VIP. Em seguida, temos `Age_cat=Adulto`, indicando que a maior parte da tripulação estava na faixa etária adulta, e `Destination=TRAPPIST-1e`, que era o destino mais comum.

- **Foco nas Variáveis de Gastos:** As variáveis de gastos (`RoomService`, `FoodCourt`, `ShoppingMall`, `Spa`, `VRDeck`), que discretizamos em categorias, aparecem com maior frequência na categoria Baixo. Isso sugere que a maioria dos passageiros não gastou muito nesses serviços. Note que `ShoppingMall_cat=Baixo`, `RoomService_cat=Baixo`, `FoodCourt_cat=Baixo`, `VRDeck_cat=Baixo` e `Spa_cat=Baixo` estão todos entre os itens mais frequentes.

- **Variáveis-Chave de Transporte:** A variável `Transported=False` e `Transported=True` aparecem com frequências muito parecidas, por volta de 50%. Isso confirma que o dataset está bem balanceado em relação ao nosso alvo, que é a variável `Transported`. A ligeira diferença pode ser importante, mas o balanço é bom para a modelagem.

### O que podemos esperar do Apriori?

Itens com alta frequência, como `VIP=False` e `Age_cat=Adulto`, terão um suporte alto. Por isso, ao rodar o algoritmo Apriori, é provável que vejamos muitas regras de associação que envolvam esses itens. Itens menos frequentes, como as categorias Alto de gastos, só aparecerão em regras se tiverem uma associação muito forte com outros itens.


```{r}
plan(multisession, workers = parallel::detectCores() - 1)
registerDoFuture()

handlers("txtprogressbar")  # ou "progress"

tic()
with_progress({
# Aplicando o algoritmo Apriori para encontrar regras de associação
regras <- apriori(dados_transacoes, 
                  parameter = list(supp = 0.2, conf = 0.8, target = "rules"))
})
toc()

# Vamos ordenar as regras por 'lift' para encontrar as associações mais interessantes
regras_sorted <- sort(regras, by = "lift")

# Inspecionar as 10 melhores regras
inspect(head(regras_sorted, n = 10))
```


Observando as regras, podemos notar alguns padrões muito claros e significativos sobre os passageiros do Space Titanic.

### O Padrão Principal: HomePlanet + Gastos Baixos -> Cabin Deck G

A característica mais notável é que a grande maioria das regras aponta para a mesma conclusão: passageiros que vêm do planeta Terra e têm gastos baixos em diversos serviços a bordo (`RoomService`, `FoodCourt`, `ShoppingMall`, `Spa`, `VRDeck`) tendem a estar localizados na cabine do Deck G.

- **Exemplo de Regra ([1]):** `{HomePlanet=Earth, FoodCourt_cat=Baixo, ShoppingMall_cat=Baixo, VRDeck_cat=Baixo} => {CabinDeck=G}`.
    - **Suporte (0.202):** Essa regra aparece em aproximadamente 20,2% de todas as transações, o que é um valor alto e indica que a combinação de `HomePlanet=Earth` com gastos baixos e a cabine no `Deck=G` é bastante comum.
    - **Confiança (0.926):** A confiança de 92,6% é extremamente alta. Isso significa que, se um passageiro é do planeta Terra e tem gastos baixos nos serviços listados, a probabilidade de ele estar no Deck G é de 92,6%.
    - **Lift (3.100):** O lift de 3,1 é a métrica mais importante aqui. Ele nos diz que a probabilidade de um passageiro que vem da Terra e gasta pouco estar no Deck G é 3,1 vezes maior do que a probabilidade de um passageiro qualquer estar no Deck G. Isso indica que a associação não é aleatória; ela é forte e significativa.
    - **coverage (0.218):** Isso significa que aproximadamente 21,8% de todos os passageiros se encaixavam nas condições do antecedente (`HomePlanet=Earth, FoodCourt_cat=Baixo, ShoppingMall_cat=Baixo, VRDeck_cat=Baixo`).
    - **count (1339):** Significa que 1339 passageiros se encaixavam em todas as condições da regra: eles vieram da Terra, tiveram gastos baixos nos serviços listados e estavam na cabine do Deck G.


### O Papel da Variável VIP

Outro ponto que salta aos olhos é a presença da variável `VIP=False` em quase todas as regras. As regras ímpares (1, 3, 5, etc.) são seguidas por regras pares idênticas, mas com o antecedente `VIP=False` adicionado. No entanto, os valores de `support`, `confidence`, `coverage` e `lift` são exatamente os mesmos.

#### Por que isso acontece?

O gráfico de frequência de itens que vimos anteriormente já nos mostrou que `VIP=False` era um dos itens mais frequentes, com uma frequência acima de 90%.

O algoritmo Apriori encontra as regras mais fortes. Como a maioria esmagadora dos passageiros não era VIP, a inclusão de `VIP=False` nos antecedentes não altera a proporção de transações que satisfazem a regra. Em essência, a presença de `VIP=False` é tão comum que se torna quase redundante.

Isso é um bom insight sobre os dados: a variável `VIP` não é um fator importante para determinar a cabine no Deck G, pois a maioria dos passageiros, sejam eles VIP ou não, já se encaixam nas outras condições da regra.


Agora que já exploramos as regras de associação gerais, vamos focar em um objetivo mais específico: entender quais características dos passageiros estão mais fortemente associadas ao seu status de transporte (`Transported=True`).

Para isso, usamos um truque muito útil na função `apriori()`: o parâmetro `appearance`. Ao usar `appearance = list(rhs = "Transported=True", default = "lhs")`, estamos direcionando o algoritmo para que ele só procure por regras que tenham `Transported=True` no consequente (`rhs`). Isso nos permite criar um "sistema de recomendação" que nos diz "se um passageiro tem as seguintes características, ele provavelmente foi transportado".


```{r}
regras_transported <- apriori(dados_transacoes,
                            parameter = list(support = 0.2, confidence = 0.8, minlen = 2),
                            appearance = list(rhs = "Transported=True", default = "lhs"))

regras_transported_sorted <- sort(regras_transported, by = "lift")

# Inspecionar as 10 melhores regras
inspect(head(regras_transported_sorted, n = 10))
```

Ao analisar as regras, um padrão se destaca de forma clara e dominante: o estado de sono criogênico.

- **Regra Principal:** A primeira e mais importante regra é [1] `{CryoSleep=True} => {Transported=True}`.
      - **support (0.288):** Quase 29% de todos os passageiros foram colocados em sono criogênico E foram transportados. Isso demonstra que essa é uma combinação comum nos dados.
      - **confidence (0.816):** Se um passageiro foi colocado em sono criogênico, há uma probabilidade de mais de 81% de ele ter sido transportado. Esta é uma previsão muito confiável.
      - **lift (1.622):** O lift de 1.62 nos diz que a probabilidade de um passageiro ser transportado, sabendo que ele está em sono criogênico, é 1,62 vezes maior do que a probabilidade geral de transporte na nave. Isso confirma que a associação não é aleatória.


As regras de `[2]` a `[10]` são apenas variações da primeira. Elas adicionam um ou mais itens de gastos baixos (`Spa_cat=Baixo`, `VRDeck_cat=Baixo`, etc.) ao antecedente, mas os valores de `support`, `confidence`, `coverage`, `lift` e `count` permanecem exatamente os mesmos.

Isso significa que a variável `CryoSleep=True` sozinha é o fator determinante para a previsão. A adição de outras características, como gastos baixos em serviços, não aumenta a confiança nem a relevância da regra, porque todos os passageiros em sono criogênico já têm gastos nulos ou baixos nesses serviços. O algoritmo Apriori está essencialmente nos mostrando que a informação `CryoSleep=True` já contém, de forma implícita, a informação de que os gastos são baixos.

Agora que identificamos as regras de associação mais relevantes para o transporte de passageiros, a melhor forma de consolidar nosso entendimento é através de uma **visualização**.

```{r}
plot(regras_transported_sorted[1:10], method = "graph", engine = "htmlwidget")
```

O gráfico de rede mostra as conexões entre os diferentes itens (nós) e as regras que os conectam (setas).

- **Círculos Rosas:** Cada círculo rosa, rotulado como `rule 1`, `rule 2`, etc., é a representação de uma regra de associação completa.

- **Caixas Azuis:** As caixas azuis, como `CryoSleep=True` ou `Transported=True`, representam os itens (variáveis e seus valores).

- **Setas que entram no círculo rosa:** Indicam os itens que compõem o antecedente (`lhs`) da regra. Por exemplo, a seta que sai de `CryoSleep=True` e vai para o círculo `rule 1` nos diz que `CryoSleep=True` é parte do antecedente da Regra 1.

- **Setas que saem do círculo rosa:** Indicam o item que é o consequente (`rhs`) da regra. Vemos que todas as setas saem dos círculos de regras e apontam para a caixa `Transported=True`. Isso confirma que `Transported=True` é o consequente de todas as regras que estamos analisando.


Assim, podemos observar que:

- **A Regra Principal (rule 1):** A seta que liga `CryoSleep=True` ao círculo `rule 1` e, em seguida, a seta que liga `rule 1` a `Transported=True` representa a regra `{CryoSleep=True} => {Transported=True}`.

- **As Regras Derivadas (rule 2, rule 3, etc.):** As setas que ligam `CryoSleep=True` e as caixas de gastos baixos aos outros círculos de regras mostram que essas regras têm antecedentes mais complexos, mas ainda resultam na mesma previsão: `Transported=True`.

O gráfico é uma ferramenta excelente para visualizar como os itens se conectam através das regras, mostrando que todos os caminhos dos antecedentes convergem para a mesma previsão final.



## Construindo um sistema de recomendação simples, baseado em regras de associação


As regras de associação são uma técnica de mineração de dados que identifica padrões e relações entre itens em um grande conjunto de transações. Pense na clássica análise de cesta de compras: a regra `{Pão, Manteiga} => {Geleia}` sugere que clientes que compram pão e manteiga também tendem a comprar geleia.

Um sistema de recomendação usa essa mesma lógica. Em vez de prever a compra de geleia, ele pode prever o interesse em um filme, a alocação de um passageiro em uma cabine, ou a alta probabilidade de um evento acontecer.


O algoritmo Apriori no `recommenderlab` trabalha com uma matriz esparsa de avaliação binária, um tipo de estrutura de dados otimizado para sistemas de recomendação. Essa matriz representa a presença ou ausência de cada item (colunas) para cada transação ou usuário (linhas). A função `as()` do pacote `arules` é perfeita para essa tarefa, pois ela converte o objeto de transações (`dados_transacoes`) que criamos anteriormente para esse novo formato de forma eficiente.

```{r}
dados_recommender <- as(dados_transacoes, "binaryRatingMatrix")
```

Com os dados agora no formato correto, estamos prontos para a etapa central do nosso sistema de recomendação: a criação do modelo.

O extrato de código a seguir usa a função `Recommender()` do pacote `recommenderlab` para treinar nosso modelo de recomendação.

```{r}
recom_model <- Recommender(data = dados_recommender,
                           method = "AR",
                           parameter = list(supp = 0.2, conf = 0.8, maxlen = 10))
```


Ao executar esse código, o `recommenderlab` irá minerar as regras de associação no nosso conjunto de dados, criando um modelo que pode ser usado para gerar previsões para novos passageiros. Depois de treinar o modelo com `Recommender()`, as regras de associação descobertas são armazenadas dentro do objeto `recom_model`. 



```{r}
# O objeto 'recom_model' armazena as regras de associação.
# Podemos extrair e inspecionar as regras encontradas.
model_details <- getModel(recom_model)
regras_finais <- model_details$rule_base

regras_finais_sorted <- sort(regras_finais, by = "lift")

# Vamos inspecionar as regras encontradas pelo recommenderlab
inspect(head(regras_finais_sorted, n = 10))
```

A análise do resultado deste comando nos dará os mesmos insights que obtivemos com o pacote `arules`, mas agora dentro do fluxo de trabalho do `recommenderlab`. Nosso objetivo agora é colocar o modelo que treinamos em ação e gerar recomendações. Para isso, iremos "simular" dois novos passageiros para serem apresentados ao nosso sistema de recomendação.


```{r}
# 1. Obter os nomes dos itens do modelo treinado
items_names <- colnames(dados_recommender)

# 2. Criar uma matriz de zeros para todos os passageiros e itens
# Vamos definir o número de passageiros que você quer avaliar
num_passageiros <- 2 
novos_passageiros_mat <- matrix(0, nrow = num_passageiros, ncol = length(items_names))
colnames(novos_passageiros_mat) <- items_names
rownames(novos_passageiros_mat) <- c("Novo_Passageiro_01", "Novo_Passageiro_02")

# 3. Preencher a matriz com as características de cada passageiro
# Passageiro 1: da Terra, com gastos baixos
novos_passageiros_mat["Novo_Passageiro_01", "HomePlanet=Earth"] <- 1
novos_passageiros_mat["Novo_Passageiro_01", "RoomService_cat=Baixo"] <- 1
novos_passageiros_mat["Novo_Passageiro_01", "FoodCourt_cat=Baixo"] <- 1

# Passageiro 2: VIP, Adulto e em sono criogênico
novos_passageiros_mat["Novo_Passageiro_02", "VIP=True"] <- 1
novos_passageiros_mat["Novo_Passageiro_02", "Age_cat=Adulto"] <- 1
novos_passageiros_mat["Novo_Passageiro_02", "CryoSleep=True"] <- 1

# 4. Converter a matriz consolidada para o formato binaryRatingMatrix
novos_passageiros_ratings <- as(novos_passageiros_mat, "binaryRatingMatrix")

# 5. Gerar as recomendações
recommendations <- predict(recom_model, novos_passageiros_ratings, n = 5)

# Inspecionar as recomendações para ambos os passageiros
as(recommendations, "list")
```

O resultado será uma lista de "recomendações" para cada um deles. Com base nas regras de associação que descobrimos, o sistema nos dirá qual item é o mais provável para cada perfil. Isso fecha o ciclo do nosso projeto, mostrando como a mineração de dados pode se traduzir em um sistema prático e preditivo.


### Análise das Recomendações

O *output* está em formato de lista, onde cada item (`$0` e `$1`) corresponde a uma recomendação para um passageiro. A ordem das recomendações corresponde à ordem dos passageiros na matriz de entrada.

1. Recomendação para o Primeiro Passageiro (`$0`): O modelo "recomendou" a seguinte lista de itens:

`"VIP=False" "Spa_cat=Baixo" "ShoppingMall_cat=Baixo" "VRDeck_cat=Baixo" "CabinDeck=G"`

 - **O que o sistema viu:** Se o seu primeiro passageiro era o que vinha da Terra com gastos baixos (`RoomService`, `FoodCourt`, etc.), o modelo identificou as regras que se aplicam a esse perfil.

 - **O que o sistema recomendou:** O sistema listou os itens que, com base nas regras, estão mais fortemente associados a esse perfil. A recomendação mais importante aqui é `CabinDeck=G`. O sistema está basicamente dizendo: "Com base nas características desse passageiro (vindo da Terra, gastos baixos), a cabine mais provável para ele é no Deck G." Os outros itens na lista são parte das regras que levaram a essa conclusão.

2. Recomendação para o Segundo Passageiro ($1): O modelo "recomendou" a seguinte lista de itens:

`"RoomService_cat=Baixo" "FoodCourt_cat=Baixo" "ShoppingMall_cat=Baixo" "Spa_cat=Baixo" "VRDeck_cat=Baixo"`

 - **O que o sistema viu:** Se o seu segundo passageiro era o VIP, adulto e em sono criogênico, a recomendação nos dá um insight diferente.

 - **O que o sistema recomendou:** A recomendação principal aqui é uma lista de itens que representam gastos baixos. Isso faz sentido, pois nossa análise anterior mostrou que a variável `CryoSleep=True` (sono criogênico) está quase sempre associada a gastos nulos ou baixos em todos os serviços. O sistema está recomendando a previsão de que, se o passageiro está em sono criogênico, ele provavelmente terá gastos baixos nesses serviços.


### Conclusão

O sistema de recomendação funcionou como esperado, aplicando as regras de associação para fazer previsões lógicas para cada perfil de passageiro.

- Para o primeiro passageiro, a recomendação foi sobre a alocação da cabine.

- Para o segundo passageiro, a recomendação foi sobre o comportamento de gastos, que é um item fortemente associado ao estado de sono criogênico.

Isso demonstra como um sistema baseado em regras de associação pode ser usado para inferir diferentes tipos de informações com base nos padrões encontrados nos dados.
