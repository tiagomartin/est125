---
title: "Análise Preditiva"
format: 
  revealjs:
    width: 1600
    height: 900
    footer: ""
    theme: quartomonothemer.scss
    slide-number: c/t
    show-slide-number: all
incremental: false
code-link: true
bibliography: references.bib
title-slide-attributes:
    data-background-image: /images/back.jpeg
    data-background-size: cover
    data-background-opacity: "0.3"
---


# Machine Learning

## O que é Inteligência Artificial (IA)?

:::: {.columns}
::: {.column width="40%"}

<br>

![](/images/IA.png){fig.align="right" width=120%}
:::

::: {.column width="60%"}

<br>

<p align="center"> 
A capacidade de um **sistema computacional** simular **habilidades cognitivas humanas** 
</p>

<br>


- Visão Computacional

- Processamento de Linguagem Natural

- Robótica 

- Machine Learning
:::
::::


## O que é Inteligência Artificial (IA)?

<br>

![](/images/linha_IA.png){fig.align="center" width=120%}


## O que é Machine Learning?

<p align="center">
Um subcampo da IA que permite que sistemas aprendam a partir de dados, sem serem explicitamente programados
</p>

<br>

![](/images/PT_ML.png){fig.align="center" width=80%}

## O que é Machine Learning?

:::: {.columns}

::: {.column width="20%"}
<span style='font-size:200px;'>&#128202;</span> 
:::

::: {.column width="80%"}
<p align="center">
Do ponto de vista da **Estatística**, Machine Learning (ML) é uma extensão e uma aplicação computacional de métodos estatísticos com um forte **foco em predição** e **descoberta de padrões em dados**, muitas vezes em larga escala e com **menor ênfase na inferência causal tradicional**.
</p>
:::

::::


. . .


:::: {.columns}

::: {.column width="20%"}
<span style='font-size:200px;'>&#128187;</span> 
:::

::: {.column width="80%"}
<p align="center">
Do ponto de vista da **Ciência da Computação**, Machine Learning (ML) é um campo que se concentra no **desenvolvimento de algoritmos** e sistemas computacionais que podem **aprender a partir de dados** para realizar tarefas **sem serem explicitamente programados** para cada uma delas.
</p>
:::

::::


## O que é Machine Learning?

![](/images/est_cc_ML.png){fig.align="center"}

## As duas culturas...

<br>

- **Data Modeling Culture:** Domina a comunidade estatística. Nela se **assume que o modelo utilizado é correto**. Testar suposições é fundamental. **Foco em inferência e na interpretação dos parâmetros**.

. . .

- **Algorithmic Modeling Culture:** Domina a comunidade de machine learning. Nela **não se assume que o modelo utilizado é correto**; **o modelo é utilizado apenas para criar bons algoritmos preditivos**. Podemos interpretar os resultados, mas esse, em geral, não é o foco.


## Exemplos práticos de aplicações de ML no dia a dia.

<br>


-	Sistemas de recomendação (Netflix, Amazon).
-	Filtros de spam (Gmail).
-	Carros autônomos (Tesla).
-	Diagnóstico médico (detecção de tumores).
-	Reconhecimento facial (smartphones).


## Como as Máquinas Aprendem? 

<br>

::: {#fig layout-ncol=2}

![](/images/bike.png){.nostretch fig-align="center" width="800px"}


![](/images/aprendizadoRN.gif){.nostretch fig-align="center" width="1200px"}
:::


## Componentes do aprendizado de máquina

<br>

:::: {.columns}

::: {.column width="60%"}
![https://vas3k.com/blog/machine_learning/](/images/fig07.png){.nostretch fig-align="center" width="700px"}
:::

::: {.column width="40%"}

<br>

<p></p>

- Dados

- Características/Features

- Algoritmos

:::

::::

## O mapa da aprendizagem de máquina

:::: {.columns}

::: {.column width="40%"}
![](/images/fig02a.png){fig.align="center"}
:::

::: {.column width="60%"}

<br>

<p align="center">
&#128073; Nunca há uma única maneira de resolver um problema no mundo do aprendizado de máquina. 

&#128073; Sempre existem vários algoritmos que se encaixam, e você deve escolher qual deles se encaixa melhor. 


&#128073; Tudo pode ser resolvido com uma rede neural? Sim, mas quem pagará por todo esse custo?
</p>



:::

::::


## O mapa da aprendizagem de máquina

![](/images/fig03a.png){.nostretch fig-align="center" width="1200px"}



## Aprendizado de Máquina Clássico


![](/images/tipos_aprend.png){.nostretch fig-align="center" width="1150px"}



## Aprendizado de Máquina Clássico



&#128073; O aprendizado de máquina clássico é frequentemente dividido em duas categorias – **Aprendizado Supervisionado** e **Não Supervisionado**.

. . .


- **Aprendizado Supervisionado:** usa um algoritmo que precisa de exemplos rotulados para desempenhar suas tarefas. 


. . .


- **Aprendizado Não-supervisionado:** os dados não são rotulados, não há professor e a máquina está tentando encontrar padrões por conta própria.



## Aprendizado Supervisionado

<br>

<span style='font-size:80px;'>&#128161;</span> Claramente, a máquina aprenderá mais rápido com um professor. Por isso, é mais comum encontrarmos esse caso nas tarefas da vida real.

. . .


- Existem dois tipos de tarefas: 

    - **classificação:** predição de categoria de um objeto e 
    - **regressão:** predição de um ponto específico em um eixo numérico.
    
    
## Tarefa de classificação

<p align="center">
Os algoritmos de classificação dividem os objetos com base em um dos atributos conhecidos de antemão. 
</p>


:::: {.columns}

::: {.column width="60%"}

<br>

- Usados nos dias de hoje para:

  - Filtragem de spam;
  - Detecção de idioma;
  - Pesquisa por documentos semelhantes;
  - Análise de sentimentos;
  - Reconhecimento de caracteres;
  - Detecção de fraude.

:::

::: {.column width="40%"}

![](/images/fig09.png){.nostretch fig-align="center" width="1000px"}

:::
::::


## Tarefa de classificação

<br>
<br>


<p align="center">
Algoritmos populares: **Naive Bayes**, **Decision Tree**, **Logistic Regression**, **K-Nearest Neighbours**, **Support Vector Machine**.
</p>


## Tarefa de regressão

<p align="center">
Se a variável resposta é quantitativa, temos um problema de análise de regressão 
</p>


:::: {.columns}

::: {.column width="60%"}

<br>

- Usados nos dias de hoje para:

  - Previsões do preço das ações;
  - Análise de demanda e volume de vendas;
  - Diagnóstico médico.

:::

::: {.column width="40%"}

![](/images/fig10.png){.nostretch fig-align="center" width="1000px"}

:::
::::

## Tarefa de regressão

<br>
<br>


<p align="center">
Algoritmos populares: **Decision Tree**, **Regressão Linear** e **Regressão Polinomial**, **K-Nearest Neighbours**, **Support Vector Machine**.
</p>




## Avaliação de modelos


<span style='font-size:80px;'>&#128161;</span>  Independente do modelo escolhido, é importante saber se um modelo de machine learning está realmente funcionando. É aí que entra a **avaliação de modelos**!


:::: {.columns}

::: {.column width="40%"}

![](/images/detetive.jpg){.nostretch fig-align="center" width="1000px"}
:::

::: {.column width="60%"}

<br>

<p align="center">
A **avaliação de modelos** de machine learning é como um **detetive investigando um caso**.
</p>

:::
::::


## Avaliação de modelos

<br>

<br>

::: {layout-ncol=2}

![](/images/over_under.png){.nostretch fig-align="center" width="1000px"}

![](/images/erro_over_under.png){.fragment fig-align="center" width="1000px"}


:::



## Avaliação de modelos



<p align="center" >
<span style='font-size:70px;'>&#129300;</span> O nosso modelo é um **herói** ou um **impostor**?
</p>

![](https://media4.giphy.com/media/ek4CUx2FONgHaMz9V5/giphy-downsized-medium.gif){fig-align="center" width="1000px"}




## Matriz de confusão


Permite a visualização do **desempenho** de um **algoritmo de classificação**

&nbsp;

![](/images/mc.png){.nostretch fig-align="center" width="1000px"}

## Matriz de confusão

<br>

- **VP (Verdadeiro Positivo):** objeto da classe positiva classificado como positivo 

. . .


- **VN (Verdadeiro Negativo):** objeto da classe negativa classificado como negativo

. . .


- **FP (Falso Positivo):** objeto da classe negativa classificado como positivo. Também conhecido como **alarme falso** ou **Erro tipo 1**


. . .


- **FN (Falso Negativo):** objeto da classe positiva classificado como negativo. É também conhecido como **Erro Tipo 2**


## Matriz de confusão

<br> 

**Exemplo:** Sejam as seguintes matrizes de confusão, obtidas de dois classificadores quaisquer.

<br>

::: {layout-ncol=2}

![](/images/mc_cliente.png){.nostretch fig-align="center" width="1000px"}

![](/images/mc_paciente.png){.nostretch fig-align="center" width="1000px"}


:::


# Métricas derivadas da matriz de confusão

## Acurácia

:::: {.columns}

::: {.column width="40%"}

![](/images/acc.jpg){.nostretch fig-align="center" width="400px"}
:::

::: {.column width="60%"}

<br>


<p align="center">
Mede a **proporção de previsões corretas** do modelo em relação ao total de previsões feitas.
</p>

:::
::::


<p align="center">
**É como sua nota em uma prova!**
</p>


## Acurácia

<br>

:::: {.columns}

::: {.column width="50%"}

![](/images/mc.png){.nostretch fig-align="center" width="800px"}
:::

::: {.column width="50%"}

<br>


![](/images/acc_form.jpg){.nostretch fig-align="center" width="800px"}

:::
::::


A **Taxa de Erro Aparente** do classificador é dada por

$$TEA = 1 - ACC$$



## Acurácia

::: {layout-nrow=2}

![](/images/mc_cliente_acc.png){.nostretch fig-align="center" width="1000px"}

![](/images/acc_tea_cliente.png){.nostretch fig-align="center" width="1000px"}

![](/images/mc_paciente_acc.png){.nostretch fig-align="center" width="1000px"}

![](/images/acc_tea_paciente.png){.nostretch fig-align="center" width="1000px"}

:::


## Acurácia


<br>

<br>


<p align="center">
Mas será que a **acurácia** é suficiente para avaliar nossos modelos de forma **precisa**? 
</p>


. . .


<p align="center">
Às vezes, uma **única métrica** não é capaz de nos contar toda a história.
</p>



## Precisão

<br>


:::: {.columns}

::: {.column width="40%"}

![](/images/precision.jpg){.nostretch fig-align="center" width="400px"}
:::

::: {.column width="60%"}

<br>


<p align="center">
Ela nos diz quantas das **previsões positivas** foram realmente **corretas**.
</p>

:::
::::


## Precisão

<br>

:::: {.columns}

::: {.column width="50%"}

![](/images/mc.png){.nostretch fig-align="center" width="800px"}
:::

::: {.column width="50%"}

<br>

![](/images/precision_form.jpg){fig-align="center" width="800px"}

:::
::::



<p align="center">
Porcentagem de verdadeiros positivos dentre todos os objetos classificados como positivos
</p>



## Precisão


::: {layout-nrow=2 layout-valign="bottom"}

![](/images/mc_cliente_prec.png){.nostretch fig-align="center" width="1000px"}

![](/images/prec_form_clientes.jpg){.nostretch fig-align="center" width="1000px"}

![](/images/mc_paciente_prec.png){.nostretch fig-align="center" width="1000px"}

![](/images/prec_form_pacientes.jpg){.nostretch fig-align="center" width="1000px"}

:::



## Sensibilidade


<br>

:::: {.columns}

::: {.column width="50%"}

![](/images/recall.jpg){.nostretch fig-align="center" width="800px"}
:::

::: {.column width="50%"}

<br>


<p align="center">
Mede a **proporção de casos positivos reais** que foram encontrados pelo modelo 
</p>


:::
::::

## Sensibilidade

<br>


:::: {.columns}

::: {.column width="50%"}

![](/images/mc.png){.nostretch fig-align="center" width="800px"}
:::

::: {.column width="50%"}

<br>

![](/images/sens_form.jpg){.nostretch fig-align="center" width="1000px"}

:::
::::

<p align="center">
Também conhecida por **Recall** ou **Taxa de Verdadeiros Positivos (TVP)**
</p>

## Sensibilidade


::: {layout-nrow=2 layout-valign="bottom"}

![](/images/mc_cliente_sens.png){.nostretch fig-align="center" width="1000px"}

![](/images/sens_form_clientes.jpg){.nostretch fig-align="center" width="1000px"}

![](/images/mc_paciente_sens.png){.nostretch fig-align="center" width="1000px"}

![](/images/sens_form_pacientes.jpg){.nostretch fig-align="center" width="1000px"}

:::


## Especificidade

:::: {.columns}

::: {.column width="50%"}

![](/images/espec.jpg){.nostretch fig-align="center" width="600px"}
:::

::: {.column width="50%"}

<br>

<br>

<p align="center">
Ajuda a identificar a capacidade do modelo em reconhecer **corretamente as amostras negativas**   
</p>


:::
::::


## Especificidade

<br>

:::: {.columns}

::: {.column width="50%"}

![](/images/mc.png){.nostretch fig-align="center" width="800px"}
:::

::: {.column width="50%"}

<br>

![](/images/espec_form.jpg){.nostretch fig-align="center" width="800px"}

:::
::::

<p align="center">
Também conhecida por **Taxa de Verdadeiros Negativos (TVN)**
</p>


## Especificidade

::: {layout-nrow=2 layout-valign="bottom"}

![](/images/mc_cliente_espec.png){.nostretch fig-align="center" width="1000px"}

![](/images/espec_form_clientes.jpg){.nostretch fig-align="center" width="1000px"}

![](/images/mc_paciente_espec.png){.nostretch fig-align="center" width="1000px"}

![](/images/espec_form_pacientes.jpg){.nostretch fig-align="center" width="1000px"}

:::


## Taxa de Falso Positivo


:::: {.columns}

::: {.column width="50%"}

<br>

![](/images/fpr.jpg){.nostretch fig-align="center" width="1000px"}
:::

::: {.column width="50%"}

<br>

<br>

<p align="center">
Ela mede a **proporção de amostras negativas** classificadas como positivas pelo modelo  
</p>


:::
::::


## Taxa de Falso Positivo


<br>

:::: {.columns}

::: {.column width="50%"}

![](/images/mc.png){.nostretch fig-align="center" width="800px"}
:::

::: {.column width="50%"}

<br>

![](/images/fpr_form.jpg){.nostretch fig-align="center" width="500px"}

:::
::::


## Taxa de Falso Positivo

::: {layout-nrow=2 layout-valign="bottom"}

![](/images/mc_cliente_espec.png){.nostretch fig-align="center" width="1000px"}

![](/images/fpr_form_clientes.jpg){.nostretch fig-align="center" width="1000px"}

![](/images/mc_paciente_espec.png){.nostretch fig-align="center" width="1000px"}

![](/images/fpr_form_pacientes.jpg){.nostretch fig-align="center" width="1000px"}

:::


## $F_1$-Score

:::: {.columns}

::: {.column width="50%"}

<br>

![](/images/f1.jpg){.nostretch fig-align="center" width="500px"}
:::

::: {.column width="50%"}

<br>

<br>

<br>

<p align="center">
 Ele leva em consideração tanto **precisão** quanto a **sensibilidade**, dando uma medida balanceada do desempenho do modelo.  
</p>


:::
::::


## $F_1$-Score

<br>

<br>

$$F_1 \text{-score} = 2 \times \dfrac{\text{Precisão} \times \text{Sensibilidade}}{\text{Precisão} + \text{Sensibilidade}}$$

<br>

<p align="center">
O $F_1$-Score é como um **equilibrista** em uma corda bamba.
</p>


## Curva ROC

- A **Curva ROC** é como um mapa que nos guia pela **sensibilidade** e pelos **falsos positivos** do modelo em diferentes configurações. 

. . .

- Ela nos mostra o quão bem nosso modelo pode **distinguir** entre as classes.


![](/images/roc.jpg){.fragment fig-align="center" width="700px"}


## Curva ROC


- Representa o número de vezes que o classificador **acertou a predição** contra o número de vezes que o classificador **errou a predição**

. . .


- A área sob a curva ROC, conhecida como **AUC-ROC**, é uma métrica comumente utilizada para avaliar o desempenho global do modelo. 

. . . 

- Quanto **maior a AUC-ROC**, **melhor** é o desempenho do modelo em discriminar corretamente as classes.

![](/images/auc.jpg){.fragment fig-align="center" width="1400px"}


# E como avaliar modelos de predição?

## Avaliação de modelos de predição

<br>

- Seja $d_j$, $j = 1,\cdots, n$, a resposta desejada para o objeto $j$ e $y_j$ a resposta estimada (predita) do algoritmo, obtida a partir de uma entrada $\mathbf{x_j}$ apresentada ao algoritmo.

. . .

- Seja então, $e_j = d_j - y_j$ a diferença entre o valor observado e o valor predito para o objeto $j$.


. . .

- Podemos definir as seguintes métricas para **avaliação de modelos preditivos.**

## Avaliação de modelos de predição

**Erro Quadrático Médio (MSE - Mean Squared Error):**

$$MSE =\dfrac{1}{n} \displaystyle{\sum_{j=1}^n e_j^2}$$

 - **Ponto forte:** Penaliza fortemente erros maiores devido ao termo quadrático. Isso significa que o MSE é sensível a outliers (valores discrepantes).


 - **Ponto fraco:** Como eleva os erros ao quadrado, a unidade da métrica resultante não é a mesma da variável original, o que dificulta a interpretação direta da magnitude do erro.


## Avaliação de modelos de predição

**Raiz do Erro Quadrático Médio (RMSE - Root Mean Squared Error):**

$$RMSE =\sqrt{\dfrac{1}{n} \displaystyle{\sum_{j=1}^n e_j^2}}$$


 - **Ponto forte:** Mantém a propriedade de penalizar erros maiores, mas retorna o erro na mesma unidade da variável original, facilitando a interpretação. É uma métrica amplamente utilizada.


 - **Ponto fraco:** Ainda é sensível a outliers, pois se baseia no MSE.



## Avaliação de modelos de predição

**Erro Médio Absoluto (MAE - Mean Absolute Error):**

$$MAE = \dfrac{1}{n} \displaystyle{\sum_{j=1}^n |e_j|}$$

 - **Ponto forte:** É mais robusto a outliers em comparação com MSE e RMSE, pois não eleva os erros ao quadrado. Fornece uma medida direta da magnitude média dos erros na unidade original da variável.


 - **Ponto fraco:** Não penaliza erros maiores de forma tão intensa quanto o MSE e RMSE. Pode não ser ideal se erros grandes tiverem um impacto significativamente maior no seu problema.




## Avaliação de modelos de predição

**Erro Percentual Absoluto Médio (MAPE - Mean Absolute Percentage Error):**

$$MAPE = \dfrac{1}{n} \displaystyle{\sum_{j=1}^n |e_j/d_j|}\times 100$$

 - **Ponto forte:** É fácil de interpretar, pois expressa o erro em termos percentuais. Isso pode ser útil para comparar o desempenho de modelos em diferentes escalas.


 - **Ponto fraco:** Não é definido quando os valores reais são zero. Além disso, pode ser assimétrico, penalizando mais os erros de previsão abaixo do valor real do que acima. Pode ser instável se houver valores reais muito pequenos.


## Avaliação de modelos de predição

<p align="center">
<span style='font-size:70px;'>&#129300;</span> Qual a melhor métrica?
</p>



**Em resumo:**


- Se você se preocupa muito com grandes erros: MSE e RMSE são boas opções.

. . .

- Se você quer uma métrica robusta a outliers: MAE é uma boa escolha.

. . .

- Se a interpretabilidade em termos percentuais é importante (com cuidado com valores zero/pequenos): MAPE pode ser útil.

. . .


<p align="center">
<span style='font-size:60px;'>&#128161;</span> O ideal é analisar todas as métricas em conjunto, considerando o contexto do seu problema e utilizando validação cruzada.
</p>


## Qual o melhor modelo?


:::: {.columns}

::: {.column width="50%"}

<br>



<span style='font-size:70px;'>&#128073;</span> Suponha que tenhamos dados simulados utilizando o seguinte modelo:

![](/images/predicao/fig01.png){.nostretch fig-align="center" width="800px"}
:::

::: {.column width="50%"}

![](/images/predicao/fig02.png){.nostretch fig-align="center" width="800px"}


:::
::::


## Qual o melhor modelo?


:::: {.columns}

::: {.column width="50%"}

<br>



<span style='font-size:70px;'>&#128073;</span> Podemos estimar diversos modelos $y$ que predizem o verdadeiro valor de $d$


:::

::: {.column width="50%"}

![](/images/predicao/fig03.png){.nostretch fig-align="center" width="800px"}


:::
::::



## Qual o melhor modelo?


:::: {.columns}

::: {.column width="50%"}

<br>



<span style='font-size:70px;'>&#128073;</span> Nosso interesse está em treinar o modelo e avaliar a sua capacidade de generalização


:::

::: {.column width="50%"}

![](/images/predicao/fig04.png){.nostretch fig-align="center" width="800px"}


:::
::::



## Validação holdout



:::: {.columns}

::: {.column width="50%"}

<br>



<span style='font-size:70px;'>&#128073;</span> **Dados originais:** treinamento e teste


<span style='font-size:70px;'>&#128073;</span> **Dados de treinamento:** treinamento e validação

:::

::: {.column width="50%"}

![](/images/predicao/houlout.png){.nostretch fig-align="center" width="800px"}


:::
::::




## Validação holdout



:::: {.columns}

::: {.column width="50%"}

<br>

**Exemplo:** Vamos avaliar a relação entre Frequência Cardíaca e Idade de 270 pacientes


![](/images/predicao/freq.png){.nostretch fig-align="center" width="600px"}

:::

::: {.column width="50%"}

<br>

![](/images/predicao/exemplo.png){.nostretch fig-align="center" width="1200px"}


:::
::::



## Validação holdout

<p align="center">
<span style='font-size:60px;'>&#129300;</span> Qual o melhor modelo nesse caso?
</p>


![](/images/predicao/fig05.png){.nostretch fig-align="center" width="700px"}


## Validação holdout


<p align="center">
<span style='font-size:60px;'>&#128073;</span> 70% da base para treino e 30% para validação
</p>

::: {layout-ncol=2}
![](/images/predicao/fig06.png){.nostretch fig-align="center" width="900px"}

![](/images/predicao/fig07.png){.nostretch fig-align="center" width="900px"}
:::




## Validação cruzada k-fold

<span style='font-size:70px;'>&#128073;</span> **Dados de treinamento:** $k$ partes iguais. **Treina** com $k-1$ partes, e **valida** com uma

![](/images/predicao/cross_validation.png){.nostretch fig-align="center" width="1400px"}



## Validação cruzada k-fold

<br>

::: {layout-ncol=2}
![](/images/predicao/fig08.png){.nostretch fig-align="center" width="900px"}

![](/images/predicao/fig09.png){.nostretch fig-align="center" width="900px"}
:::


## Trade-off bias-variância


Imagine que você está tentando **acertar** um alvo com dardos. Seus arremessos podem ser agrupados de três maneiras diferentes:


- **Grupo de alto viés (bias):** Seus arremessos são **consistentemente agrupados longe do alvo**, mas **próximos uns dos outros**. Isso indica um **alto viés**, pois você está fazendo arremessos incorretos, mas de forma **consistente**.


. . .

- **Grupo de alta variância:** Seus arremessos estão **espalhados por toda a área**, **longe do alvo e uns dos outros**. Isso indica **alta variância**, pois seus arremessos são **inconsistentes e imprevisíveis**. 



. . .


- **Grupo equilibrado:** Seus arremessos estão **agrupados próximo ao alvo** e também estão **próximos uns dos outros**. Isso é o **equilíbrio** entre **viés** e **variância**, onde você está acertando o alvo de forma **consistente** e **precisa**.



## Trade-off bias-variância

![](/images/predicao/bias_variance.png){.nostretch fig-align="center" width="900px"}


## Trade-off bias-variância


<br>


Queremos construir modelos que não apenas performem bem nos dados de treinamento, mas que também façam previsões precisas em dados novos e não vistos.


. . .


O **erro total** de um **modelo preditivo** em dados não vistos pode ser **decomposto em três componentes principais**, ou seja,



$$\text{Erro Total} = \text{Bias}^2 + \text{Variância} + \text{Erro Irredutível}$$



## Trade-off bias-variância

<br>

- **Bias (Viés):** Erro devido a suposições simplificadoras no modelo. Um modelo com alto bias tende a subajustar (underfit) os dados de treinamento, perdendo relações importantes entre as variáveis.


. . .


- **Variância:** Sensibilidade do modelo a pequenas variações nos dados de treinamento. Um modelo com alta variância tende a sobreajustar (overfit) os dados de treinamento, aprendendo até mesmo o ruído presente neles.


. . .

- **Erro Irredutível:** Ruído inerente aos dados que não pode ser reduzido por nenhum modelo.


## O Problema do Subajuste (Underfitting)

<br>

Modelos com **alto bias** fazem suposições fortes sobre a forma da função que mapeia as entradas para as saídas. São tipicamente modelos mais simples, com poucos parâmetros.

. . .


- Consequências:

  - Desempenho ruim tanto nos dados de treinamento quanto nos dados de teste.
  - Incapacidade de capturar a complexidade real dos dados.
  
  
## O Problema do Sobreajuste (Overfitting)

<br>

Modelos com **alta variância** aprendem os dados de treinamento muito bem, incluindo o ruído presente neles. São tipicamente modelos mais complexos, com muitos parâmetros.


- Consequências:

  - Excelente desempenho nos dados de treinamento.
  - Desempenho significativamente pior em dados de teste não vistos. O modelo "decorou" os dados de treinamento em vez de aprender padrões gerais.


## Underfitting e Overfitting

<br>

![](/images/predicao/over_under_good.png){.nostretch fig-align="center" width="1800px"}


## Bias vs. Variância


:::: {.columns}

::: {.column width="50%"}

<br>

<br>

Voltemos ao nosso modelo simulado:


![](/images/predicao/fig01.png){.nostretch fig-align="center" width="600px"}

:::

::: {.column width="50%"}

![](/images/predicao/fig02.png){.nostretch fig-align="center" width="1200px"}


:::
::::



## Bias vs. Variância

<p align="center">
<span style='font-size:60px;'>&#128073;</span> Vamos ajustar um modelo polinomial de **grau 2**
</p>




![](/images/predicao/fig12.png){.nostretch fig-align="center" width="800px"}


## Bias vs. Variância

::: {layout-ncol=2}
![](/images/predicao/fig13.png){.nostretch fig-align="center" width="900px"}

![](/images/predicao/fig14.png){.nostretch fig-align="center" width="900px"}
:::





## Bias vs. Variância

<p align="center">
<span style='font-size:60px;'>&#128073;</span> Vamos ajustar um modelo polinomial de **grau 10**
</p>




![](/images/predicao/fig15.png){.nostretch fig-align="center" width="800px"}


## Bias vs. Variância

::: {layout-ncol=2}
![](/images/predicao/fig16.png){.nostretch fig-align="center" width="900px"}

![](/images/predicao/fig17.png){.nostretch fig-align="center" width="900px"}
:::










## O Tradeoff - A Balança Delicada

<span style='font-size:80px;'>&#128073;</span> **Bias** e **variância** estão **inversamente relacionados**. Tentar reduzir um geralmente aumenta o outro.


. . .

- **Modelos simples** tendem a ter **alto bias e baixa variância**.

- **Modelos complexos** tendem a ter **baixo bias e alta variância**.


. . .

<span style='font-size:80px;'>&#128161;</span> O objetivo é encontrar um modelo com um **bom equilíbrio** entre **bias** e **variância**, que **minimize o erro de generalização**.



## O Tradeoff - A Balança Delicada

<br>

![](/images/predicao/bias-variance_tradeOff.png){.nostretch fig-align="center" width="1800px"}

## Como Lidar com o Tradeoff?

<br>

- **Seleção de Modelos:** Experimentar diferentes tipos de modelos (lineares, não lineares, árvores, redes neurais, etc.).

. . .

- **Ajuste de Hiperparâmetros:**  Controlar a complexidade do modelo ajustando seus hiperparâmetros (ex: profundidade máxima de uma árvore, número de neurônios em uma camada).

. . .


- **Validação Cruzada:** Usar técnicas de validação cruzada para estimar o desempenho do modelo em dados não vistos de forma mais robusta e ajudar a identificar overfitting.

. . .

- **Engenharia de Features:** Criar features mais informativas pode reduzir o bias.


## Como Lidar com o Tradeoff?

<br>

- **Regularização:** Técnicas como L1 e L2 adicionam uma penalidade à complexidade do modelo, ajudando a reduzir a variância (overfitting).


. . .


- **Mais Dados:** Em alguns casos, aumentar a quantidade de dados de treinamento pode ajudar a reduzir a variância.

. . .


- **Ensemble Methods:** Combinar múltiplos modelos (ex: Random Forest, Gradient Boosting) pode ajudar a reduzir tanto o bias quanto a variância.