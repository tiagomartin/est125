---
title: "Análise Preditiva"
format: 
  revealjs:
    width: 1600
    height: 900
    footer: ""
    theme: quartomonothemer.scss
    slide-number: c/t
    show-slide-number: all
incremental: false
code-link: true
bibliography: references.bib
title-slide-attributes:
    data-background-image: /images/back.jpeg
    data-background-size: cover
    data-background-opacity: "0.3"
---


# Machine Learning

## O que é Inteligência Artificial (IA)?

:::: {.columns}
::: {.column width="40%"}

<br>

![](/images/IA.png){fig.align="right" width=120%}
:::

::: {.column width="60%"}

<br>

<p align="center"> 
A capacidade de um **sistema computacional** simular **habilidades cognitivas humanas** 
</p>

<br>


- Visão Computacional

- Processamento de Linguagem Natural

- Robótica 

- Machine Learning
:::
::::


## O que é Inteligência Artificial (IA)?

<br>

![](/images/linha_IA.png){fig.align="center" width=120%}


## O que é Machine Learning?

<p align="center">
Um subcampo da IA que permite que sistemas aprendam a partir de dados, sem serem explicitamente programados
</p>

<br>

![](/images/PT_ML.png){fig.align="center" width=80%}

## O que é Machine Learning?

:::: {.columns}

::: {.column width="20%"}
<span style='font-size:200px;'>&#128202;</span> 
:::

::: {.column width="80%"}
<p align="center">
Do ponto de vista da **Estatística**, Machine Learning (ML) é uma extensão e uma aplicação computacional de métodos estatísticos com um forte **foco em predição** e **descoberta de padrões em dados**, muitas vezes em larga escala e com **menor ênfase na inferência causal tradicional**.
</p>
:::

::::


. . .


:::: {.columns}

::: {.column width="20%"}
<span style='font-size:200px;'>&#128187;</span> 
:::

::: {.column width="80%"}
<p align="center">
Do ponto de vista da **Ciência da Computação**, Machine Learning (ML) é um campo que se concentra no **desenvolvimento de algoritmos** e sistemas computacionais que podem **aprender a partir de dados** para realizar tarefas **sem serem explicitamente programados** para cada uma delas.
</p>
:::

::::


## O que é Machine Learning?

![](/images/est_cc_ML.png){fig.align="center"}

## As duas culturas...

<br>

- **Data Modeling Culture:** Domina a comunidade estatística. Nela se **assume que o modelo utilizado é correto**. Testar suposições é fundamental. **Foco em inferência e na interpretação dos parâmetros**.

. . .

- **Algorithmic Modeling Culture:** Domina a comunidade de machine learning. Nela **não se assume que o modelo utilizado é correto**; **o modelo é utilizado apenas para criar bons algoritmos preditivos**. Podemos interpretar os resultados, mas esse, em geral, não é o foco.


## Exemplos práticos de aplicações de ML no dia a dia.

<br>


-	Sistemas de recomendação (Netflix, Amazon).
-	Filtros de spam (Gmail).
-	Carros autônomos (Tesla).
-	Diagnóstico médico (detecção de tumores).
-	Reconhecimento facial (smartphones).


## Como as Máquinas Aprendem? 

<br>

::: {#fig layout-ncol=2}

![](/images/bike.png){.nostretch fig-align="center" width="800px"}


![](/images/aprendizadoRN.gif){.nostretch fig-align="center" width="1200px"}
:::


## Componentes do aprendizado de máquina

<br>

:::: {.columns}

::: {.column width="60%"}
![https://vas3k.com/blog/machine_learning/](/images/fig07.png){.nostretch fig-align="center" width="700px"}
:::

::: {.column width="40%"}

<br>

<p></p>

- Dados

- Características/Features

- Algoritmos

:::

::::

## O mapa da aprendizagem de máquina

:::: {.columns}

::: {.column width="40%"}
![](/images/fig02a.png){fig.align="center"}
:::

::: {.column width="60%"}

<br>

<p align="center">
&#128073; Nunca há uma única maneira de resolver um problema no mundo do aprendizado de máquina. 

&#128073; Sempre existem vários algoritmos que se encaixam, e você deve escolher qual deles se encaixa melhor. 


&#128073; Tudo pode ser resolvido com uma rede neural? Sim, mas quem pagará por todo esse custo?
</p>



:::

::::


## O mapa da aprendizagem de máquina

![](/images/fig03a.png){.nostretch fig-align="center" width="1200px"}



## Aprendizado de Máquina Clássico


![](/images/tipos_aprend.png){.nostretch fig-align="center" width="1150px"}



## Aprendizado de Máquina Clássico



&#128073; O aprendizado de máquina clássico é frequentemente dividido em duas categorias – **Aprendizado Supervisionado** e **Não Supervisionado**.

. . .


- **Aprendizado Supervisionado:** usa um algoritmo que precisa de exemplos rotulados para desempenhar suas tarefas. 


. . .


- **Aprendizado Não-supervisionado:** os dados não são rotulados, não há professor e a máquina está tentando encontrar padrões por conta própria.



## Aprendizado Supervisionado

<br>

<span style='font-size:80px;'>&#128161;</span> Claramente, a máquina aprenderá mais rápido com um professor. Por isso, é mais comum encontrarmos esse caso nas tarefas da vida real.

. . .


- Existem dois tipos de tarefas: 

    - **classificação:** predição de categoria de um objeto e 
    - **regressão:** predição de um ponto específico em um eixo numérico.
    
    
## Tarefa de classificação

<p align="center">
Os algoritmos de classificação dividem os objetos com base em um dos atributos conhecidos de antemão. 
</p>


:::: {.columns}

::: {.column width="60%"}

<br>

- Usados nos dias de hoje para:

  - Filtragem de spam;
  - Detecção de idioma;
  - Pesquisa por documentos semelhantes;
  - Análise de sentimentos;
  - Reconhecimento de caracteres;
  - Detecção de fraude.

:::

::: {.column width="40%"}

![](/images/fig09.png){.nostretch fig-align="center" width="1000px"}

:::
::::


## Tarefa de classificação

<br>
<br>


<p align="center">
Algoritmos populares: **Naive Bayes**, **Decision Tree**, **Logistic Regression**, **K-Nearest Neighbours**, **Support Vector Machine**.
</p>


## Tarefa de regressão

<p align="center">
Se a variável resposta é quantitativa, temos um problema de análise de regressão 
</p>


:::: {.columns}

::: {.column width="60%"}

<br>

- Usados nos dias de hoje para:

  - Previsões do preço das ações;
  - Análise de demanda e volume de vendas;
  - Diagnóstico médico.

:::

::: {.column width="40%"}

![](/images/fig10.png){.nostretch fig-align="center" width="1000px"}

:::
::::

## Tarefa de regressão

<br>
<br>


<p align="center">
Algoritmos populares: **Decision Tree**, **Regressão Linear** e **Regressão Polinomial**, **K-Nearest Neighbours**, **Support Vector Machine**.
</p>




## Avaliação de modelos


<span style='font-size:80px;'>&#128161;</span>  Independente do modelo escolhido, é importante saber se um modelo de machine learning está realmente funcionando. É aí que entra a **avaliação de modelos**!


:::: {.columns}

::: {.column width="40%"}

![](/images/detetive.jpg){.nostretch fig-align="center" width="1000px"}
:::

::: {.column width="60%"}

<br>

<p align="center">
A **avaliação de modelos** de machine learning é como um **detetive investigando um caso**.
</p>

:::
::::


## Avaliação de modelos

<br>

<br>

::: {layout-ncol=2}

![](/images/over_under.png){.nostretch fig-align="center" width="1000px"}

![](/images/erro_over_under.png){.fragment fig-align="center" width="1000px"}


:::



## Avaliação de modelos



<p align="center" >
<span style='font-size:70px;'>&#129300;</span> O nosso modelo é um **herói** ou um **impostor**?
</p>

![](https://media4.giphy.com/media/ek4CUx2FONgHaMz9V5/giphy-downsized-medium.gif){fig-align="center" width="1000px"}




## Matriz de confusão


Permite a visualização do **desempenho** de um **algoritmo de classificação**

&nbsp;

![](/images/mc.png){.nostretch fig-align="center" width="1000px"}

## Matriz de confusão

<br>

- **VP (Verdadeiro Positivo):** objeto da classe positiva classificado como positivo 

. . .


- **VN (Verdadeiro Negativo):** objeto da classe negativa classificado como negativo

. . .


- **FP (Falso Positivo):** objeto da classe negativa classificado como positivo. Também conhecido como **alarme falso** ou **Erro tipo 1**


. . .


- **FN (Falso Negativo):** objeto da classe positiva classificado como negativo. É também conhecido como **Erro Tipo 2**


## Matriz de confusão

<br> 

**Exemplo:** Sejam as seguintes matrizes de confusão, obtidas de dois classificadores quaisquer.

<br>

::: {layout-ncol=2}

![](/images/mc_cliente.png){.nostretch fig-align="center" width="1000px"}

![](/images/mc_paciente.png){.nostretch fig-align="center" width="1000px"}


:::


# Métricas derivadas da matriz de confusão

## Acurácia

:::: {.columns}

::: {.column width="40%"}

![](/images/acc.jpg){.nostretch fig-align="center" width="400px"}
:::

::: {.column width="60%"}

<br>


<p align="center">
Mede a **proporção de previsões corretas** do modelo em relação ao total de previsões feitas.
</p>

:::
::::


<p align="center">
**É como sua nota em uma prova!**
</p>


## Acurácia

<br>

:::: {.columns}

::: {.column width="50%"}

![](/images/mc.png){.nostretch fig-align="center" width="800px"}
:::

::: {.column width="50%"}

<br>


![](/images/acc_form.jpg){.nostretch fig-align="center" width="800px"}

:::
::::


A **Taxa de Erro Aparente** do classificador é dada por

$$TEA = 1 - ACC$$



## Acurácia

::: {layout-nrow=2}

![](/images/mc_cliente_acc.png){.nostretch fig-align="center" width="1000px"}

![](/images/acc_tea_cliente.png){.nostretch fig-align="center" width="1000px"}

![](/images/mc_paciente_acc.png){.nostretch fig-align="center" width="1000px"}

![](/images/acc_tea_paciente.png){.nostretch fig-align="center" width="1000px"}

:::


## Acurácia


<br>

<br>


<p align="center">
Mas será que a **acurácia** é suficiente para avaliar nossos modelos de forma **precisa**? 
</p>


. . .


<p align="center">
Às vezes, uma **única métrica** não é capaz de nos contar toda a história.
</p>



## Precisão

<br>


:::: {.columns}

::: {.column width="40%"}

![](/images/precision.jpg){.nostretch fig-align="center" width="400px"}
:::

::: {.column width="60%"}

<br>


<p align="center">
Ela nos diz quantas das **previsões positivas** foram realmente **corretas**.
</p>

:::
::::


## Precisão

<br>

:::: {.columns}

::: {.column width="50%"}

![](/images/mc.png){.nostretch fig-align="center" width="800px"}
:::

::: {.column width="50%"}

<br>

![](/images/precision_form.jpg){fig-align="center" width="800px"}

:::
::::



<p align="center">
Porcentagem de verdadeiros positivos dentre todos os objetos classificados como positivos
</p>



## Precisão


::: {layout-nrow=2 layout-valign="bottom"}

![](/images/mc_cliente_prec.png){.nostretch fig-align="center" width="1000px"}

![](/images/prec_form_clientes.jpg){.nostretch fig-align="center" width="1000px"}

![](/images/mc_paciente_prec.png){.nostretch fig-align="center" width="1000px"}

![](/images/prec_form_pacientes.jpg){.nostretch fig-align="center" width="1000px"}

:::



## Sensibilidade


<br>

:::: {.columns}

::: {.column width="50%"}

![](/images/recall.jpg){.nostretch fig-align="center" width="800px"}
:::

::: {.column width="50%"}

<br>


<p align="center">
Mede a **proporção de casos positivos reais** que foram encontrados pelo modelo 
</p>


:::
::::

## Sensibilidade

<br>


:::: {.columns}

::: {.column width="50%"}

![](/images/mc.png){.nostretch fig-align="center" width="800px"}
:::

::: {.column width="50%"}

<br>

![](/images/sens_form.jpg){.nostretch fig-align="center" width="1000px"}

:::
::::

<p align="center">
Também conhecida por **Recall** ou **Taxa de Verdadeiros Positivos (TVP)**
</p>

## Sensibilidade


::: {layout-nrow=2 layout-valign="bottom"}

![](/images/mc_cliente_sens.png){.nostretch fig-align="center" width="1000px"}

![](/images/sens_form_clientes.jpg){.nostretch fig-align="center" width="1000px"}

![](/images/mc_paciente_sens.png){.nostretch fig-align="center" width="1000px"}

![](/images/sens_form_pacientes.jpg){.nostretch fig-align="center" width="1000px"}

:::


## Especificidade

:::: {.columns}

::: {.column width="50%"}

![](/images/espec.jpg){.nostretch fig-align="center" width="600px"}
:::

::: {.column width="50%"}

<br>

<br>

<p align="center">
Ajuda a identificar a capacidade do modelo em reconhecer **corretamente as amostras negativas**   
</p>


:::
::::


## Especificidade

<br>

:::: {.columns}

::: {.column width="50%"}

![](/images/mc.png){.nostretch fig-align="center" width="800px"}
:::

::: {.column width="50%"}

<br>

![](/images/espec_form.jpg){.nostretch fig-align="center" width="800px"}

:::
::::

<p align="center">
Também conhecida por **Taxa de Verdadeiros Negativos (TVN)**
</p>


## Especificidade

::: {layout-nrow=2 layout-valign="bottom"}

![](/images/mc_cliente_espec.png){.nostretch fig-align="center" width="1000px"}

![](/images/espec_form_clientes.jpg){.nostretch fig-align="center" width="1000px"}

![](/images/mc_paciente_espec.png){.nostretch fig-align="center" width="1000px"}

![](/images/espec_form_pacientes.jpg){.nostretch fig-align="center" width="1000px"}

:::


## Taxa de Falso Positivo


:::: {.columns}

::: {.column width="50%"}

<br>

![](/images/fpr.jpg){.nostretch fig-align="center" width="1000px"}
:::

::: {.column width="50%"}

<br>

<br>

<p align="center">
Ela mede a **proporção de amostras negativas** classificadas como positivas pelo modelo  
</p>


:::
::::


## Taxa de Falso Positivo


<br>

:::: {.columns}

::: {.column width="50%"}

![](/images/mc.png){.nostretch fig-align="center" width="800px"}
:::

::: {.column width="50%"}

<br>

![](/images/fpr_form.jpg){.nostretch fig-align="center" width="500px"}

:::
::::


## Taxa de Falso Positivo

::: {layout-nrow=2 layout-valign="bottom"}

![](/images/mc_cliente_espec.png){.nostretch fig-align="center" width="1000px"}

![](/images/fpr_form_clientes.jpg){.nostretch fig-align="center" width="1000px"}

![](/images/mc_paciente_espec.png){.nostretch fig-align="center" width="1000px"}

![](/images/fpr_form_pacientes.jpg){.nostretch fig-align="center" width="1000px"}

:::


## $F_1$-Score

:::: {.columns}

::: {.column width="50%"}

<br>

![](/images/f1.jpg){.nostretch fig-align="center" width="500px"}
:::

::: {.column width="50%"}

<br>

<br>

<br>

<p align="center">
 Ele leva em consideração tanto **precisão** quanto a **sensibilidade**, dando uma medida balanceada do desempenho do modelo.  
</p>


:::
::::


## $F_1$-Score

<br>

<br>

$$F_1 \text{-score} = 2 \times \dfrac{\text{Precisão} \times \text{Sensibilidade}}{\text{Precisão} + \text{Sensibilidade}}$$

<br>

<p align="center">
O $F_1$-Score é como um **equilibrista** em uma corda bamba.
</p>


## Curva ROC

- A **Curva ROC** é como um mapa que nos guia pela **sensibilidade** e pelos **falsos positivos** do modelo em diferentes configurações. 

. . .

- Ela nos mostra o quão bem nosso modelo pode **distinguir** entre as classes.


![](/images/roc.jpg){.fragment fig-align="center" width="700px"}


## Curva ROC


- Representa o número de vezes que o classificador **acertou a predição** contra o número de vezes que o classificador **errou a predição**

. . .


- A área sob a curva ROC, conhecida como **AUC-ROC**, é uma métrica comumente utilizada para avaliar o desempenho global do modelo. 

. . . 

- Quanto **maior a AUC-ROC**, **melhor** é o desempenho do modelo em discriminar corretamente as classes.

![](/images/auc.jpg){.fragment fig-align="center" width="1400px"}


# E como avaliar modelos de predição?

## Avaliação de modelos de predição

<br>

- Seja $d_j$, $j = 1,\cdots, n$, a resposta desejada para o objeto $j$ e $y_j$ a resposta estimada (predita) do algoritmo, obtida a partir de uma entrada $\mathbf{x_j}$ apresentada ao algoritmo.

. . .

- Seja então, $e_j = d_j - y_j$ a diferença entre o valor observado e o valor predito para o objeto $j$.


. . .

- Podemos definir as seguintes métricas para **avaliação de modelos preditivos.**

## Avaliação de modelos de predição

**Erro Quadrático Médio (MSE - Mean Squared Error):**

$$MSE =\dfrac{1}{n} \displaystyle{\sum_{j=1}^n e_j^2}$$

 - **Ponto forte:** Penaliza fortemente erros maiores devido ao termo quadrático. Isso significa que o MSE é sensível a outliers (valores discrepantes).


 - **Ponto fraco:** Como eleva os erros ao quadrado, a unidade da métrica resultante não é a mesma da variável original, o que dificulta a interpretação direta da magnitude do erro.


## Avaliação de modelos de predição

**Raiz do Erro Quadrático Médio (RMSE - Root Mean Squared Error):**

$$RMSE =\sqrt{\dfrac{1}{n} \displaystyle{\sum_{j=1}^n e_j^2}}$$


 - **Ponto forte:** Mantém a propriedade de penalizar erros maiores, mas retorna o erro na mesma unidade da variável original, facilitando a interpretação. É uma métrica amplamente utilizada.


 - **Ponto fraco:** Ainda é sensível a outliers, pois se baseia no MSE.



## Avaliação de modelos de predição

**Erro Médio Absoluto (MAE - Mean Absolute Error):**

$$MAE = \dfrac{1}{n} \displaystyle{\sum_{j=1}^n |e_j|}$$

 - **Ponto forte:** É mais robusto a outliers em comparação com MSE e RMSE, pois não eleva os erros ao quadrado. Fornece uma medida direta da magnitude média dos erros na unidade original da variável.


 - **Ponto fraco:** Não penaliza erros maiores de forma tão intensa quanto o MSE e RMSE. Pode não ser ideal se erros grandes tiverem um impacto significativamente maior no seu problema.




## Avaliação de modelos de predição

**Erro Percentual Absoluto Médio (MAPE - Mean Absolute Percentage Error):**

$$MAPE = \dfrac{1}{n} \displaystyle{\sum_{j=1}^n |e_j/d_j|}\times 100$$

 - **Ponto forte:** É fácil de interpretar, pois expressa o erro em termos percentuais. Isso pode ser útil para comparar o desempenho de modelos em diferentes escalas.


 - **Ponto fraco:** Não é definido quando os valores reais são zero. Além disso, pode ser assimétrico, penalizando mais os erros de previsão abaixo do valor real do que acima. Pode ser instável se houver valores reais muito pequenos.


## Avaliação de modelos de predição

<p align="center">
<span style='font-size:70px;'>&#129300;</span> Qual a melhor métrica?
</p>



**Em resumo:**


- Se você se preocupa muito com grandes erros: MSE e RMSE são boas opções.

. . .

- Se você quer uma métrica robusta a outliers: MAE é uma boa escolha.

. . .

- Se a interpretabilidade em termos percentuais é importante (com cuidado com valores zero/pequenos): MAPE pode ser útil.

. . .


<p align="center">
<span style='font-size:60px;'>&#128161;</span> O ideal é analisar todas as métricas em conjunto, considerando o contexto do seu problema e utilizando validação cruzada.
</p>


## Qual o melhor modelo?


:::: {.columns}

::: {.column width="50%"}

<br>



<span style='font-size:70px;'>&#128073;</span> Suponha que tenhamos dados simulados utilizando o seguinte modelo:

![](/images/predicao/fig01.png){.nostretch fig-align="center" width="800px"}
:::

::: {.column width="50%"}

![](/images/predicao/fig02.png){.nostretch fig-align="center" width="800px"}


:::
::::


## Qual o melhor modelo?


:::: {.columns}

::: {.column width="50%"}

<br>



<span style='font-size:70px;'>&#128073;</span> Podemos estimar diversos modelos $y$ que predizem o verdadeiro valor de $d$


:::

::: {.column width="50%"}

![](/images/predicao/fig03.png){.nostretch fig-align="center" width="800px"}


:::
::::



## Qual o melhor modelo?


:::: {.columns}

::: {.column width="50%"}

<br>



<span style='font-size:70px;'>&#128073;</span> Nosso interesse está em treinar o modelo e avaliar a sua capacidade de generalização


:::

::: {.column width="50%"}

![](/images/predicao/fig04.png){.nostretch fig-align="center" width="800px"}


:::
::::



## Validação holdout



:::: {.columns}

::: {.column width="50%"}

<br>



<span style='font-size:70px;'>&#128073;</span> **Dados originais:** treinamento e teste


<span style='font-size:70px;'>&#128073;</span> **Dados de treinamento:** treinamento e validação

:::

::: {.column width="50%"}

![](/images/predicao/houlout.png){.nostretch fig-align="center" width="800px"}


:::
::::




## Validação holdout



:::: {.columns}

::: {.column width="50%"}

<br>

**Exemplo:** Vamos avaliar a relação entre Frequência Cardíaca e Idade de 270 pacientes


![](/images/predicao/freq.png){.nostretch fig-align="center" width="600px"}

:::

::: {.column width="50%"}

<br>

![](/images/predicao/exemplo.png){.nostretch fig-align="center" width="1200px"}


:::
::::



## Validação holdout

<p align="center">
<span style='font-size:60px;'>&#129300;</span> Qual o melhor modelo nesse caso?
</p>


![](/images/predicao/fig05.png){.nostretch fig-align="center" width="700px"}


## Validação holdout


<p align="center">
<span style='font-size:60px;'>&#128073;</span> 70% da base para treino e 30% para validação
</p>

::: {layout-ncol=2}
![](/images/predicao/fig06.png){.nostretch fig-align="center" width="900px"}

![](/images/predicao/fig07.png){.nostretch fig-align="center" width="900px"}
:::




## Validação cruzada k-fold

<span style='font-size:70px;'>&#128073;</span> **Dados de treinamento:** $k$ partes iguais. **Treina** com $k-1$ partes, e **valida** com uma

![](/images/predicao/cross_validation.png){.nostretch fig-align="center" width="1400px"}



## Validação cruzada k-fold

<br>

::: {layout-ncol=2}
![](/images/predicao/fig08.png){.nostretch fig-align="center" width="900px"}

![](/images/predicao/fig09.png){.nostretch fig-align="center" width="900px"}
:::


## Trade-off bias-variância


Imagine que você está tentando **acertar** um alvo com dardos. Seus arremessos podem ser agrupados de três maneiras diferentes:


- **Grupo de alto viés (bias):** Seus arremessos são **consistentemente agrupados longe do alvo**, mas **próximos uns dos outros**. Isso indica um **alto viés**, pois você está fazendo arremessos incorretos, mas de forma **consistente**.


. . .

- **Grupo de alta variância:** Seus arremessos estão **espalhados por toda a área**, **longe do alvo e uns dos outros**. Isso indica **alta variância**, pois seus arremessos são **inconsistentes e imprevisíveis**. 



. . .


- **Grupo equilibrado:** Seus arremessos estão **agrupados próximo ao alvo** e também estão **próximos uns dos outros**. Isso é o **equilíbrio** entre **viés** e **variância**, onde você está acertando o alvo de forma **consistente** e **precisa**.



## Trade-off bias-variância

![](/images/predicao/bias_variance.png){.nostretch fig-align="center" width="900px"}


## Trade-off bias-variância


<br>


Queremos construir modelos que não apenas performem bem nos dados de treinamento, mas que também façam previsões precisas em dados novos e não vistos.


. . .


O **erro total** de um **modelo preditivo** em dados não vistos pode ser **decomposto em três componentes principais**, ou seja,



$$\text{Erro Total} = \text{Bias}^2 + \text{Variância} + \text{Erro Irredutível}$$



## Trade-off bias-variância

<br>

- **Bias (Viés):** Erro devido a suposições simplificadoras no modelo. Um modelo com alto bias tende a subajustar (underfit) os dados de treinamento, perdendo relações importantes entre as variáveis.


. . .


- **Variância:** Sensibilidade do modelo a pequenas variações nos dados de treinamento. Um modelo com alta variância tende a sobreajustar (overfit) os dados de treinamento, aprendendo até mesmo o ruído presente neles.


. . .

- **Erro Irredutível:** Ruído inerente aos dados que não pode ser reduzido por nenhum modelo.


## O Problema do Subajuste (Underfitting)

<br>

Modelos com **alto bias** fazem suposições fortes sobre a forma da função que mapeia as entradas para as saídas. São tipicamente modelos mais simples, com poucos parâmetros.

. . .


- Consequências:

  - Desempenho ruim tanto nos dados de treinamento quanto nos dados de teste.
  - Incapacidade de capturar a complexidade real dos dados.
  
  
## O Problema do Sobreajuste (Overfitting)

<br>

Modelos com **alta variância** aprendem os dados de treinamento muito bem, incluindo o ruído presente neles. São tipicamente modelos mais complexos, com muitos parâmetros.


- Consequências:

  - Excelente desempenho nos dados de treinamento.
  - Desempenho significativamente pior em dados de teste não vistos. O modelo "decorou" os dados de treinamento em vez de aprender padrões gerais.


## Underfitting e Overfitting

<br>

![](/images/predicao/over_under_good.png){.nostretch fig-align="center" width="1800px"}


## Bias vs. Variância


:::: {.columns}

::: {.column width="50%"}

<br>

<br>

Voltemos ao nosso modelo simulado:


![](/images/predicao/fig01.png){.nostretch fig-align="center" width="600px"}

:::

::: {.column width="50%"}

![](/images/predicao/fig02.png){.nostretch fig-align="center" width="1200px"}


:::
::::



## Bias vs. Variância

<p align="center">
<span style='font-size:60px;'>&#128073;</span> Vamos ajustar um modelo polinomial de **grau 2**
</p>




![](/images/predicao/fig12.png){.nostretch fig-align="center" width="800px"}


## Bias vs. Variância

::: {layout-ncol=2}
![](/images/predicao/fig13.png){.nostretch fig-align="center" width="900px"}

![](/images/predicao/fig14.png){.nostretch fig-align="center" width="900px"}
:::





## Bias vs. Variância

<p align="center">
<span style='font-size:60px;'>&#128073;</span> Vamos ajustar um modelo polinomial de **grau 10**
</p>




![](/images/predicao/fig15.png){.nostretch fig-align="center" width="800px"}


## Bias vs. Variância

::: {layout-ncol=2}
![](/images/predicao/fig16.png){.nostretch fig-align="center" width="900px"}

![](/images/predicao/fig17.png){.nostretch fig-align="center" width="900px"}
:::










## O Tradeoff - A Balança Delicada

<span style='font-size:80px;'>&#128073;</span> **Bias** e **variância** estão **inversamente relacionados**. Tentar reduzir um geralmente aumenta o outro.


. . .

- **Modelos simples** tendem a ter **alto bias e baixa variância**.

- **Modelos complexos** tendem a ter **baixo bias e alta variância**.


. . .

<span style='font-size:80px;'>&#128161;</span> O objetivo é encontrar um modelo com um **bom equilíbrio** entre **bias** e **variância**, que **minimize o erro de generalização**.



## O Tradeoff - A Balança Delicada

<br>

![](/images/predicao/bias-variance_tradeOff.png){.nostretch fig-align="center" width="1800px"}

## Como Lidar com o Tradeoff?

<br>

- **Seleção de Modelos:** Experimentar diferentes tipos de modelos (lineares, não lineares, árvores, redes neurais, etc.).

. . .

- **Ajuste de Hiperparâmetros:**  Controlar a complexidade do modelo ajustando seus hiperparâmetros (ex: profundidade máxima de uma árvore, número de neurônios em uma camada).

. . .


- **Validação Cruzada:** Usar técnicas de validação cruzada para estimar o desempenho do modelo em dados não vistos de forma mais robusta e ajudar a identificar overfitting.

. . .

- **Engenharia de Features:** Criar features mais informativas pode reduzir o bias.


## Como Lidar com o Tradeoff?

<br>

- **Regularização:** Técnicas como L1 e L2 adicionam uma penalidade à complexidade do modelo, ajudando a reduzir a variância (overfitting).


. . .


- **Mais Dados:** Em alguns casos, aumentar a quantidade de dados de treinamento pode ajudar a reduzir a variância.

. . .


- **Ensemble Methods:** Combinar múltiplos modelos (ex: Random Forest, Gradient Boosting) pode ajudar a reduzir tanto o bias quanto a variância.



# Algoritmos de predição

## Algoritmos de predição

<br>

- Algoritmos mais comuns usados para problemas de predição:

  - K-Nearest Neighbors (KNN)
  - Naive Bayes
  - Árvores de decisão
  - Random Forests
  - Máquinas de Vetores de Suporte (SVM)
  - Redes Neurais Artificiais (ANN)
  

##  K-Nearest Neighbors (KNN) 

<br>

O KNN é um algoritmo de aprendizado supervisionado de classificação e regressão, que usa a proximidade dos objetos para classificar novas instâncias.


. . .

É um dos algoritmos mais simples e intuitivos de aprendizado de máquina. Utiliza a ideia do **vizinho mais próximo**, o que significa que ele determina a classe de uma instância com base nas classes de seus vizinhos mais próximos.

. . .

Em outras palavras, se a maioria dos vizinhos mais próximos de uma instância pertence a uma classe específica, então a instância também é classificada como pertencente a essa classe.


## Algoritmo KNN

![](/images/knn/knn.png){.nostretch fig-align="center" width="900px"}


##  Algoritmo KNN

<br>

KNN é usado para problemas de classificação e regressão.


. . .


  - Em problemas de **classificação**, a classe mais comum entre os K vizinhos mais próximos é escolhida como a classe da nova instância.

. . .

  - Em problemas de **regressão**, a média ou mediana dos valores alvo dos K vizinhos mais próximos é escolhida como o valor alvo da nova instância.


## A escolha do valor de K

<br>

O valor de K é um **parâmetro** importante em KNN. Ele determina o **número de vizinhos mais próximos** que são usados para classificar uma nova instância.

. . .


Um valor de K pequeno pode levar a um modelo muito **sensível** ao **ruído** nos dados (overfitting), enquanto um valor grande de K pode levar a uma **perda** de detalhes importantes nos dados (underfitting).


. . .

A escolha do valor K ideal é frequentemente realizada por meio de técnicas de **validação cruzada**. 

. . .


K ímpar evita empates.



  


## Métricas de Distância

- **Distância Euclidiana:** A mais comum. 

$$d_{ij} = \displaystyle{\sqrt{(\mathbf{x}_i - \mathbf{x}_j)^t(\mathbf{x}_i - \mathbf{x}_j)}} = \sqrt{\displaystyle{\sum_{k=1}^p(x_{ik} - x_{jk})^2}}$$

- **Distância de Minkowski:** Soma das diferenças absolutas entre as coordenadas. 

$$d_{ij} = \left( \displaystyle{\sum_{k=1}^P} |X_{ik} - X_{jk}|^{\lambda}\right)^{\frac{1}{\lambda}}$$

## Métricas de Distância

<br>

- Para a distância de Minkowski:

  - Se $\lambda = 1$, temos a chamada **métrica de Manhattan**. É também conhecida como *city block*.  
  - Se $\lambda = 2$, temos a distância euclidiana.
  - A métrica de Minkowski é menos afetada pela presença de valores discrepantes na amostra do que a distância Euclidiana.

. . .


- Se os dados forem textuais: usar cosseno


## Vantagens e Desvantagens

<br>

:::: {.columns}

::: {.column width="10%"}
<span style='font-size:130px;'>&#128077;</span>
:::

::: {.column width="90%"}
  -	Simples de entender e implementar.
  -	Não faz muitas suposições sobre os dados (não paramétrico).
  -	Útil para dados complexos e não lineares.
  -	Pode ser usado tanto para classificação quanto para regressão.
:::

::::

## Vantagens e Desvantagens

<br>

:::: {.columns}

::: {.column width="10%"}

<br>

<span style='font-size:130px;'>&#128078;</span>
:::

::: {.column width="90%"}
  -	Computacionalmente caro para grandes conjuntos de dados (cálculo de distância para todos os pontos).
  -	Sensível à escala dos dados (variáveis com escalas maiores podem dominar o cálculo da distância) - importância da normalização/padronização.
  -	Desempenho pode degradar em dados com muitas dimensões (maldição da dimensionalidade).
  - Escolha do valor de k pode ser crucial e não é trivial.

:::

::::



## Pré-processamento de Dados para KNN


<br>

:::: {.columns}

::: {.column width="10%"}

<span style='font-size:130px;'>&#128187;</span>
:::

::: {.column width="90%"}
  -	**Escalonamento de features:** Padronização (média zero, desvio padrão um) ou normalização (escala entre 0 e 1) para garantir que todas as features contribuam igualmente para o cálculo da distância.
  -	**Tratamento de valores ausentes:** Imputação ou remoção.
  - **Seleção de features:** Reduzir a dimensionalidade para melhorar o desempenho.


:::

::::


## Exemplo: Compra de um computador


![](/images/knn/tabela.jpg){.nostretch fig-align="center" width="1300px"}

## Exemplo: Compra de um computador


:::: {.columns}

::: {.column width="40%"}

![](/images/joao.png){.nostretch fig-align="center" width="1300px"}
:::

::: {.column width="60%"}

<br>

João possui as seguintes características

- menos de 30 anos
- renda média
- é estudante
- possuí um bom crédito na praça!


:::

::::


## Exemplo: Compra de um computador 

<p align="center">
João **compraria** ou **não compraria** o computador?
</p>


![](https://media2.giphy.com/media/XeH1MFu4x3etVsllUN/giphy.gif){.nostretch fig-align="center" width="1100px"}  



## Exemplo: Compra de um computador


:::: {.columns}

::: {.column width="40%"}

![](/images/joao.png){.nostretch fig-align="center" width="1300px"}
:::

::: {.column width="60%"}

<br>

<p align="center" style="font-size: 76px">**Quem é o João?**</p>

&nbsp;
&nbsp;

::: {.fragment}
<p align="center" style="font-size: 56px">$x_0 = (\leq 30, \text{ Média}, \text{ Sim}, \text{ Bom})$</p>
:::


:::

::::


## Exemplo: Compra de um computador 

<p align="center">
Usando o classificador KNN com k = 5
</p>


![](/images/knn/tab_dist.jpg){.nostretch fig-align="center" width="1100px"}



## Exemplo: Compra de um computador 

<br>

Temos então que os **5 vizinhos** mais próximos a João são

 \s\s

:::: {.columns}

::: {.column width="10%"}
<span style='font-size:130px;'>&#x274C;</span>
:::

::: {.column width="90%"}

 \s\s

- <p style="color: red">$x_2 = \{\leq 30, \text{ Alta}, \text{ Sim}, \text{ Bom}\}$</p>
- <p style="color: red">$x_8 = \{\leq 30, \text{Média}, \text{ Não}, \text{ Bom}\}$</p>

:::

::::

. . .

:::: {.columns}

::: {.column width="10%"}

<span style='font-size:130px;'>&#x2705;</span>
:::

::: {.column width="90%"}


 
- <p style="color: green">$x_9 = \{\leq 30, \text{ Baixa}, \text{ Sim}, \text{ Bom}\}$</p>
- <p style="color: green">$x_{10} = \{> 40, \text{ Média}, \text{ Sim}, \text{ Excelente}\}$</p>
- <p style="color: green">$x_{11} = \{\leq 30, \text{ Média}, \text{ Sim}, \text{ Excelente}\}$</p>
:::

::::


## Exemplo: Compra de um computador 

<br>

<br>


<details>
  <summary align="center" style='font-size:80px;'>**João comprará o computador?**</summary>
  <p align="center" style="color: green; font-size:80px;"> **De acordo com o KNN: SIM!** </p>
</details>


## KNN para classificação no R e Python

```{r include = FALSE}
library(reticulate)
reticulate::conda_list()
use_condaenv("py3.8", required = TRUE)
py_config()
```


::: {.panel-tabset}

### R

```{r}
#| echo: true

library(tidymodels)
library(Metrics)

set.seed(12345)
data(iris)
iris_split <- initial_split(iris, strata = Species)
train_data <- training(iris_split)
test_data <- testing(iris_split)

knn_spec <- nearest_neighbor(neighbors = 5) %>% 
  set_engine("kknn") %>%
  set_mode("classification")

knn_fit <- workflow() %>%
  add_model(knn_spec) %>%
  add_formula(Species ~ .) %>%
  fit(data = train_data)

sp_predict <- predict(knn_fit, test_data)

Metrics::accuracy(test_data$Species, sp_predict$.pred_class)
```

### Python

```{python}
#| echo: true

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(
    iris.data, iris.target, stratify=iris.target, random_state=12345
)

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)
accuracy_score(y_test, y_pred)
```

:::

## KNN para regressão no R e Python


::: {.panel-tabset}

### R

```{r}
#| echo: true

library(tidymodels)
library(Metrics)

data("mtcars")
set.seed(12345)
mtcars_split <- initial_split(mtcars, strata = mpg)
train_data <- training(mtcars_split)
test_data <- testing(mtcars_split)

knn_spec <- nearest_neighbor(neighbors = 5) %>%
  set_engine("kknn") %>%
  set_mode("regression")

knn_fit <- workflow() %>%
  add_model(knn_spec) %>%
  add_formula(mpg ~ .) %>%
  fit(data = train_data)

mpg_predict <- predict(knn_fit, test_data)

Metrics::mse(test_data$mpg, mpg_predict$.pred) # MSE
```

### Python

```{python}
#| echo: true

from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error

data = fetch_california_housing()
X_train, X_test, y_train, y_test = train_test_split(
    data.data, data.target, random_state=12345
)

knn_reg = KNeighborsRegressor(n_neighbors=5)
knn_reg.fit(X_train, y_train)
y_pred = knn_reg.predict(X_test)
mean_squared_error(y_test, y_pred, squared=True)  # MSE
```

:::


## Algoritmo Naive Bayes

<br>


Baseia-se no **Teorema de Bayes**, que afirma que a probabilidade de um evento ocorrer dado que outro evento já ocorreu é proporcional à probabilidade deste último evento ocorrer dado o primeiro.

. . .

A "ingenuidade" (Naive): assume que os preditores são independentes entre si, dado o valor da classe.

. . . 

Aplicado principalmente em problemas de classificação, especialmente com dados categóricos ou textuais.


##  Revisão do Teorema de Bayes

Sejam A e B dois eventos

$$P(A|B) = \dfrac{P(B|A)P(A)}{P(B)},\,\,\,\,\,\,\, \text{para } P(B)>0$$


. . .

O Teorema de Bayes Aplicado ao Naive Bayes:

$$P(\text{Classe}|\text{Características}) = \dfrac{P(\text{Características}|\text{Classe})P(\text{Classe})}{P(\text{Características})}$$


. . . 

<p align="center">
<span style='font-size:80px;'>&#128073;</span>O objetivo é encontrar a classe com a **maior probabilidade posterior**.
</p>


## O Teorema de Bayes Aplicado ao Naive Bayes

Devido a essa suposição de independência condicional, a probabilidade das características conjuntas dado a classe pode ser simplificada para o produto das probabilidades de cada característica individual dado a classe:

$$P(X_1, X_2,\cdots, X_n|\text{Classe}) = P(X_1|\text{Classe}) \times P(X_2|\text{Classe}) \times \cdots \times P(X_n|\text{Classe})$$

. . .

Substituindo na fórmula de Bayes, nos leva a

$$P(\text{Classe}|\text{Características}) \propto P(\text{Classe}) \times \prod_{i=1}^n P(X_i|\text{Classe})$$


**Observação importante:** O denominador $P(\text{Características})$ é constante para todas as classes, então podemos ignorá-lo para fins de comparação


## Tipos de Naive Bayes

<br>

- **Gaussian Naive Bayes:** Para características contínuas. Assume que as características são distribuídas de acordo com uma distribuição Gaussiana (Normal).

. . . 

- **Multinomial Naive Bayes:** Ideal para contagens de ocorrências (ex: contagem de palavras em documentos, usado em classificação de texto).

. . .

- **Bernoulli Naive Bayes:** Adequado para dados binários (presença/ausência de uma característica).




## Vantagens e Desvantagens

<br>

:::: {.columns}

::: {.column width="10%"}

<br>

<span style='font-size:160px;'>&#128077;</span>
:::

::: {.column width="90%"}
  -	**Simplicidade:** Fácil de entender e implementar.
  - **Eficiência:** Muito rápido para treinar e prever, especialmente em grandes conjuntos de dados.
  - **Bom desempenho:** Surpreendentemente eficaz em muitos problemas reais, mesmo com a suposição de independência.
  - **Processamento de texto:** Excelente para classificação de documentos e filtragem de spam.
  - **Não requer muitos dados:** Pode funcionar bem com conjuntos de dados menores.
:::

::::

## Vantagens e Desvantagens

<br>

:::: {.columns}

::: {.column width="10%"}

<br>

<span style='font-size:160px;'>&#128078;</span>
:::

::: {.column width="90%"}
  -	**Suposição de independência:** A suposição de independência entre as características raramente é verdadeira no mundo real, o que pode limitar a precisão.
  - **Problema de "zero frequência":** Se uma categoria de característica não aparecer no conjunto de treinamento para uma determinada classe, a probabilidade para essa característica será zero, o que leva a uma probabilidade posterior zero. (para resolver: Laplace Smoothing)
  - **Estimativa de Probabilidades:** Pode ter um desempenho ruim quando há características numéricas com distribuições complexas (a suposição Gaussiana pode não se aplicar).

:::

::::



## Pré-processamento de Dados para Naive Bayes




:::: {.columns}

::: {.column width="10%"}

<br>

<span style='font-size:160px;'>&#128187;</span>
:::

::: {.column width="90%"}
  -	**Dados Categóricos:** Transformar para formato numérico (One-Hot Encoding ou Label Encoding, dependendo do tipo de NB).
  - **Dados Numéricos:**
    - **GaussianNB:** Assumir distribuição normal. Normalização/padronização pode ajudar, mas não é estritamente necessária como em KNN, já que não se baseia em distância.
    - **Discretização:** Converter dados numéricos em categóricos (bins) para usar Multinomial ou Bernoulli NB.
  - **Tratamento de Valores Ausentes:** Imputação ou remoção.
  - **Textuais:** Tokenização, remoção de stop words, stemização/lema, TF-IDF, CountVectorizer.


:::

::::






## Exemplo: Compra de um computador


![](/images/knn/tabela.jpg){.nostretch fig-align="center" width="1300px"}




## Exemplo: Compra de um computador


:::: {.columns}

::: {.column width="40%"}

![](/images/joao.png){.nostretch fig-align="center" width="1300px"}
:::

::: {.column width="60%"}

<br>

<p align="center" style="font-size: 76px">**Voltando ao Joãozinho...**</p>

&nbsp;
&nbsp;

::: {.fragment}
<p align="center" style="font-size: 56px">$x_0 = (\leq 30, \text{ Média}, \text{ Sim}, \text{ Bom})$</p>
:::


:::

::::


## Exemplo: Compra de um computador

:::: {.columns}

::: {.column width="50%"}

<br>


![](/images/knn/tabela.jpg){fig-align="center"}
:::

::: {.column width="50%"}

<br>

<p align="center">**Probabilidade de ocorrência das classes**</p>

::: {.fragment}
$$ P(\text{classe = Sim}) = \dfrac{9}{14}$$ 
$$P(\text{classe = Não}) = \dfrac{5}{14}$$
:::


:::

::::


## Exemplo: Compra de um computador

:::: {.columns}

::: {.column width="50%"}

<br>


![](/images/knn/tabela.jpg){fig-align="center"}
:::

::: {.column width="50%"}

<br>

<p align="center">$x_0 = (\leq 30, \text{ Média}, \text{ Sim}, \text{ Bom})$</p>

::: {.fragment}
Para o atributo **Idade**:

$$ P(\text{Idade} \leq 30 | \text{classe = Sim}) = \dfrac{2}{9} \\ P(\text{Idade} \leq 30 | \text{classe = Não}) = \dfrac{3}{5}$$
:::


:::

::::


## Exemplo: Compra de um computador

:::: {.columns}

::: {.column width="50%"}

<br>


![](/images/knn/tabela.jpg){fig-align="center"}
:::

::: {.column width="50%"}

<br>

<p align="center">$x_0 = (\leq 30, \text{ Média}, \text{ Sim}, \text{ Bom})$</p>

::: {.fragment}
Para o atributo **Renda**:

$$ P(\text{Renda = Média} | \text{classe = Sim}) = \dfrac{4}{9} \\ P(\text{Renda = Média} | \text{classe = Não}) = \dfrac{2}{5}$$
:::


:::

::::



## Exemplo: Compra de um computador

:::: {.columns}

::: {.column width="50%"}

<br>


![](/images/knn/tabela.jpg){fig-align="center"}
:::

::: {.column width="50%"}

<br>

<p align="center">$x_0 = (\leq 30, \text{ Média}, \text{ Sim}, \text{ Bom})$</p>

::: {.fragment}
Para o atributo **Estudante**:

$$ P(\text{Estudante = Sim} | \text{classe = Sim}) = \dfrac{6}{9} \\ P(\text{Estudante = Sim} | \text{classe = Não}) = \dfrac{2}{5}$$
:::


:::

::::



## Exemplo: Compra de um computador

:::: {.columns}

::: {.column width="50%"}

<br>


![](/images/knn/tabela.jpg){fig-align="center"}
:::

::: {.column width="50%"}

<br>

<p align="center">$x_0 = (\leq 30, \text{ Média}, \text{ Sim}, \text{ Bom})$</p>

::: {.fragment}
Para o atributo **Crédito**:

$$ P(\text{Crédito = Bom} | \text{classe = Sim}) = \dfrac{6}{9} \\ P(\text{Crédito = Bom} | \text{classe = Não}) = \dfrac{3}{5}$$
:::


:::

::::



## Exemplo: Compra de um computador

Temos então, sob independência:


$$P(x_0|\text{Sim}) = P(\leq 30 \cap \text{Média} \cap \text{Sim} \cap \text{Bom}|\text{Sim} ) \\ = \dfrac{2}{9} \times \dfrac{4}{9}\times \dfrac{6}{9}\times \dfrac{6}{9} = \dfrac{288}{729} = 0,0439\\$$


. . .


e, 


$$P(x_0|\text{Não}) = P(\leq 30 \cap \text{Média} \cap \text{Sim} \cap \text{Bom}|\text{Não} ) \\ = \dfrac{3}{5} \times \dfrac{2}{5}\times \dfrac{2}{5}\times \dfrac{3}{5} = \dfrac{36}{625} = 0,0576\\$$



## Exemplo: Compra de um computador


Pelo Teorema da Probabilidade Total:

$$
\begin{eqnarray*}
P(x_0) &=& P(x_0|\text{Sim}) \times P(\text{Sim}) + P(x_0|\text{Não}) \times P(\text{Não}) \\ &=& 0,0439 \times 0,6429 + 0,0576 \times 0,3571 \\ &=& 0,0488
\end{eqnarray*}
$$

. . .


Assim, pelo Teorema de Bayes:

$$P(\text{Sim}|x_0) = \dfrac{P(x_0|\text{Sim}) \times P(\text{Sim})}{P(x_0)} = \dfrac{0,0439 \times 0,6429}{0,0488} = 0,5783$$

## Exemplo: Compra de um computador

e, 

$$P(\text{Não}|x_0) = \dfrac{P(x_0|\text{Não}) \times P(\text{Não})}{P(x_0)} = \dfrac{0,0576 \times 0,3571}{0,0488} = 0,4215 \\ $$


## Exemplo: Compra de um computador 

<br>

<br>


<details>
  <summary align="center" style='font-size:80px;'>**João comprará o computador?**</summary>
  <p align="center" style="color: green; font-size:80px;"> **De acordo com o Naive Bayes: SIM!** </p>
</details>


## Naive Bayes para classificação no R e Python

::: {.panel-tabset}

### R

```{r}
#| echo: true

library(tidymodels)
library(discrim)
library(Metrics)

set.seed(12345)
data(iris)
iris_split <- initial_split(iris, strata = Species)
train_data <- training(iris_split)
test_data <- testing(iris_split)

nb_model <- naive_Bayes() %>% 
  set_engine("klaR") %>%
  set_mode("classification")

nb_fit <- workflow() %>%
  add_model(nb_model) %>%
  add_formula(Species ~ .) %>%
  fit(data = train_data)

sp_predict <- predict(nb_fit, new_data = test_data)

Metrics::accuracy(test_data$Species, sp_predict$.pred_class)
```

### Python

```{python}
#| echo: true

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB # Para dados contínuos como Iris
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.datasets import load_iris # Para carregar o dataset Iris

iris = load_iris()
X = pd.DataFrame(iris.data, columns=iris.feature_names)
y = pd.Series(iris.target_names[iris.target], name='species') # Mapear números para nomes de espécies

# Split dos dados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)

model_nb = GaussianNB()
model_nb.fit(X_train, y_train)
y_pred = model_nb.predict(X_test)
accuracy_score(y_test, y_pred)
```

:::




## Árvores de decisão

<br>

Uma **árvore de decisão** é um modelo de aprendizado de máquina que utiliza uma estrutura de árvore para tomar decisões com base em condições nos dados de entrada. 


. . .

Essa estrutura hierárquica consiste em nós que representam **testes** sobre atributos e arestas que conectam os nós, indicando os resultados desses testes.


. . .


Cada **nó interno** da árvore representa um teste em um atributo específico, enquanto as **folhas** representam as classes ou valores de saída. 





## Árvores de decisão


:::: {.columns}
::: {.column width="50%"}
![](/images/ad/ad.png){.nostretch fig-align="center" width="1000px"}
:::

::: {.column width="50%"}

<br>

<p align="center">Ao percorrer a árvore da raiz até uma folha, os dados de entrada são avaliados de acordo com os testes em cada nó, seguindo o caminho apropriado até alcançar uma folha, onde é tomada a decisão final.</p>
:::
::::


## Principais Algoritmos 


<br>


<p align="center">
**ID3 (Iterative Dichotomiser 3)** 
</p>

- É um dos primeiros algoritmos de árvore de decisão e utiliza o **ganho de informação** como critério para selecionar a melhor divisão em cada nó. No entanto, o ID3 não lida diretamente com **atributos numéricos**.

. . .


- Favorece características com muitos valores distintos.


## Principais Algoritmos 


<br>


<p align="center">
**C4.5**
</p>

- É uma extensão do ID3 e possui melhorias, incluindo a capacidade de lidar com **atributos numéricos** e **valores ausentes**. Além disso, o C4.5 utiliza a **razão de ganho** como métrica de seleção de atributos, em vez do ganho de informação utilizado pelo ID3.

. . .

- Corrige o viés em relação a características com muitos valores.



## Principais Algoritmos 


<br>


<p align="center">
**CART (Classification and Regression Trees)**
</p>

- Pode ser usado tanto para classificação quanto para regressão.

. . .

- Para classificação, usa o índice de Gini como critério de divisão.

. . .

- Gera árvores binárias (cada nó tem exatamente dois filhos). 


. . .

- Ele busca minimizar a **impureza** nos nós da árvore.




## Principais Algoritmos 


<br>


<p align="center">
**CART (Classification and Regression Trees)**
</p>

- Para regressão, busca dividir os dados de forma a minimizar o erro quadrático médio (MSE) ou o desvio absoluto médio (MAE) nos nós folha.


## Processo de preparação de um modelo de Árvore de Decisão

<br>

![](/images/ad/processo.jpg){.nostretch fig-align="center" width="1800px"}



## Critérios de Divisão para Classificação

<br>

<br>

<p align="center">
O objetivo dos critérios de divisão é encontrar a melhor característica para separar os dados em subconjuntos mais "puros" em relação à variável alvo (classe).
</p>


## Critérios de Divisão para Classificação

<br>

- **Entropia**

A **entropia** é uma **medida de impureza** ou aleatoriedade dos dados em um algoritmo de árvore de decisão. Ela é utilizada para avaliar o quão homogêneos ou heterogêneos são os exemplos de uma determinada classe em um conjunto de dados.

. . .

É calculada a partir da distribuição das classes no conjunto de dados. Quanto **maior** a entropia, **maior a incerteza** sobre a classe de um exemplo. Quanto **menor** a entropia, mais **homogêneos** são os exemplos em relação à classe.


## Critérios de Divisão para Classificação

<br>

- **Entropia**

$$ \text{E(S)} = \sum_{i=1}^c -p_i\log_2 p_i$$


em que $p_i$ é a proporção de exemplos na classe $i$ da amostra de treinamento S.


## Critérios de Divisão para Classificação

<br>

- **Ganho de Informação (G)**

O **ganho de informação** é uma métrica utilizada para medir a relevância de um atributo na divisão dos dados. Ele indica a **quantidade de informação** que um atributo fornece sobre a **classe** ou **variável** de saída.

. . .

Mede a **redução na entropia** após a divisão do conjunto de dados por uma característica.

. . .

O ID3 escolhe a característica com o **maior ganho de informação**.



## Critérios de Divisão para Classificação

<br>

- **Ganho de Informação (G)**


$$ \text{G}(S, A) = \text{E}(S) - \text{E}(S,A)$$

em que $E(S,A) = \sum_{v\in \text{valores de } A} \dfrac{|S_v|}{|S|} \times \text{E}(S_v)$ é a entropia do atributo A.





## Critérios de Divisão para Classificação

<br>

- **Razão de ganho**

Também conhecida como **gain ratio**, é uma métrica utilizada para selecionar os melhores atributos de divisão, levando em consideração o viés por atributos com muitos valores possíveis.

. . .

Enquanto o **ganho de informação** mede a redução da entropia dos dados após a divisão com base em um atributo, a **razão de ganho** ajusta esse valor, levando em consideração o número de valores distintos do atributo. 

. . .

Essa correção é importante para evitar que atributos com **muitos valores** possíveis tenham vantagem sobre atributos com **menos valores**.



## Critérios de Divisão para Classificação

<br>

- **Razão de ganho**


$$ \text{Gain ratio}(S, A) = \dfrac{G(S, A)}{E(S, A)}$$







## Critérios de Divisão para Classificação



- **Índice de Gini**

O índice de Gini é outra medida de **impureza** utilizada para avaliar a heterogeneidade dos dados em relação à classe ou variável de saída. 


. . .

Medida da probabilidade de uma amostra ser classificada incorretamente se fosse aleatoriamente rotulada de acordo com a distribuição das classes no subconjunto.

. . .

Um valor menor indica maior pureza.


. . .


Usado pelo CART para classificação.



## Critérios de Divisão para Classificação



- **Índice de Gini**

$$ \text{Gini}(S) = 1 - \sum_{i=1}^c p_i^2$$
em que $p_i$ é a proporção de exemplos na classe $i$ da amostra de treinamento S.


. . .


O CART busca a divisão que resulta na maior redução no índice de Gini.


. . .

O índice de Gini varia de 0 a 1, sendo 0 quando todos os exemplos pertencem à mesma classe (alta pureza) e 1 quando os exemplos estão igualmente distribuídos entre as classes (alta impureza).


## Critérios de Divisão para Regressão

<br>

<br>


<p align="center">
O objetivo é dividir os dados de forma a minimizar a variabilidade da variável alvo dentro de cada nó folha.
</p>



## Critérios de Divisão para Regressão

- **Redução do Erro Quadrático Médio (MSE):**


O CART para regressão geralmente busca a divisão que maximiza a redução no MSE.

. . .

Calcula-se o MSE no nó pai e o MSE ponderado nos nós filhos após a divisão. A divisão que proporciona a maior redução é escolhida.

. . .

$$MSE = \dfrac{1}{|S|} \displaystyle{\sum_{i\in S} (y_i - \bar{y})^2}$$



em que $y_i$ é o valor da variável alvo para a amostra $i$ e $\bar{y}$ é a média dos valores da variável alvo em S.



## Critérios de Divisão para Regressão

- **Redução do Desvio Absoluto Médio (MAE):**


Alternativamente, alguns algoritmos de árvores de regressão podem usar o MAE.


. . .


$$MAE = \dfrac{1}{|S|} \displaystyle{\sum_{i\in S} |y_i - \text{mediana}(y)|}$$


## Vantagens e Desvantagens

<br>

:::: {.columns}

::: {.column width="10%"}

<br>

<span style='font-size:160px;'>&#128077;</span>
:::

::: {.column width="90%"}
  -	Fáceis de entender e interpretar (modelos "caixa branca").
  - Podem lidar com dados numéricos e categóricos.
  - Não exigem muita preparação dos dados (não sensíveis a escala ou transformações monótonas).
  - Capazes de capturar relações não lineares entre as características e a variável alvo.
  - Úteis para seleção de características (as características mais próximas da raiz são consideradas mais importantes).
:::

::::

## Vantagens e Desvantagens

<br>

:::: {.columns}

::: {.column width="10%"}

<br>

<span style='font-size:160px;'>&#128078;</span>
:::

::: {.column width="90%"}
  -	Tendência ao overfitting (ajustar-se demais aos dados de treinamento, resultando em mau desempenho em dados novos).
  - Podem ser sensíveis a pequenas variações nos dados de treinamento.
  - Podem criar árvores complexas que não generalizam bem.
  - Para algumas tarefas, podem não ser tão precisas quanto outros algoritmos.
  - O algoritmo guloso de construção da árvore nem sempre encontra a melhor árvore possível.

:::

::::



## Controle de Overfitting (Podas)

<br>

A **poda** é o processo de **reduzir o tamanho de uma árvore de decisão**, removendo seções da árvore que podem estar superajustando os dados de treinamento.

. . .

O objetivo da poda é **simplificar** a árvore, tornando-a mais generalizável e menos propensa a memorizar ruídos específicos do conjunto de treinamento.


## Controle de Overfitting (Podas)

<br>

Tipos de Poda:


- **Pré-poda:** Parar o crescimento da árvore antecipadamente com base em critérios (ex: profundidade máxima, número mínimo de amostras por nó).

  - Mais eficiente computacionalmente; pode levar ao underfitting
  
. . .

- **Pós-poda:** Construir a árvore completa e depois remover nós que não melhoram o desempenho em um conjunto de validação.

  - Árvores com melhor capacidade de generalização; mais intensiva computacionalmente
  


## Exemplo: Compra de um computador


![](/images/knn/tabela.jpg){.nostretch fig-align="center" width="1300px"}




## Exemplo: Compra de um computador


:::: {.columns}

::: {.column width="50%"}

<br>


![](/images/knn/tabela.jpg){fig-align="center"}
:::

::: {.column width="50%"}

<br>

<p align="center">**Cálculo da Entropia**</p>

$$ \text{E(S)} = \sum_{i=1}^c -p_i\log_2 p_i$$

::: {.fragment}
$$ \text{E(S)} = -\dfrac{9}{14}\log_2 (\dfrac{9}{14}) - \dfrac{5}{14}\log_2 (\dfrac{5}{14}) = 0,940$$
:::


:::

::::


## Exemplo: Compra de um computador


:::: {.columns}

::: {.column width="50%"}

<br>

<br>

<style type="text/css">
.tg  {border-collapse:collapse;border-color:#93a1a1;border-spacing:0;}
.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-cw6g"></th>
    <th class="tg-cw6g"></th>
    <th class="tg-c3ow" colspan="2">Classe</th>
    <th class="tg-c3ow"></th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-cw6g"></td>
    <td class="tg-oao4"></td>
    <td class="tg-c3ow">Sim</td>
    <td class="tg-c3ow">Não</td>
    <td class="tg-c3ow"></td>
  </tr>
  <tr>
    <td class="tg-itrc" rowspan="3">Idade<br></td>
    <td class="tg-oao4">=&lt; 30</td>
    <td class="tg-c3ow">2</td>
    <td class="tg-c3ow">3</td>
    <td class="tg-c3ow">5</td>
  </tr>
  <tr>
    <td class="tg-oao4">31...40</td>
    <td class="tg-c3ow">4</td>
    <td class="tg-c3ow">0</td>
    <td class="tg-c3ow">4</td>
  </tr>
  <tr>
    <td class="tg-oao4">&gt;40</td>
    <td class="tg-c3ow">3</td>
    <td class="tg-c3ow">2</td>
    <td class="tg-c3ow">5</td>
  </tr>
  <tr>
    <td class="tg-cw6g"></td>
    <td class="tg-oao4"></td>
    <td class="tg-c3ow"></td>
    <td class="tg-c3ow"></td>
  </tr>
</tbody>
</table>
:::

::: {.column width="50%"}

<br>

<p align="center">**Ganho de informação para o atributo idade**</p>

$$ \text{E(S, Idade)} = \dfrac{|\leq 30|}{|S|}\times \text{E}(\leq 30)\\
+ \dfrac{|31...40|}{|S|}\times \text{E}(31...40) \\ +  \dfrac{|>40|}{|S|}\times \text{E}(>40)$$

<!-- ::: {.fragment} -->
<!-- $$ \text{E(S)} = -\dfrac{9}{14}\log_2 (\dfrac{9}{14}) - \dfrac{5}{14}\log_2 (\dfrac{5}{14}) = 0,940$$ -->
<!-- ::: -->


:::

::::



## Exemplo: Compra de um computador


:::: {.columns}

::: {.column width="50%"}

<br>

<br>

<style type="text/css">
.tg  {border-collapse:collapse;border-color:#93a1a1;border-spacing:0;}
.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-cw6g"></th>
    <th class="tg-cw6g"></th>
    <th class="tg-c3ow" colspan="2">Classe</th>
    <th class="tg-c3ow"></th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-cw6g"></td>
    <td class="tg-oao4"></td>
    <td class="tg-c3ow">Sim</td>
    <td class="tg-c3ow">Não</td>
    <td class="tg-c3ow"></td>
  </tr>
  <tr>
    <td class="tg-itrc" rowspan="3">Idade<br></td>
    <td class="tg-oao4">=&lt; 30</td>
    <td class="tg-c3ow">2</td>
    <td class="tg-c3ow">3</td>
    <td class="tg-c3ow">5</td>
  </tr>
  <tr>
    <td class="tg-oao4">31...40</td>
    <td class="tg-c3ow">4</td>
    <td class="tg-c3ow">0</td>
    <td class="tg-c3ow">4</td>
  </tr>
  <tr>
    <td class="tg-oao4">&gt;40</td>
    <td class="tg-c3ow">3</td>
    <td class="tg-c3ow">2</td>
    <td class="tg-c3ow">5</td>
  </tr>
  <tr>
    <td class="tg-cw6g"></td>
    <td class="tg-oao4"></td>
    <td class="tg-c3ow"></td>
    <td class="tg-c3ow"></td>
  </tr>
</tbody>
</table>
:::

::: {.column width="50%"}

<br>

<p align="center">**Ganho de informação para o atributo idade**</p>

$$ \text{E(S, Idade)} = \dfrac{5}{14}\times \text{E}(\leq 30) \\ + \dfrac{4}{14}\times \text{E}(31...40) \\ +  \dfrac{5}{14}\times \text{E}(>40)$$




:::

::::



## Exemplo: Compra de um computador


:::: {.columns}

::: {.column width="50%"}

<br>

<br>

<style type="text/css">
.tg  {border-collapse:collapse;border-color:#93a1a1;border-spacing:0;}
.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-cw6g"></th>
    <th class="tg-cw6g"></th>
    <th class="tg-c3ow" colspan="2">Classe</th>
    <th class="tg-c3ow"></th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-cw6g"></td>
    <td class="tg-oao4"></td>
    <td class="tg-c3ow">Sim</td>
    <td class="tg-c3ow">Não</td>
    <td class="tg-c3ow"></td>
  </tr>
  <tr>
    <td class="tg-itrc" rowspan="3">Idade<br></td>
    <td class="tg-oao4">=&lt; 30</td>
    <td class="tg-c3ow">2</td>
    <td class="tg-c3ow">3</td>
    <td class="tg-c3ow">5</td>
  </tr>
  <tr>
    <td class="tg-oao4">31...40</td>
    <td class="tg-c3ow">4</td>
    <td class="tg-c3ow">0</td>
    <td class="tg-c3ow">4</td>
  </tr>
  <tr>
    <td class="tg-oao4">&gt;40</td>
    <td class="tg-c3ow">3</td>
    <td class="tg-c3ow">2</td>
    <td class="tg-c3ow">5</td>
  </tr>
  <tr>
    <td class="tg-cw6g"></td>
    <td class="tg-oao4"></td>
    <td class="tg-c3ow"></td>
    <td class="tg-c3ow"></td>
  </tr>
</tbody>
</table>
:::

::: {.column width="50%"}

<br>

<p align="center">**Ganho de informação para o atributo idade**</p>

$$ \text{E}(\leq 30) = -\dfrac{2}{5}\log_2 (\dfrac{2}{5}) - \dfrac{3}{5}\log_2 (\dfrac{3}{5}) = 0,971$$
$$ \text{E}(31...40) = 0\,\,\,\,\,\,\,\, \text{e} \,\,\,\,\,\,\,\, \text{E}(>40) = 0,971$$



:::

::::



## Exemplo: Compra de um computador


:::: {.columns}

::: {.column width="50%"}

<br>

<br>

<style type="text/css">
.tg  {border-collapse:collapse;border-color:#93a1a1;border-spacing:0;}
.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-cw6g"></th>
    <th class="tg-cw6g"></th>
    <th class="tg-c3ow" colspan="2">Classe</th>
    <th class="tg-c3ow"></th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-cw6g"></td>
    <td class="tg-oao4"></td>
    <td class="tg-c3ow">Sim</td>
    <td class="tg-c3ow">Não</td>
    <td class="tg-c3ow"></td>
  </tr>
  <tr>
    <td class="tg-itrc" rowspan="3">Idade<br></td>
    <td class="tg-oao4">=&lt; 30</td>
    <td class="tg-c3ow">2</td>
    <td class="tg-c3ow">3</td>
    <td class="tg-c3ow">5</td>
  </tr>
  <tr>
    <td class="tg-oao4">31...40</td>
    <td class="tg-c3ow">4</td>
    <td class="tg-c3ow">0</td>
    <td class="tg-c3ow">4</td>
  </tr>
  <tr>
    <td class="tg-oao4">&gt;40</td>
    <td class="tg-c3ow">3</td>
    <td class="tg-c3ow">2</td>
    <td class="tg-c3ow">5</td>
  </tr>
  <tr>
    <td class="tg-cw6g"></td>
    <td class="tg-oao4"></td>
    <td class="tg-c3ow"></td>
    <td class="tg-c3ow"></td>
  </tr>
</tbody>
</table>
:::

::: {.column width="50%"}

<br>

<p align="center">**Ganho de informação para o atributo idade**</p>

$$ \text{E(S, Idade)} = \dfrac{5}{|14|}\times 0,971  + \dfrac{4}{|14|}\times 0 \\ +  \dfrac{5}{14}\times 0,971 = 0,693$$

$$ \text{G}(S, \text{Idade}) = \text{E}(S) - \text{E}(S,\text{Idade})\\ = 0,940 - 0,693 = 0,247$$



:::

::::








## Exemplo: Compra de um computador



![](/images/ad/ganhos.png){.nostretch fig-align="center" width="1800px"}



## Exemplo: Compra de um computador

<br>

Escolhemos o atributo com maior ganho de informação como nó de decisão. No nosso caso, o atributo **Idade**. A partir daí, dividimos o conjunto de dados a partir das categorias da variável idade e repetimos o mesmo processo em todos os ramos. 

. . .

Um ramo com entropia de 0 é um **nó folha**. Um ramo com entropia maior que 0 precisa de mais divisão.


## Exemplo: Compra de um computador


<p align="center">**Árvore estimada**</p>


![](/images/ad/arv_est.png){.nostretch fig-align="center" width="1000px"}




## Exemplo: Compra de um computador


:::: {.columns}

::: {.column width="40%"}

![](/images/joao.png){.nostretch fig-align="center" width="1300px"}
:::

::: {.column width="60%"}

<br>

<p align="center" style="font-size: 76px">**Voltando ao Joãozinho...**</p>

&nbsp;
&nbsp;

::: {.fragment}
<p align="center" style="font-size: 56px">$x_0 = (\leq 30, \text{ Média}, \text{ Sim}, \text{ Bom})$</p>
:::


:::

::::


## Exemplo: Compra de um computador

<p align="center" style="font-size: 56px">$x_0 = (\leq 30, \text{ Média}, \text{ Sim}, \text{ Bom})$</p>


![](/images/ad/arv_est_joao.png){.nostretch fig-align="center" width="1000px"}



## Exemplo: Compra de um computador 

<br>

<br>


<details>
  <summary align="center" style='font-size:80px;'>**João comprará o computador?**</summary>
  <p align="center" style="color: green; font-size:80px;"> **De acordo com Árvores de Decisão: SIM!** </p>
</details>


## Árvores de  Decisão para classificação no R e Python

::: {.panel-tabset}

### R

```{r}
#| echo: true

library(tidymodels)
library(discrim)
library(Metrics)

set.seed(12345)
data(iris)
iris_split <- initial_split(iris, strata = Species)
train_data <- training(iris_split)
test_data <- testing(iris_split)

tree_model <- decision_tree() %>% 
  set_engine("rpart") %>%
  set_mode("classification")

tree_fit <- workflow() %>%
  add_model(tree_model) %>%
  add_formula(Species ~ .) %>%
  fit(data = train_data)

sp_predict <- predict(tree_fit, new_data = test_data)

Metrics::accuracy(test_data$Species, sp_predict$.pred_class)
```

### Python

```{python}
#| echo: true

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.datasets import load_iris

iris = load_iris()
X = pd.DataFrame(iris.data, columns=iris.feature_names)
y = pd.Series(iris.target_names[iris.target], name='species') # Mapear números para nomes de espécies

# Split dos dados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)

tree = DecisionTreeClassifier(random_state=12345)
tree.fit(X_train, y_train)
y_pred = tree.predict(X_test)
accuracy_score(y_test, y_pred)
```

:::


## Árvores de Decisão para regressão no R e Python

::: {.panel-tabset}

### R

```{r}
#| echo: true

library(tidymodels)
library(Metrics)

data("mtcars")
set.seed(12345)
mtcars_split <- initial_split(mtcars, strata = mpg)
train_data <- training(mtcars_split)
test_data <- testing(mtcars_split)

tree_model <- decision_tree() %>% 
  set_engine("rpart") %>%
  set_mode("regression")

tree_fit <- workflow() %>%
  add_model(tree_model) %>%
  add_formula(mpg ~ .) %>%
  fit(data = train_data)

mpg_predict <- predict(tree_fit, test_data)

Metrics::mse(test_data$mpg, mpg_predict$.pred) # MSE
```

### Python

```{python}
#| echo: true

from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error

data = fetch_california_housing()
X_train, X_test, y_train, y_test = train_test_split(
    data.data, data.target, random_state=12345
)

tree = DecisionTreeRegressor(random_state=12345)
tree.fit(X_train, y_train)
y_pred = tree.predict(X_test)
mean_squared_error(y_test, y_pred, squared=True)  # MSE
```

:::
