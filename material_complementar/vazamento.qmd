---
title: "Vazamento de dados: O inimigo oculto da predição confiável"
format:
  html:
    toc: true
    code-fold: false
    code-summary: "Mostrar código"
    embed-resources: true
execute: 
  eval: false   
---

Hoje vamos mergulhar em um problema sutil, mas extremamente perigoso no mundo da modelagem preditiva: o vazamento de dados (ou data leakage). Se não diagnosticado e tratado corretamente, ele pode levar à criação de modelos que parecem incrivelmente precisos em seus dados de treino, mas falham miseravelmente ao serem aplicados a dados reais e não vistos.


## 🤔 O que é vazamento de dados (data leakage)?

Imagine que você está tentando prever se um paciente tem uma determinada doença com base em seus exames. Se você incluir no seu conjunto de dados de treino uma informação que só estaria disponível após o diagnóstico (por exemplo, um código de procedimento médico realizado após a confirmação da doença), seu modelo "aprenderá" essa correlação espúria. Ele não estará realmente identificando os fatores de risco da doença, mas sim "colando" a resposta com base em informações futuras.

Data leakage ocorre quando informações que não estariam disponíveis no momento da predição são utilizadas no treinamento do modelo. Isso faz com que o modelo aprenda padrões irreais, que não se sustentam em dados do mundo real.

Em outras palavras, o modelo "cola" na resposta porque tem acesso a informações que não deveria ter. Isso gera uma falsa sensação de desempenho alto durante o treinamento e validação.


## ⚠️ Consequências do vazamento de dados

- 📉 **Overfitting extremo:** o modelo aprende relações espúrias que não se generalizam.

- 🤥 **Avaliações enganosas:** métricas como acurácia ou AUC são infladas artificialmente.

- 🚫 **Falhas na produção:** quando aplicado em novos dados, o modelo apresenta desempenho muito inferior.

- 💸 **Decisões erradas:** em contextos reais (saúde, finanças, marketing), isso pode levar a prejuízos graves.


## 🧐 O que pode causar Data Leakage?

Diversas práticas (muitas vezes bem-intencionadas) podem causar vazamento de dados:

- Pré-processamento antes da separação treino/teste
    - Ex: imputar valores ausentes usando a média de toda a base, inclusive do conjunto de teste.

- Variáveis que refletem eventos futuros
    - Ex: tentar prever inadimplência usando a variável “pagamento em atraso”, que só é registrada após o evento.

- Variáveis altamente correlacionadas com o alvo
    - Ex: incluir o valor da fatura final ao prever se o cliente vai pagar — esse valor depende justamente do pagamento.

- Criação de variáveis a partir do target (target leakage)
    - Ex: criar variáveis com base no rótulo da variável-resposta, direta ou indiretamente.

- Informações compartilhadas entre treino e teste
    - Ex: repetir registros ou agrupar dados por cliente sem cuidado pode gerar vazamento entre observações de treino e teste.
    
## 🧠 Como evitar o Data Leakage?

A boa notícia é que o vazamento de dados pode ser evitado com boas práticas:


- **Entendimento profundo dos dados e do problema:** Antes de qualquer coisa, é crucial entender a origem, o significado e o fluxo dos seus dados. Quais variáveis estão disponíveis em que momento? Qual é a linha do tempo dos eventos? Essa compreensão ajudará a identificar potenciais fontes de vazamento.

- **Separação rigorosa dos conjuntos de dados:** A divisão entre dados de treino, validação e teste deve ser feita **antes de qualquer etapa de pré-processamento ou engenharia de features**. O conjunto de teste só deve ser usado para avaliar o desempenho final do modelo, após todo o desenvolvimento. O conjunto de validação serve para ajustar hiperparâmetros e comparar diferentes modelos, sem "espiar" os dados de teste.

- **Pré-processamento e engenharia de features dentro dos folds de validação cruzada:** Se você estiver usando validação cruzada, certifique-se de que qualquer etapa de pré-processamento (escalonamento, imputação de valores faltantes, codificação de variáveis categóricas) e engenharia de features seja realizada apenas nos dados de treino de cada fold. As estatísticas e transformações aprendidas em um fold de treino devem ser aplicadas separadamente ao fold de validação correspondente. Isso evita que informações do fold de validação "vazem" para o treino.

- **Cuidado com variáveis derivadas do alvo:** Tenha extrema cautela ao criar novas variáveis que possam ser derivadas diretamente da variável alvo ou de informações que só estariam disponíveis após a ocorrência do evento que você está tentando prever. O exemplo do código de procedimento médico é um caso clássico.

- **Análise temporal cuidadosa:** Em problemas com dados temporais, a separação dos conjuntos de treino e teste deve respeitar a ordem cronológica. Usar dados futuros para treinar um modelo que pretende prever o passado (ou o presente) é uma receita certa para o vazamento. Técnicas como `time series split` são essenciais nesses casos.

- **Pipeline de modelagem:** A criação de um pipeline bem definido, que encapsula todas as etapas de pré-processamento, engenharia de features e treinamento do modelo, ajuda a garantir que o processo seja aplicado de forma consistente e a evitar erros que possam levar ao vazamento.

- **Auditoria e revisão do código:** Peça a colegas para revisarem seu código em busca de potenciais fontes de vazamento. Uma nova perspectiva pode identificar problemas que você pode ter perdido.


## ✨ Conclusão


O vazamento de dados é sorrateiro. Ele não lança erros, nem avisa que está ali. Mas pode comprometer todo o seu projeto de ciência de dados.

Por isso, desconfie de modelos perfeitos demais, questione suas variáveis e sempre pergunte:

> “Essa informação estaria disponível na vida real no momento da previsão?”

Evitar o data leakage é mais do que uma prática técnica — é um exercício de pensamento crítico e rigor metodológico.