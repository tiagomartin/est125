---
title: "Vazamento de dados: O inimigo oculto da prediÃ§Ã£o confiÃ¡vel"
format:
  html:
    toc: true
    code-fold: false
    code-summary: "Mostrar cÃ³digo"
    embed-resources: true
execute: 
  eval: false   
---

Hoje vamos mergulhar em um problema sutil, mas extremamente perigoso no mundo da modelagem preditiva: o vazamento de dados (ou data leakage). Se nÃ£o diagnosticado e tratado corretamente, ele pode levar Ã  criaÃ§Ã£o de modelos que parecem incrivelmente precisos em seus dados de treino, mas falham miseravelmente ao serem aplicados a dados reais e nÃ£o vistos.


## ğŸ¤” O que Ã© vazamento de dados (data leakage)?

Imagine que vocÃª estÃ¡ tentando prever se um paciente tem uma determinada doenÃ§a com base em seus exames. Se vocÃª incluir no seu conjunto de dados de treino uma informaÃ§Ã£o que sÃ³ estaria disponÃ­vel apÃ³s o diagnÃ³stico (por exemplo, um cÃ³digo de procedimento mÃ©dico realizado apÃ³s a confirmaÃ§Ã£o da doenÃ§a), seu modelo "aprenderÃ¡" essa correlaÃ§Ã£o espÃºria. Ele nÃ£o estarÃ¡ realmente identificando os fatores de risco da doenÃ§a, mas sim "colando" a resposta com base em informaÃ§Ãµes futuras.

Data leakage ocorre quando informaÃ§Ãµes que nÃ£o estariam disponÃ­veis no momento da prediÃ§Ã£o sÃ£o utilizadas no treinamento do modelo. Isso faz com que o modelo aprenda padrÃµes irreais, que nÃ£o se sustentam em dados do mundo real.

Em outras palavras, o modelo "cola" na resposta porque tem acesso a informaÃ§Ãµes que nÃ£o deveria ter. Isso gera uma falsa sensaÃ§Ã£o de desempenho alto durante o treinamento e validaÃ§Ã£o.


## âš ï¸ ConsequÃªncias do vazamento de dados

- ğŸ“‰ **Overfitting extremo:** o modelo aprende relaÃ§Ãµes espÃºrias que nÃ£o se generalizam.

- ğŸ¤¥ **AvaliaÃ§Ãµes enganosas:** mÃ©tricas como acurÃ¡cia ou AUC sÃ£o infladas artificialmente.

- ğŸš« **Falhas na produÃ§Ã£o:** quando aplicado em novos dados, o modelo apresenta desempenho muito inferior.

- ğŸ’¸ **DecisÃµes erradas:** em contextos reais (saÃºde, finanÃ§as, marketing), isso pode levar a prejuÃ­zos graves.


## ğŸ§ O que pode causar Data Leakage?

Diversas prÃ¡ticas (muitas vezes bem-intencionadas) podem causar vazamento de dados:

- PrÃ©-processamento antes da separaÃ§Ã£o treino/teste
    - Ex: imputar valores ausentes usando a mÃ©dia de toda a base, inclusive do conjunto de teste.

- VariÃ¡veis que refletem eventos futuros
    - Ex: tentar prever inadimplÃªncia usando a variÃ¡vel â€œpagamento em atrasoâ€, que sÃ³ Ã© registrada apÃ³s o evento.

- VariÃ¡veis altamente correlacionadas com o alvo
    - Ex: incluir o valor da fatura final ao prever se o cliente vai pagar â€” esse valor depende justamente do pagamento.

- CriaÃ§Ã£o de variÃ¡veis a partir do target (target leakage)
    - Ex: criar variÃ¡veis com base no rÃ³tulo da variÃ¡vel-resposta, direta ou indiretamente.

- InformaÃ§Ãµes compartilhadas entre treino e teste
    - Ex: repetir registros ou agrupar dados por cliente sem cuidado pode gerar vazamento entre observaÃ§Ãµes de treino e teste.
    
## ğŸ§  Como evitar o Data Leakage?

A boa notÃ­cia Ã© que o vazamento de dados pode ser evitado com boas prÃ¡ticas:


- **Entendimento profundo dos dados e do problema:** Antes de qualquer coisa, Ã© crucial entender a origem, o significado e o fluxo dos seus dados. Quais variÃ¡veis estÃ£o disponÃ­veis em que momento? Qual Ã© a linha do tempo dos eventos? Essa compreensÃ£o ajudarÃ¡ a identificar potenciais fontes de vazamento.

- **SeparaÃ§Ã£o rigorosa dos conjuntos de dados:** A divisÃ£o entre dados de treino, validaÃ§Ã£o e teste deve ser feita **antes de qualquer etapa de prÃ©-processamento ou engenharia de features**. O conjunto de teste sÃ³ deve ser usado para avaliar o desempenho final do modelo, apÃ³s todo o desenvolvimento. O conjunto de validaÃ§Ã£o serve para ajustar hiperparÃ¢metros e comparar diferentes modelos, sem "espiar" os dados de teste.

- **PrÃ©-processamento e engenharia de features dentro dos folds de validaÃ§Ã£o cruzada:** Se vocÃª estiver usando validaÃ§Ã£o cruzada, certifique-se de que qualquer etapa de prÃ©-processamento (escalonamento, imputaÃ§Ã£o de valores faltantes, codificaÃ§Ã£o de variÃ¡veis categÃ³ricas) e engenharia de features seja realizada apenas nos dados de treino de cada fold. As estatÃ­sticas e transformaÃ§Ãµes aprendidas em um fold de treino devem ser aplicadas separadamente ao fold de validaÃ§Ã£o correspondente. Isso evita que informaÃ§Ãµes do fold de validaÃ§Ã£o "vazem" para o treino.

- **Cuidado com variÃ¡veis derivadas do alvo:** Tenha extrema cautela ao criar novas variÃ¡veis que possam ser derivadas diretamente da variÃ¡vel alvo ou de informaÃ§Ãµes que sÃ³ estariam disponÃ­veis apÃ³s a ocorrÃªncia do evento que vocÃª estÃ¡ tentando prever. O exemplo do cÃ³digo de procedimento mÃ©dico Ã© um caso clÃ¡ssico.

- **AnÃ¡lise temporal cuidadosa:** Em problemas com dados temporais, a separaÃ§Ã£o dos conjuntos de treino e teste deve respeitar a ordem cronolÃ³gica. Usar dados futuros para treinar um modelo que pretende prever o passado (ou o presente) Ã© uma receita certa para o vazamento. TÃ©cnicas como `time series split` sÃ£o essenciais nesses casos.

- **Pipeline de modelagem:** A criaÃ§Ã£o de um pipeline bem definido, que encapsula todas as etapas de prÃ©-processamento, engenharia de features e treinamento do modelo, ajuda a garantir que o processo seja aplicado de forma consistente e a evitar erros que possam levar ao vazamento.

- **Auditoria e revisÃ£o do cÃ³digo:** PeÃ§a a colegas para revisarem seu cÃ³digo em busca de potenciais fontes de vazamento. Uma nova perspectiva pode identificar problemas que vocÃª pode ter perdido.


## âœ¨ ConclusÃ£o


O vazamento de dados Ã© sorrateiro. Ele nÃ£o lanÃ§a erros, nem avisa que estÃ¡ ali. Mas pode comprometer todo o seu projeto de ciÃªncia de dados.

Por isso, desconfie de modelos perfeitos demais, questione suas variÃ¡veis e sempre pergunte:

> â€œEssa informaÃ§Ã£o estaria disponÃ­vel na vida real no momento da previsÃ£o?â€

Evitar o data leakage Ã© mais do que uma prÃ¡tica tÃ©cnica â€” Ã© um exercÃ­cio de pensamento crÃ­tico e rigor metodolÃ³gico.