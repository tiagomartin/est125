{
  "hash": "d26667974085a27e0bb3cf2f4ec6aea2",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Reconhecendo padr√µes usando a base de dados Space Titanic\"\nformat: html\nexecute:\n  cache: true\n---\n\nImagine que voc√™ √© um cientista de dados respons√°vel por entender os perfis dos passageiros da nave Space Titanic, que viajava em dire√ß√£o a uma col√¥nia espacial. Infelizmente, parte da tripula√ß√£o desapareceu misteriosamente e agora queremos entender se havia padr√µes ocultos entre os passageiros que possam explicar esse desfecho.\n\nA base de dados Space Titanic, inspirada no cl√°ssico Titanic e dispon√≠vel no [`Kaggle`](https://www.kaggle.com), ser√° utilizada para trabalharmos t√©cnicas de clusteriza√ß√£o n√£o supervisionada, que nos permitem:\n\n- üîç Descobrir grupos de passageiros com perfis semelhantes;\n\n- üß† Analisar comportamentos e caracter√≠sticas emergentes em cada grupo;\n\n- üìä Auxiliar em decis√µes estrat√©gicas para personaliza√ß√£o de servi√ßos, seguran√ßa de bordo e planejamento de miss√µes futuras.\n\n\n## Pacotes utilizados \n\n\n::: {.cell}\n\n```{.r .cell-code}\nload <- function(pkg){\n  new.pkg <- pkg[!(pkg %in% installed.packages()[, \"Package\"])]\n  if (length(new.pkg))\n    install.packages(new.pkg, dependencies = TRUE)\n  sapply(pkg, require, character.only = TRUE)\n} \n\n## Pacotes utilizados nessa an√°lise\n\npackages = c(\"tidyverse\",'tidymodels', 'tidyclust', 'dbscan', 'meanShiftR', 'kohonen', 'doParallel', 'tictoc', 'tidyr', 'purrr', 'cluster', 'umap', 'funModeling', 'clue', 'janitor', 'mclust', 'tictoc', 'future', 'doFuture', 'progressr', 'FactoMineR', 'factoextra', 'vegan')\nload(packages)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  tidyverse  tidymodels   tidyclust      dbscan  meanShiftR     kohonen \n       TRUE        TRUE        TRUE        TRUE        TRUE        TRUE \n doParallel      tictoc       tidyr       purrr     cluster        umap \n       TRUE        TRUE        TRUE        TRUE        TRUE        TRUE \nfunModeling        clue     janitor      mclust      tictoc      future \n       TRUE        TRUE        TRUE        TRUE        TRUE        TRUE \n   doFuture   progressr  FactoMineR  factoextra       vegan \n       TRUE        TRUE        TRUE        TRUE        TRUE \n```\n\n\n:::\n:::\n\n\n\n## Leitura dos dados\n \n\n::: {.cell}\n\n```{.r .cell-code}\ndados = rio::import(\"https://raw.githubusercontent.com/tiagomartin/est125/refs/heads/main/dados/space_titanic.csv\")\ndados %>% \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 8,693\nColumns: 14\n$ PassengerId  <chr> \"0001_01\", \"0002_01\", \"0003_01\", \"0003_02\", \"0004_01\", \"0‚Ä¶\n$ HomePlanet   <chr> \"Europa\", \"Earth\", \"Europa\", \"Europa\", \"Earth\", \"Earth\", ‚Ä¶\n$ CryoSleep    <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FA‚Ä¶\n$ Cabin        <chr> \"B/0/P\", \"F/0/S\", \"A/0/S\", \"A/0/S\", \"F/1/S\", \"F/0/P\", \"F/‚Ä¶\n$ Destination  <chr> \"TRAPPIST-1e\", \"TRAPPIST-1e\", \"TRAPPIST-1e\", \"TRAPPIST-1e‚Ä¶\n$ Age          <dbl> 39, 24, 58, 33, 16, 44, 26, 28, 35, 14, 34, 45, 32, 48, 2‚Ä¶\n$ VIP          <lgl> FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FA‚Ä¶\n$ RoomService  <dbl> 0, 109, 43, 0, 303, 0, 42, 0, 0, 0, 0, 39, 73, 719, 8, 32‚Ä¶\n$ FoodCourt    <dbl> 0, 9, 3576, 1283, 70, 483, 1539, 0, 785, 0, 0, 7295, 0, 1‚Ä¶\n$ ShoppingMall <dbl> 0, 25, 0, 371, 151, 0, 3, 0, 17, 0, NA, 589, 1123, 65, 12‚Ä¶\n$ Spa          <dbl> 0, 549, 6715, 3329, 565, 291, 0, 0, 216, 0, 0, 110, 0, 0,‚Ä¶\n$ VRDeck       <dbl> 0, 44, 49, 193, 2, 0, 0, NA, 0, 0, 0, 124, 113, 24, 7, 0,‚Ä¶\n$ Name         <chr> \"Maham Ofracculy\", \"Juanna Vines\", \"Altark Susent\", \"Sola‚Ä¶\n$ Transported  <lgl> FALSE, TRUE, FALSE, FALSE, TRUE, TRUE, TRUE, TRUE, TRUE, ‚Ä¶\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndados %>% df_status()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       variable q_zeros p_zeros q_na p_na q_inf p_inf      type unique\n1   PassengerId       0    0.00    0 0.00     0     0 character   8693\n2    HomePlanet       0    0.00    0 0.00     0     0 character      4\n3     CryoSleep    5439   62.57  217 2.50     0     0   logical      2\n4         Cabin       0    0.00    0 0.00     0     0 character   6561\n5   Destination       0    0.00    0 0.00     0     0 character      4\n6           Age     178    2.05  179 2.06     0     0   numeric     80\n7           VIP    8291   95.38  203 2.34     0     0   logical      2\n8   RoomService    5577   64.16  181 2.08     0     0   numeric   1273\n9     FoodCourt    5456   62.76  183 2.11     0     0   numeric   1507\n10 ShoppingMall    5587   64.27  208 2.39     0     0   numeric   1115\n11          Spa    5324   61.24  183 2.11     0     0   numeric   1327\n12       VRDeck    5495   63.21  188 2.16     0     0   numeric   1306\n13         Name       0    0.00    0 0.00     0     0 character   8474\n14  Transported    4315   49.64    0 0.00     0     0   logical      2\n```\n\n\n:::\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(12345)  # Escolha um n√∫mero fixo qualquer\n```\n:::\n\n\n\nDe an√°lises anteriores, propomos as seguintes novas vari√°veis\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Engenharia de vari√°veis\ndados = dados %>%\n  separate(Cabin, c(\"CabinDeck\", \"CabinNum\", \"CabinSide\"), sep = \"/\", remove = TRUE) %>% \n  separate(PassengerId, c(\"PassGroup\", \"nGroup\"), sep = \"_\", remove = TRUE) %>% \n  mutate(CabinDeck = as.factor(CabinDeck),\n         CabinSide = as.factor(CabinSide), \n         PassGroup = as.numeric(PassGroup))\n```\n:::\n\n\n\n## Receita de pr√©-processamento\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreceita = recipe(~ ., data = dados) %>%\n  step_rm(Name, Transported) %>%\n  step_mutate(across(where(is.character), as.factor)) %>%\n  step_mutate(\n    GroupSize = as.integer(purrr::map_dbl(PassGroup, ~ sum(PassGroup == .x))),\n    IsAlone = ifelse(GroupSize==1, 1, 0) %>% as.factor(),\n    CabinNum = as.numeric(CabinNum),\n    nGroup = as.numeric(nGroup),\n    VIP = as.factor(VIP),\n    CryoSleep = ifelse((RoomService > 0 | FoodCourt > 0 | ShoppingMall > 0 | Spa > 0 | VRDeck > 0), tidyr::replace_na(CryoSleep, FALSE),TRUE),\n    CryoSleep = as.factor(CryoSleep)) %>% \n  step_impute_knn(CryoSleep, neighbors = 2, impute_with = imp_vars(PassGroup, CabinDeck, CabinNum, CabinSide)) %>% \n  step_mutate(\n    RoomService = ifelse(CryoSleep==TRUE, tidyr::replace_na(RoomService, 0),RoomService),\n    FoodCourt = ifelse(CryoSleep==TRUE, tidyr::replace_na(FoodCourt, 0),FoodCourt),\n    ShoppingMall = ifelse(CryoSleep==TRUE, tidyr::replace_na(ShoppingMall, 0), ShoppingMall),\n    Spa = ifelse(CryoSleep==TRUE, tidyr::replace_na(Spa, 0), Spa),\n    VRDeck = ifelse(CryoSleep==TRUE, tidyr::replace_na(VRDeck, 0), VRDeck)\n  ) %>% \n  step_impute_knn(RoomService, FoodCourt, ShoppingMall, Spa, VRDeck, neighbors = 2, \n                  impute_with = imp_vars(PassGroup, CabinDeck, CabinNum, CabinSide)) %>%\n  step_impute_bag(Age, VIP, CryoSleep, Destination, HomePlanet, CabinDeck, CabinNum, \n                  CabinSide) %>%\n  step_mutate(across(RoomService:VRDeck, ~ log10(. + 1))) %>% \n  step_mutate(despesasSuperfluas = RoomService + Spa + VRDeck,\n              despesasBasicas = FoodCourt + ShoppingMall,\n              Isearth = ifelse(HomePlanet=='Earth', 1, 0) %>% as.factor(),\n              Iskid = ifelse(Age < 14, 1, 0) %>% as.factor()) %>% \n  step_rm(PassGroup) %>%\n  step_corr(all_numeric_predictors(), threshold = 0.95) %>%  # Remove colineares\n  step_dummy(all_nominal_predictors()) %>%\n  step_normalize(all_numeric_predictors()) %>% \n  step_nzv(all_predictors())\n```\n:::\n\n\n\n\n## Pr√©-processamento fora do tuning\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprep_dados <- prep(receita)\ndados_prep <- bake(prep_dados, new_data = NULL)\n```\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndados_prep %>% \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 8,693\nColumns: 28\n$ nGroup                    <dbl> -0.4911332, -0.4911332, -0.4911332, 0.457416‚Ä¶\n$ CabinNum                  <dbl> -1.88552650, -1.88552650, -1.88552650, -1.88‚Ä¶\n$ Age                       <dbl> 0.70841598, -0.33569386, 2.03095510, 0.29077‚Ä¶\n$ RoomService               <dbl> -0.6523874, 1.0620923, 0.7278793, -0.6523874‚Ä¶\n$ FoodCourt                 <dbl> -0.6640943, 0.1155437, 2.1063642, 1.7594612,‚Ä¶\n$ ShoppingMall              <dbl> -0.63553377, 0.62593994, -0.63553377, 1.6561‚Ä¶\n$ Spa                       <dbl> -0.6780625, 1.5859232, 2.4837539, 2.2320499,‚Ä¶\n$ VRDeck                    <dbl> -0.65344522, 0.72259213, 0.76067799, 1.25078‚Ä¶\n$ GroupSize                 <dbl> -0.6486974, -0.6486974, -0.0222670, -0.02226‚Ä¶\n$ despesasSuperfluas        <dbl> -0.96031582, 1.63333401, 1.92940474, 1.38153‚Ä¶\n$ despesasBasicas           <dbl> -0.8759684, 0.4760396, 1.1134474, 2.3034453,‚Ä¶\n$ HomePlanet_Earth          <dbl> -1.0605560, 0.9427932, -1.0605560, -1.060556‚Ä¶\n$ HomePlanet_Europa         <dbl> 1.7546941, -0.5698344, 1.7546941, 1.7546941,‚Ä¶\n$ HomePlanet_Mars           <dbl> -0.5036351, -0.5036351, -0.5036351, -0.50363‚Ä¶\n$ CryoSleep_TRUE.           <dbl> 1.228852, -0.813674, -0.813674, -0.813674, -‚Ä¶\n$ CabinDeck_B               <dbl> 3.1871633, -0.3137225, -0.3137225, -0.313722‚Ä¶\n$ CabinDeck_C               <dbl> -0.3065922, -0.3065922, -0.3065922, -0.30659‚Ä¶\n$ CabinDeck_D               <dbl> -0.2412044, -0.2412044, -0.2412044, -0.24120‚Ä¶\n$ CabinDeck_E               <dbl> -0.3347395, -0.3347395, -0.3347395, -0.33473‚Ä¶\n$ CabinDeck_F               <dbl> -0.6881752, 1.4529512, -0.6881752, -0.688175‚Ä¶\n$ CabinDeck_G               <dbl> -0.6458598, -0.6458598, -0.6458598, -0.64585‚Ä¶\n$ CabinSide_S               <dbl> -1.0113959, 0.9886188, 0.9886188, 0.9886188,‚Ä¶\n$ Destination_X55.Cancri.e  <dbl> -0.5109838, -0.5109838, -0.5109838, -0.51098‚Ä¶\n$ Destination_PSO.J318.5.22 <dbl> -0.3174684, -0.3174684, -0.3174684, -0.31746‚Ä¶\n$ Destination_TRAPPIST.1e   <dbl> 0.6852732, 0.6852732, 0.6852732, 0.6852732, ‚Ä¶\n$ IsAlone_X1                <dbl> 0.8994799, 0.8994799, -1.1116257, -1.1116257‚Ä¶\n$ Isearth_X1                <dbl> -1.0605560, 0.9427932, -1.0605560, -1.060556‚Ä¶\n$ Iskid_X1                  <dbl> -0.353350, -0.353350, -0.353350, -0.353350, ‚Ä¶\n```\n\n\n:::\n:::\n\n\n## Verificando a Estrutura de Agrupamento com PCA\n\nAntes de aplicar algoritmos de clusteriza√ß√£o, √© essencial compreender a estrutura de correla√ß√£o intr√≠nseca dos dados, ou seja, se os dados realmente apresentam ind√≠cios de agrupamentos naturais. Uma das formas mais eficazes e intuitivas de verificar isso √© por meio de uma an√°lise explorat√≥ria baseada em An√°lise de Componentes Principais (PCA).\n\nA PCA reduz a dimensionalidade dos dados ao projet√°-los em um novo sistema de eixos ortogonais (as componentes principais) que maximizam a vari√¢ncia explicada. Ao analisar os dados projetados nas duas primeiras componentes principais, √© poss√≠vel visualizar poss√≠veis agrupamentos naturais, outliers e sobreposi√ß√µes.\n\nEssa visualiza√ß√£o tamb√©m permite:\n\n- Avaliar a separabilidade dos grupos esperados;\n\n- Identificar vari√°veis que mais contribuem para a estrutura dos dados;\n\n- Decidir se faz sentido aplicar t√©cnicas de clusteriza√ß√£o.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npca_result <- prcomp(dados_prep, center = TRUE, scale. = TRUE)\nfviz_pca_ind(pca_result, col.ind = \"grey70\") \n```\n\n::: {.cell-output-display}\n![](space_titanic_cluster_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n## Defini√ß√£o dos modelos K-means e Hier√°rquico\n\nAntes de ajustarmos os modelos de clusteriza√ß√£o, √© necess√°rio definir suas configura√ß√µes por meio dos *model specifications* no framework `tidymodels`, utilizando o pacote `tidyclust`. Essa etapa permite estabelecer os principais par√¢metros do modelo, como o n√∫mero de grupos a ser ajustado (`tune()`), o mecanismo de execu√ß√£o (`engine`) e o modo de opera√ß√£o (`partition` para m√©todos de agrupamento).\n\nAtualmente, o pacote `tidyclust` oferece suporte apenas a dois algoritmos de clusteriza√ß√£o: **K-means** e **Clusteriza√ß√£o Hier√°rquica Aglomerativa**. A seguir, criamos as especifica√ß√µes para esses dois m√©todos:\n\n- `kmeans_spec`: define o modelo K-means, que busca particionar os dados em grupos minimizando a variabilidade interna de cada cluster.\n\n- `hclust_spec`: define o modelo hier√°rquico, com liga√ß√£o do tipo `ward.D`, que constr√≥i agrupamentos de forma incremental buscando minimizar o aumento da vari√¢ncia total entre grupos.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkmeans_spec <- k_means(num_clusters = tune()) %>%\n  set_engine(\"stats\") %>%\n  set_mode(\"partition\")\n\nhclust_spec <- hier_clust(num_clusters = tune(), linkage_method = \"ward.D2\") %>%\n  set_engine(\"stats\") %>%\n  set_mode(\"partition\")\n```\n:::\n\n\n\nAmbas as especifica√ß√µes usam o motor `stats`, que corresponde √†s implementa√ß√µes nativas do R. Essas defini√ß√µes servir√£o como base para a constru√ß√£o dos *workflows* de clusteriza√ß√£o, permitindo a valida√ß√£o cruzada e o ajuste autom√°tico do n√∫mero ideal de grupos com base nos dados analisados.\n\n## Tuning com valida√ß√£o cruzada\n\nCom as especifica√ß√µes dos modelos definidas, o pr√≥ximo passo consiste na constru√ß√£o dos *workflows* e na execu√ß√£o do processo de ajuste dos hiperpar√¢metros, neste caso, o n√∫mero de clusters.\n\nPrimeiramente, utilizamos a fun√ß√£o `vfold_cv()` para gerar um esquema de valida√ß√£o cruzada com 5 parti√ß√µes, garantindo uma avalia√ß√£o robusta da performance dos modelos em diferentes subconjuntos dos dados (`dados_prep`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfolds_prep <- vfold_cv(dados_prep, v = 5)\n```\n:::\n\n\nEm seguida, criamos dois *workflows*, um para o modelo K-means e outro para o modelo Hier√°rquico. Ambos s√£o configurados para usar todos os preditores dispon√≠veis na base de dados `(~ .)` e incorporam suas respectivas especifica√ß√µes (`kmeans_spec` e `hclust_spec`).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf_kmeans <- workflow() %>% add_model(kmeans_spec) %>% add_formula(~ .)\nwf_hclust <- workflow() %>% add_model(hclust_spec) %>% add_formula(~ .)\n```\n:::\n\n\nO grid de valores para o hiperpar√¢metro `num_clusters` √© definido entre 2 e 10, permitindo que o processo de tuning explore diferentes poss√≠veis quantidades de agrupamentos.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid <- tibble(num_clusters = 2:6)\n```\n:::\n\n\nPor fim, aplicamos a fun√ß√£o `tune_cluster()` para cada modelo, realizando o ajuste do n√∫mero de clusters com base na m√©trica de avalia√ß√£o silhueta m√©dia (`silhouette_avg`), uma medida amplamente utilizada para quantificar a qualidade dos agrupamentos formados. Essa m√©trica avalia o qu√£o bem cada ponto est√° agrupado com seus vizinhos em compara√ß√£o com outros clusters.\n\nEsse processo nos permitir√° comparar o desempenho dos modelos e selecionar o n√∫mero ideal de grupos de forma sistem√°tica e fundamentada.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. Plano com paralelismo\nplan(multisession, workers = parallel::detectCores() - 1)\nregisterDoFuture()\n\nhandlers(\"txtprogressbar\")  # ou \"progress\"\n\ntic()\nwith_progress({\nres_kmeans <- tune_cluster(\n  wf_kmeans,\n  resamples = folds_prep,\n  grid = grid,\n  metrics = cluster_metric_set(silhouette_avg)\n)\n})\n\nwith_progress({\nres_hclust <- tune_cluster(\n  wf_hclust,\n  resamples = folds_prep,\n  grid = grid,\n  metrics = cluster_metric_set(silhouette_avg)\n)\n})\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n1775.67 sec elapsed\n```\n\n\n:::\n:::\n\n\n## Resultados e melhor modelo\n\nAp√≥s a execu√ß√£o do processo de tuning com valida√ß√£o cruzada, o pr√≥ximo passo √© identificar o n√∫mero ideal de clusters para cada modelo com base na m√©trica de avalia√ß√£o escolhida, neste caso, a silhueta m√©dia (`silhouette_avg`). Essa m√©trica indica qu√£o bem as observa√ß√µes est√£o agrupadas: valores pr√≥ximos de 1 sugerem melhor separa√ß√£o entre os grupos.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmelhor_kmeans <- select_best(res_kmeans, metric = \"silhouette_avg\")\nmelhor_hclust <- select_best(res_hclust, metric = \"silhouette_avg\")\n```\n:::\n\n\n\nUtilizamos a fun√ß√£o `select_best()` para extrair, de forma autom√°tica, o valor de `num_clusters` que resultou na melhor performance para cada modelo. Em seguida, atualizamos as especifica√ß√µes dos modelos K-means e Hier√°rquico com o n√∫mero de clusters √≥timo encontrado.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkmeans_final <- k_means(num_clusters = melhor_kmeans$num_clusters) %>%\n  set_engine(\"stats\") %>%\n  set_mode(\"partition\")\n\nhclust_final <- hier_clust(num_clusters = melhor_hclust$num_clusters, linkage_method = \"ward.D\") %>%\n  set_engine(\"stats\") %>%\n  set_mode(\"partition\")\n```\n:::\n\n\nCom os modelos atualizados, recriamos os *workflows* finais utilizando a fun√ß√£o `update_model()`, garantindo que cada *workflow* reflita o melhor n√∫mero de grupos encontrado durante o tuning.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nworkflow_final_kmeans <- wf_kmeans %>%\n  update_model(kmeans_final)\n\nworkflow_final_hclust <- wf_hclust %>%\n  update_model(hclust_final)\n```\n:::\n\n\n\nPor fim, ajustamos os modelos finais aos dados completos (`dados_prep`) utilizando a fun√ß√£o `fit()`. As predi√ß√µes geradas (`predict()`) nos fornecem os r√≥tulos de cluster para cada observa√ß√£o, permitindo identificar a qual grupo cada indiv√≠duo foi atribu√≠do. Esses r√≥tulos s√£o armazenados nas vari√°veis `grupos_kmeans` e `grupos_hierarquico`, que ser√£o posteriormente utilizados para interpreta√ß√£o e visualiza√ß√£o dos padr√µes encontrados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo_final_kmeans <- fit(workflow_final_kmeans, data = dados_prep)\ngrupos_kmeans <- as.factor(predict(modelo_final_kmeans, new_data = dados_prep)$.pred_cluster)\n\nmodelo_final_hclust <- fit(workflow_final_hclust, data = dados_prep)\ngrupos_hierarquico <- as.factor(predict(modelo_final_hclust, new_data = dados_prep)$.pred_cluster)\n```\n:::\n\n\n\nEsse processo assegura que os modelos finais utilizados para an√°lise estejam otimizados em rela√ß√£o √† estrutura dos dados e fundamentados em uma m√©trica de qualidade apropriada para tarefas de clusteriza√ß√£o.\n\n## Visualiza√ß√£o de Grupos Gerados via PCA\n\nEm tarefas de clusteriza√ß√£o, √© comum gerar agrupamentos com base em medidas de similaridade ou dist√¢ncia entre observa√ß√µes. No entanto, como os dados frequentemente t√™m muitas vari√°veis (ou dimens√µes), torna-se desafiador visualizar e interpretar os agrupamentos diretamente no espa√ßo original.\n\nPara lidar com esse problema, uma t√©cnica amplamente utilizada √© a An√°lise de Componentes Principais (`PCA`). A `PCA` transforma os dados originais em um novo sistema de coordenadas formado por componentes principais, isto √©, combina√ß√µes lineares das vari√°veis originais que maximizam a vari√¢ncia explicada. As duas primeiras componentes geralmente capturam a maior parte da estrutura dos dados, possibilitando uma visualiza√ß√£o bidimensional informativa.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_pca_ind(\n  pca_result,\n  geom.ind = \"point\",\n  col.ind = grupos_kmeans,\n  palette = \"Set2\",\n  addEllipses = TRUE,\n  legend.title = \"Grupo\",\n  title = \"Visualiza√ß√£o dos Grupos Formados no Espa√ßo das Componentes Principais\"\n)\n```\n\n::: {.cell-output-display}\n![](space_titanic_cluster_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n\n```{.r .cell-code}\nfviz_pca_ind(\n  pca_result,\n  geom.ind = \"point\",\n  col.ind = grupos_hierarquico,\n  palette = \"Set2\",\n  addEllipses = TRUE,\n  legend.title = \"Grupo\",\n  title = \"Visualiza√ß√£o dos Grupos Formados no Espa√ßo das Componentes Principais\"\n)\n```\n\n::: {.cell-output-display}\n![](space_titanic_cluster_files/figure-html/unnamed-chunk-19-2.png){width=672}\n:::\n:::\n\n\nAo projetar os dados nesse plano PCA e colorir os pontos de acordo com os grupos gerados por um algoritmo de clusteriza√ß√£o, conseguimos:\n\n- Visualizar a separa√ß√£o (ou sobreposi√ß√£o) entre os grupos;\n\n- Avaliar a qualidade da segmenta√ß√£o de forma intuitiva;\n\n- Identificar outliers ou observa√ß√µes amb√≠guas;\n\n- Validar visualmente se h√° coer√™ncia entre os agrupamentos e a estrutura intr√≠nseca dos dados.\n\nAl√©m disso, o uso de elipses de confian√ßa pode refor√ßar a no√ß√£o de centralidade e dispers√£o de cada grupo, tornando a visualiza√ß√£o ainda mais interpret√°vel.\n\n\n\n## Tuning manual de DBSCAN, MeanShift e SOM\n\n\nDiferentemente dos m√©todos K-means e Hierarchical Clustering, que podem ser facilmente integrados ao framework `tidyclust` e ajustados automaticamente via valida√ß√£o cruzada com `tune_cluster()`, os algoritmos DBSCAN, MeanShift e Redes SOM exigem uma abordagem manual de tuning dos hiperpar√¢metros. Isso se deve a caracter√≠sticas espec√≠ficas desses modelos e √†s limita√ß√µes atuais das interfaces automatizadas.\n\n\n\n### Tuning de DBSCAN\n\nComo o algoritmo DBSCAN n√£o possui uma etapa autom√°tica de ajuste de hiperpar√¢metros integrada ao `tidyclust`, √© necess√°rio realizar o tuning manual dos dois par√¢metros fundamentais do modelo:\n\n- `eps`: raio de vizinhan√ßa que define a densidade m√≠nima em torno de um ponto;\n\n- `minPts`: n√∫mero m√≠nimo de pontos necess√°rio para formar uma regi√£o densa (n√∫cleo do cluster).\n\nPara facilitar esse processo, definimos a fun√ß√£o `avaliar_dbscan()`, que recebe diferentes combina√ß√µes de `eps` e `minPts` e avalia o desempenho do modelo com base na m√©dia do √≠ndice de silhueta, uma m√©trica que quantifica o qu√£o bem cada observa√ß√£o est√° agrupada.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\navaliar_dbscan <- function(eps, minPts, dados) {\n  modelo <- dbscan::dbscan(dados, eps = eps, minPts = minPts)\n\n  # Remove ru√≠do (cluster 0)\n  grupos <- modelo$cluster\n  grupos_validos <- grupos[grupos != 0]\n  n_clusters <- length(unique(grupos_validos))\n\n  # Calcular a silhueta apenas se houver pelo menos dois grupos distintos (al√©m de ru√≠do)\n  if (n_clusters > 1) {\n    sil <- silhouette(grupos, dist(dados))\n    media_sil <- mean(sil[, 3], na.rm = TRUE)\n  } else {\n    media_sil <- NA_real_\n  }\n\n  tibble(\n    eps = eps,\n    minPts = minPts,\n    n_clusters = n_clusters,\n    silhueta = media_sil\n  )\n}\n```\n:::\n\n\n\nEssa abordagem permite montar uma `grid` de busca com diferentes valores de `eps` e `minPts`, testando v√°rias combina√ß√µes para selecionar aquela que maximiza a separa√ß√£o entre os clusters e minimiza a presen√ßa de ru√≠do.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Grid de hiperpar√¢metros\neps_grid <- seq(3.0, 4.0, by = 0.1)\nminPts_grid <- seq(10, 30, by = 2)   # M√≠nimo de pontos mais restritivo\n```\n:::\n\n\nSeguindo, construimos um grid de par√¢metros por meio da fun√ß√£o `expand.grid()`, combinando todos os valores poss√≠veis de `eps` e `minPts` definidos previamente nas vari√°veis `eps_grid` e `minPts_grid`. Utilizamos a fun√ß√£o `pmap_dfr()` (do pacote `purrr`) para aplicar a fun√ß√£o `avaliar_dbscan()` a cada combina√ß√£o da grid. O argumento `.progress =` permite o acompanhamento da execu√ß√£o, √∫til especialmente em grades extensas.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\ndbscan_results <- expand.grid(eps = eps_grid, minPts = minPts_grid) %>%\n  mutate(silhouette = pmap_dfr(list(eps, minPts), avaliar_dbscan, dados = dados_prep, .progress = FALSE)) %>%\n  drop_na() %>%\n  arrange(desc(silhouette$silhueta))\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n373.43 sec elapsed\n```\n\n\n:::\n:::\n\n\nOs resultados s√£o ordenados em ordem decrescente de acordo com a silhueta m√©dia, permitindo identificar rapidamente os conjuntos de par√¢metros que produziram os melhores agrupamentos em termos de coes√£o e separa√ß√£o dos grupos.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmelhor_dbscan <- dbscan_results %>%\n  filter(!is.na(silhouette$silhueta), silhouette$n_clusters == 3) %>%\n  arrange(desc(silhouette$silhueta)) %>%\n  slice(1) %>%\n  pull(silhouette)\n```\n:::\n\n\nCom os valores ideais de `eps` e `minPts` em m√£os, ajustamos o modelo DBSCAN final sobre os dados completos (`dados_prep`). Os r√≥tulos de cluster atribu√≠dos pelo modelo s√£o armazenados em `grupos_dbscan`, e podem assumir os valores 1, 2, 3 para os grupos v√°lidos e 0 para os pontos classificados como ru√≠do.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo_dbscan <- dbscan(dados_prep, eps = melhor_dbscan$eps, minPts = melhor_dbscan$minPts)\ngrupos_dbscan <- as.factor(modelo_dbscan$cluster)\n```\n:::\n\n\n\nPara facilitar a interpreta√ß√£o visual dos agrupamentos encontrados, utilizamos novamente a proje√ß√£o PCA.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_pca_ind(\n  pca_result,\n  geom.ind = \"point\",\n  col.ind = grupos_dbscan,\n  palette = \"Set2\",\n  addEllipses = TRUE,\n  legend.title = \"Grupo\",\n  title = \"Visualiza√ß√£o dos Grupos Formados no Espa√ßo das Componentes Principais\"\n)\n```\n\n::: {.cell-output-display}\n![](space_titanic_cluster_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n\n\n### Tuning de MeanShift\n\nO algoritmo **MeanShift** √© um m√©todo de clusteriza√ß√£o baseado em densidade que n√£o exige a defini√ß√£o pr√©via do n√∫mero de clusters. No entanto, seu desempenho √© altamente sens√≠vel √† escolha do par√¢metro `bandwidth`, que determina o raio de influ√™ncia ao redor de cada ponto para estimar os modos da distribui√ß√£o dos dados.\n\nComo o `tidyclust` ainda n√£o oferece suporte nativo ao MeanShift, a defini√ß√£o do melhor modelo deve ser feita manual e empiricamente, avaliando diferentes valores de `bandwidth`.\n\nPara isso, implementamos duas fun√ß√µes: A fun√ß√£o `avaliar_meanshift()`, que aplica o algoritmo `meanShiftR::meanShift()` a uma matriz de dados com um vetor de `bandwidth` (um valor para cada vari√°vel)\n\n\n::: {.cell}\n\n```{.r .cell-code}\navaliar_meanshift <- function(bandwidth, dados) {\n  # Aplica o MeanShift com o vetor de bandwidth\n  modelo <- meanShiftR::meanShift(dados, bandwidth = bandwidth)\n\n  # Grupos\n  grupos <- modelo$assignment + 1\n\n  # Verifica se h√° mais de um grupo\n  if (length(unique(grupos)) < 2) {\n    return(tibble(\n      bandwidth = list(bandwidth),\n      silhueta = NA_real_,\n      n_clusters = 1\n    ))\n  }\n\n  # Calcula silhueta\n  sil <- silhouette(grupos, dist(dados))\n  sil_media <- mean(sil[, 3])\n\n  # Retorna tibble\n  tibble(\n    bandwidth = list(bandwidth),\n    silhueta = sil_media,\n    n_clusters = length(unique(grupos))\n  )\n}\n```\n:::\n\n\nE a fun√ß√£o `tuning_meanshift()`, que gera uma grid de vetores de `bandwidth` multiplicando o desvio padr√£o de cada vari√°vel por uma sequ√™ncia de fatores escalares (de 1.5 a 5.0). Para cada vetor de `bandwidth`, aplicamos a fun√ß√£o `avaliar_meanshift()` e armazenamos os resultados, possibilitando identificar a combina√ß√£o que resulta na melhor estrutura de agrupamento com base na silhueta m√©dia.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntuning_meanshift <- function(dados) {\n  # Grid de escalas maiores para reduzir o n√∫mero de grupos\n  sd_vars <- apply(dados, 2, sd)\n  escalas <- seq(1.5, 5, by = 0.1)\n  bw_grid <- lapply(escalas, function(e) e * sd_vars)\n\n  # Avalia cada vetor de bandwidth\n  resultados <- purrr::map_dfr(bw_grid, ~avaliar_meanshift(.x, dados))\n\n  return(resultados)\n}\n```\n:::\n\n\nO objeto final `resultado` cont√©m todas as combina√ß√µes testadas e suas respectivas performances, servindo de base para a escolha do `bandwidth` ideal para o modelo MeanShift.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nresultado <- tuning_meanshift(as.matrix(dados_prep))\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n2781.31 sec elapsed\n```\n\n\n:::\n:::\n\n\n\nAp√≥s testarmos diversas combina√ß√µes de `bandwidth` utilizando a fun√ß√£o `tuning_meanshift()`, o pr√≥ximo passo consiste em selecionar a melhor configura√ß√£o para o modelo MeanShift com base na silhueta m√©dia.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmelhor_bw <- resultado %>%\n  filter(!is.na(silhueta), n_clusters > 1) %>%\n  arrange(desc(silhueta)) %>%\n  slice(1) %>%\n  pull(bandwidth) %>%\n  .[[1]]\n\n\nmodelo_meanshift <- meanShift(as.matrix(dados_prep), bandwidth = melhor_bw)\ngrupos_meanshift <- as.factor(modelo_meanshift$assignment)\n```\n:::\n\n\n\nOs r√≥tulos de cluster obtidos pelo modelo s√£o ent√£o utilizados para construir uma visualiza√ß√£o bidimensional via PCA, facilitando a interpreta√ß√£o visual dos agrupamentos. No gr√°fico gerado, cada ponto representa uma observa√ß√£o, posicionada de acordo com os escores das componentes e colorida segundo o cluster ao qual pertence.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_pca_ind(\n  pca_result,\n  geom.ind = \"point\",\n  col.ind = grupos_meanshift,\n  palette = \"Set2\",\n  addEllipses = TRUE,\n  legend.title = \"Grupo\",\n  title = \"Visualiza√ß√£o dos Grupos Formados no Espa√ßo das Componentes Principais\"\n)\n```\n\n::: {.cell-output-display}\n![](space_titanic_cluster_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\n\n### Tuning de Redes SOM (Kohonen)\n\nDiferentemente de m√©todos cl√°ssicos como K-means, as Redes de Kohonen (SOM ‚Äì Self-Organizing Maps) formam agrupamentos de forma n√£o supervisionada a partir de uma grade de neur√¥nios, cuja estrutura (dimens√£o, topologia, taxa de aprendizado, n√∫mero de itera√ß√µes) impacta diretamente a qualidade dos grupos formados.\n\nComo o pacote `tidyclust` ainda n√£o oferece suporte direto para SOMs, o processo de tuning dos hiperpar√¢metros deve ser feito manualmente. Para isso, foi criada a fun√ß√£o `avaliar_som()`, que recebe os principais hiperpar√¢metros do modelo e avalia sua performance de clusteriza√ß√£o por meio do √≠ndice de silhueta m√©dia.\n\n\n::: {.cell}\n\n```{.r .cell-code}\navaliar_som <- function(xdim, ydim, topo, rlen, alpha, dados) {\n  grid <- somgrid(xdim = xdim, ydim = ydim, topo = topo)\n  \n  modelo <- som(\n    X = dados,\n    grid = grid,\n    rlen = rlen,\n    alpha = alpha,\n    keep.data = TRUE\n  )\n  \n  grupos <- modelo$unit.classif\n  \n  if (length(unique(grupos)) < 2) {\n    return(tibble(\n      xdim = xdim,\n      ydim = ydim,\n      topo = topo,\n      rlen = rlen,\n      alpha = paste(alpha, collapse = \"-\"),\n      silhueta = NA_real_,\n      n_clusters = length(unique(grupos))\n    ))\n  }\n  \n  sil <- silhouette(grupos, dist(dados))\n  sil_media <- mean(sil[, 3])\n  \n  tibble(\n    xdim = xdim,\n    ydim = ydim,\n    topo = topo,\n    rlen = rlen,\n    alpha = paste(alpha, collapse = \"-\"),\n    silhueta = sil_media,\n    n_clusters = length(unique(grupos))\n  )\n}\n```\n:::\n\n\nAntes de iniciar o ajuste de modelos SOM, √© necess√°rio definir uma grid de busca com diferentes combina√ß√µes de hiperpar√¢metros, permitindo explorar sistematicamente o impacto de cada configura√ß√£o na qualidade dos agrupamentos formados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxdim_vals <- 2:5\nydim_vals <- 2:5\ntopo_vals <- c(\"rectangular\", \"hexagonal\")\nrlen_vals <- c(50, 100, 200, 400)\nalpha_vals <- list(c(0.05, 0.01), c(0.1, 0.01), c(0.15, 0.01), c(0.2, 0.01))\n\ngrid_som <- expand.grid(\n  xdim = xdim_vals,\n  ydim = ydim_vals,\n  topo = topo_vals,\n  rlen = rlen_vals,\n  alpha = I(alpha_vals),  # evita descompactar a lista\n  stringsAsFactors = FALSE \n)\n```\n:::\n\n\nO c√≥digo acima constr√≥i o grid utilizando a fun√ß√£o `expand.grid()`, combinando os principais par√¢metros que controlam o comportamento da rede SOM:\n\n- `xdim` e `ydim`: definem as dimens√µes da grade de neur√¥nios (por exemplo, uma grade 3x3 possui 9 unidades de sa√≠da). Grades maiores permitem maior resolu√ß√£o nos agrupamentos, mas podem aumentar a complexidade e o risco de overfitting.\n\n- `topo`: especifica a topologia da grade, podendo ser:\n    -  `rectangular`: disposi√ß√£o cl√°ssica dos neur√¥nios em linhas e colunas.\n    - `hexagonal`: cada neur√¥nio possui mais vizinhos imediatos, o que suaviza a transi√ß√£o entre clusters.\n\n- `rlen`: define o n√∫mero de itera√ß√µes de treinamento da rede. Quanto maior o valor, maior o tempo de treinamento, mas tamb√©m a chance de converg√™ncia mais est√°vel.\n\n- `alpha`: um vetor com dois valores que especificam a taxa de aprendizado inicial e final. Taxas maiores aceleram o aprendizado no in√≠cio, mas podem comprometer a estabilidade; taxas menores favorecem ajustes mais precisos no final do treinamento.\n\n\nUma observa√ß√£o importante para o par√¢metro `alpha` √© que ele √© passada como uma lista (`I(alpha_vals)`) para garantir que cada vetor `c(valor_inicial, valor_final)` seja tratado como uma unidade indivis√≠vel durante a expans√£o da grid. Isso evita que o `expand.grid()` desfa√ßa os pares de taxas de aprendizado.\n\nO objeto `grid_som` resultante cont√©m todas as poss√≠veis combina√ß√µes entre os valores de cada hiperpar√¢metro, e ser√° utilizado para ajustar e avaliar diferentes modelos SOM via a fun√ß√£o `avaliar_som()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nresultado_som <- pmap_dfr(\n  grid_som,\n  function(xdim, ydim, topo, rlen, alpha) {\n    avaliar_som(xdim, ydim, topo, rlen, alpha, dados = as.matrix(dados_prep))\n  }\n)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n1224.41 sec elapsed\n```\n\n\n:::\n:::\n\n\n\nAp√≥s a avalia√ß√£o das diversas combina√ß√µes de hiperpar√¢metros, selecionamos agora a melhor configura√ß√£o da rede SOM com base nos seguintes crit√©rios:\n\n- Forma√ß√£o de no m√°ximo 5 clusters, evitando segmenta√ß√µes excessivamente fragmentadas.\n\n- Maior silhueta m√©dia, indicando uma boa separa√ß√£o e coes√£o entre os grupos formados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmelhor_som <- resultado_som %>%\n  filter(n_clusters <= 5) %>%\n  arrange(desc(silhueta)) %>%\n  slice(1)\n```\n:::\n\n\nCom os par√¢metros selecionados, configuramos a grade de neur√¥nios com `somgrid()`, especificando o n√∫mero de neur√¥nios (`xdim` √ó `ydim`) e a topologia (`topo`). Em seguida, o modelo SOM √© ajustado com:\n\n- Os dados preparados (`dados_prep`);\n\n- O n√∫mero de √©pocas de treinamento (`rlen`);\n\n- A taxa de aprendizado inicial e final (`alpha`), convertida novamente de texto para vetor num√©rico.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid <- somgrid(xdim = melhor_som$xdim, ydim = melhor_som$ydim, topo = melhor_som$topo)\n\nmodelo_som <- kohonen::som(\n  X = as.matrix(dados_prep),\n  grid = grid,\n  rlen = melhor_som$rlen,\n  alpha = as.numeric(strsplit(melhor_som$alpha, \"-\")[[1]]),\n  keep.data = TRUE\n)\n```\n:::\n\n\n\nA sa√≠da `modelo_som$unit.classif` fornece os neur√¥nios vencedores (clusters) para cada observa√ß√£o, representando os grupos aos quais os dados foram atribu√≠dos.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrupos_som <- modelo_som$unit.classif\n```\n:::\n\n\n\nPara interpretar os resultados, aplicamos uma proje√ß√£o PCA sobre os dados e colorimos os pontos com base nos grupos atribu√≠dos pela rede SOM. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_pca_ind(\n  pca_result,\n  geom.ind = \"point\",\n  col.ind = factor(grupos_som),\n  palette = \"Set2\",\n  addEllipses = TRUE,\n  legend.title = \"Grupo\",\n  title = \"Visualiza√ß√£o dos Grupos Formados no Espa√ßo das Componentes Principais\"\n)\n```\n\n::: {.cell-output-display}\n![](space_titanic_cluster_files/figure-html/unnamed-chunk-37-1.png){width=672}\n:::\n:::\n\n\n\n\n## An√°lise dos Clusters\n\nAp√≥s aplicar diferentes algoritmos de clusteriza√ß√£o aos dados (K-means, DBSCAN, MeanShift, SOM e Hier√°rquico), √© importante avaliar o grau de concord√¢ncia entre os agrupamentos gerados por cada m√©todo. Para isso, utilizamos o √çndice Rand Ajustado (ARI ‚Äì Adjusted Rand Index), uma m√©trica amplamente usada para comparar parti√ß√µes, corrigindo a aleatoriedade esperada por acaso.\n\nPara isso, criamos o objeto `lista_grupos`, que armazena os vetores de r√≥tulos atribu√≠dos por cada m√©todo aos dados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlista_grupos <- list(\n  kmeans = grupos_kmeans,\n  dbscan = grupos_dbscan,\n  meanshift = grupos_meanshift,\n  som = grupos_som,\n  hierarquico = grupos_hierarquico\n)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Conta o n√∫mero de grupos √∫nicos gerados por cada m√©todo\ntabela_num_grupos <- purrr::map_int(lista_grupos, ~ n_distinct(.x)) %>%\n  tibble::enframe(name = \"Metodo\", value = \"Numero_de_Grupos\")\n\n# Exibe a tabela\ntabela_num_grupos\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 √ó 2\n  Metodo      Numero_de_Grupos\n  <chr>                  <int>\n1 kmeans                     3\n2 dbscan                     4\n3 meanshift                  3\n4 som                        4\n5 hierarquico                3\n```\n\n\n:::\n:::\n\n\n\nUtilizando a fun√ß√£o `combn()`, criamos todas as combina√ß√µes poss√≠veis de dois algoritmos para comparar seus agrupamentos entre si. Para cada par de m√©todos, aplicamos a fun√ß√£o `adjustedRandIndex()` (do pacote `mclust`), que retorna um valor entre:\n\n- 1: agrupamentos id√™nticos;\n\n- 0: agrupamentos n√£o mais concordantes do que o esperado ao acaso;\n\n- < 0: discord√¢ncia inferior ao esperado aleatoriamente.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Gerar todas as combina√ß√µes de pares de m√©todos\ncomparacao_ari <- combn(names(lista_grupos), 2, simplify = FALSE, FUN = function(par) {\n  ari_val <- adjustedRandIndex(lista_grupos[[par[1]]], lista_grupos[[par[2]]])\n  tibble(\n    metodo1 = par[1],\n    metodo2 = par[2],\n    ARI = ari_val\n  )\n}) %>%\n  bind_rows() %>%\n  arrange(desc(ARI))\n\n# Visualizar resultados\ncomparacao_ari\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 √ó 3\n   metodo1   metodo2          ARI\n   <chr>     <chr>          <dbl>\n 1 meanshift som          0.498  \n 2 kmeans    som          0.443  \n 3 kmeans    meanshift    0.353  \n 4 meanshift hierarquico  0.136  \n 5 som       hierarquico  0.136  \n 6 kmeans    dbscan       0.0376 \n 7 kmeans    hierarquico  0.00546\n 8 dbscan    som         -0.00256\n 9 dbscan    meanshift   -0.0118 \n10 dbscan    hierarquico -0.0772 \n```\n\n\n:::\n:::\n\n\n\n## Valida√ß√£o Estat√≠stica dos Agrupamentos\n\nPodemos observar que os algoritmos que aparentemente apresentaram as melhores separa√ß√µes em nossa base de dados foram o K-means e as redes SOM. Embora o K-means seja amplamente conhecido por sua velocidade e facilidade de interpreta√ß√£o, ele assume que os grupos possuem forma aproximadamente esf√©rica e tamanho similar, o que pode limitar sua aplicabilidade em dados com estruturas mais complexas. Por outro lado, o SOM √© uma t√©cnica baseada em aprendizado n√£o supervisionado que preserva rela√ß√µes topol√≥gicas e permite visualizar agrupamentos de forma intuitiva, sendo particularmente √∫til em bases com n√£o linearidades ou alta dimensionalidade.\n\n\nA partir de agora, √© fundamental ir al√©m da interpreta√ß√£o visual e realizar uma avalia√ß√£o estat√≠stica formal da validade dos grupos formados.\n\nNesta etapa, buscamos responder √† seguinte pergunta:\n\n> \"Os grupos encontrados pelos m√©todos de clusteriza√ß√£o representam subdivis√µes estatisticamente distintas com base nas vari√°veis originais dos dados?\"\n\n\n\nPara essa finalidade, a PERMANOVA (Permutational Multivariate Analysis of Variance) √© uma t√©cnica robusta e amplamente utilizada. A PERMANOVA avalia a exist√™ncia de heterogeneidade entre grupos com base em uma matriz de dist√¢ncias (como dist√¢ncias euclidianas ou de Gower), ao inv√©s de depender de pressupostos fortes como normalidade multivariada e homogeneidade das vari√¢ncias, como ocorre na MANOVA tradicional. A l√≥gica do teste baseia-se em permuta√ß√µes aleat√≥rias dos r√≥tulos dos grupos, calculando a distribui√ß√£o emp√≠rica da estat√≠stica F sob a hip√≥tese nula de que n√£o h√° diferen√ßa entre os grupos.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Definir n√∫mero de n√∫cleos (ex: todos menos 1)\nn_cores <- parallel::detectCores() - 1\n\n# Registrar o cluster\ncl <- makeCluster(n_cores)\nregisterDoParallel(cl)\n\n# Verificar se grupos est√£o no formato adequado\ngrupos_kmeans <- as.factor(grupos_kmeans)\n\n# Calcular a matriz de dist√¢ncias (ou usar diretamente no adonis2)\ndist_matrix <- dist(dados_prep, method = \"euclidean\")\n\n# Executar PERMANOVA com paraleliza√ß√£o\ntic()\nresultado_permanova <- adonis2(\n  formula = dist_matrix ~ grupos_kmeans,\n  permutations = how(nperm = 999, blocks = NULL),  # ou aumentar nperm = 5000+\n  parallel = cl\n)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n985.22 sec elapsed\n```\n\n\n:::\n\n```{.r .cell-code}\n# Encerrar cluster\nstopCluster(cl)\n\n# Exibir o resultado\nresultado_permanova\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPermutation test for adonis under reduced model\nTerms added sequentially (first to last)\nPermutation: free\nNumber of permutations: 999\n\nadonis2(formula = dist_matrix ~ grupos_kmeans, permutations = how(nperm = 999, blocks = NULL), parallel = cl)\n                Df SumOfSqs      R2      F Pr(>F)    \ngrupos_kmeans    2    52535 0.21586 1196.1  0.001 ***\nResidual      8690   190841 0.78414                  \nTotal         8692   243376 1.00000                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Definir n√∫mero de n√∫cleos (ex: todos menos 1)\nn_cores <- parallel::detectCores() - 1\n\n# Registrar o cluster\ncl <- makeCluster(n_cores)\nregisterDoParallel(cl)\n\n# Verificar se grupos est√£o no formato adequado\ngrupos_som <- as.factor(grupos_som)\n\n# Calcular a matriz de dist√¢ncias (ou usar diretamente no adonis2)\ndist_matrix <- dist(dados_prep, method = \"euclidean\")\n\n# Executar PERMANOVA com paraleliza√ß√£o\ntic()\nresultado_permanova <- adonis2(\n  formula = dist_matrix ~ grupos_som,\n  permutations = how(nperm = 999, blocks = NULL),  # ou aumentar nperm = 5000+\n  parallel = cl\n)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n1035.25 sec elapsed\n```\n\n\n:::\n\n```{.r .cell-code}\n# Encerrar cluster\nstopCluster(cl)\n\n# Exibir o resultado\nresultado_permanova\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPermutation test for adonis under reduced model\nTerms added sequentially (first to last)\nPermutation: free\nNumber of permutations: 999\n\nadonis2(formula = dist_matrix ~ grupos_som, permutations = how(nperm = 999, blocks = NULL), parallel = cl)\n             Df SumOfSqs      R2      F Pr(>F)    \ngrupos_som    3    72674 0.29861 1233.1  0.001 ***\nResidual   8689   170702 0.70139                  \nTotal      8692   243376 1.00000                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\nPodemos observar que ambos os agrupamentos s√£o estatisticamente significativos (valor-p < 0.001), indicando que h√° estrutura nos dados, ou seja, os grupos n√£o s√£o aleat√≥rios. O agrupamento por SOM com 4 grupos explica mais variabilidade (29,9%) da estrutura de dist√¢ncias do que o K-means com 3 grupos (21,6%). O valor de F tamb√©m √© maior para o SOM (1233.1 vs. 1196.1), o que refor√ßa a qualidade da separa√ß√£o em 4 grupos.\n\n\n## Perfis dos grupos gerados\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndados_com_grupos <- dados_prep %>%\n  mutate(grupo_som = factor(grupos_som))\n\nresumo_grupos <- dados_com_grupos %>%\n  group_by(grupo_som) %>%\n  summarise(across(where(is.numeric), mean, na.rm = TRUE)) %>%\n  pivot_longer(-grupo_som, names_to = \"variavel\", values_to = \"media\")\n\nggplot(resumo_grupos, aes(x = variavel, y = media, color = grupo_som, group = grupo_som)) +\n  geom_line() + geom_point() +\n  theme_minimal() +\n  labs(title = \"Perfis M√©dios por Vari√°vel e Grupo (SOM)\", x = \"\", y = \"M√©dia\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](space_titanic_cluster_files/figure-html/unnamed-chunk-43-1.png){width=672}\n:::\n:::\n\n\n\nNo gr√°fico acima, cada linha representa um dos 4 grupos gerados pela rede SOM (grupo_som de 1 a 4). O eixo x traz as vari√°veis originais da base de dados, enquanto que o eixo y representa a m√©dia padronizada de cada vari√°vel dentro de cada grupo. As diferen√ßas entre as linhas ao longo do eixo x indicam vari√°veis que mais distinguem os grupos.\n\nCom base no gr√°fico, destacam-se como importantes na separa√ß√£o entre os grupos SOM:\n\n| Vari√°vel                                    | Observa√ß√£o                                                                         |\n| ------------------------------------------- | ---------------------------------------------------------------------------------- |\n| `ShoppingMall`                              | Grupo 1 tem valores visivelmente mais altos.                                       |\n| `RoomService`, `Spa`, `VRDeck`              | Claramente mais elevados no **grupo 1**, pr√≥ximos de zero ou negativos nos outros. |\n| `FoodCourt`                                 | Tamb√©m destaca o grupo 1 com pico alto.                                            |\n| `IsAlone_X1`                                | Forte separa√ß√£o: grupo 3 com valor m√≠nimo, grupo 1 e 4 mais elevados.              |\n| `HomePlanet_Earth`                          | Grupo 2 se diferencia nitidamente dos demais.                                      |\n| `HomePlanet_Mars`                           | Grupo 1 com valor fortemente negativo (quase -1), indicando aus√™ncia.              |\n| `Destination_TRAPPIST-1e`                   | Varia√ß√£o clara entre os grupos, sobretudo entre 1 e 3.                             |\n| `CryoSleep_TRUE.`                           | Separa√ß√£o vis√≠vel entre grupos 1/3 e 2/4.                                          |\n| `CabinDeck_B`, `CabinDeck_C`, `CabinDeck_F` | Alguns grupos t√™m picos bem distintos, sugerindo uso diferente das cabines.        |\n\n\n### Interpreta√ß√£o geral dos grupos\n\n- **Grupo 1:** parece composto por passageiros com alto consumo de servi√ßos (`RoomService`, `Spa`, `VRDeck`, `FoodCourt`, `ShoppingMall`), geralmente n√£o dormindo em `CryoSleep`, e com valores extremos em v√°rias vari√°veis.\n  - **Perfil:** Passageiros ativos, soci√°veis, consumidores de servi√ßos, n√£o em criogenia, principalmente da Terra e viajando para TRAPPIST-1e.\n\n- **Grupo 2:** mostra valores mais centrados, destaca-se por `HomePlanet_Earth` e padr√µes mais equilibrados.\n  - **Perfil:** Grupo moderado, com pouca atividade em servi√ßos pagos, viagem equilibrada entre sozinhos e acompanhados, origem majorit√°ria da Terra, mas n√£o se destacam por extremos.\n\n\n- **Grupo 3:** possui v√°rios valores m√©dios negativos, baixa presen√ßa de servi√ßos, e maior chance de estar sozinho (`IsAlone`).\n  - **Perfil:** Passageiros com perfil econ√¥mico, viagem solit√°ria, em criogenia, oriundos de Marte, com destino alternativo.\n\n- **Grupo 4:** flutua, mas tem valores mais elevados em algumas categorias como `CabinDeck_E` e `VRDeck`.\n  - **Perfil:** Grupo com forte localiza√ß√£o em Deck G, com uso moderado de servi√ßos e perfil h√≠brido, sem comportamento extremo.\n\nO gr√°fico evidencia que vari√°veis relacionadas ao consumo de servi√ßos, plano de viagem (`HomePlanet`/`Destination`) e caracter√≠sticas de cabine s√£o as principais respons√°veis pela separa√ß√£o dos grupos SOM. Isso demonstra que a SOM foi eficaz em capturar padr√µes de comportamento e perfil de passageiros.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}