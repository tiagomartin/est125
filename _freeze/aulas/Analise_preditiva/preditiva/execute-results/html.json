{
  "hash": "6af62fc5dc3d16459eef277ead63f12a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Análise Preditiva\"\nformat: \n  revealjs:\n    width: 1600\n    height: 900\n    footer: \"\"\n    theme: quartomonothemer.scss\n    slide-number: c/t\n    show-slide-number: all\nincremental: false\ncode-link: true\nbibliography: references.bib\ntitle-slide-attributes:\n    data-background-image: /images/back.jpeg\n    data-background-size: cover\n    data-background-opacity: \"0.3\"\n---\n\n\n# Machine Learning\n\n## O que é Inteligência Artificial (IA)?\n\n:::: {.columns}\n::: {.column width=\"40%\"}\n\n<br>\n\n![](/images/IA.png){fig.align=\"right\" width=120%}\n:::\n\n::: {.column width=\"60%\"}\n\n<br>\n\n<p align=\"center\"> \nA capacidade de um **sistema computacional** simular **habilidades cognitivas humanas** \n</p>\n\n<br>\n\n\n- Visão Computacional\n\n- Processamento de Linguagem Natural\n\n- Robótica \n\n- Machine Learning\n:::\n::::\n\n\n## O que é Inteligência Artificial (IA)?\n\n<br>\n\n![](/images/linha_IA.png){fig.align=\"center\" width=120%}\n\n\n## O que é Machine Learning?\n\n<p align=\"center\">\nUm subcampo da IA que permite que sistemas aprendam a partir de dados, sem serem explicitamente programados\n</p>\n\n<br>\n\n![](/images/PT_ML.png){fig.align=\"center\" width=80%}\n\n## O que é Machine Learning?\n\n:::: {.columns}\n\n::: {.column width=\"20%\"}\n<span style='font-size:200px;'>&#128202;</span> \n:::\n\n::: {.column width=\"80%\"}\n<p align=\"center\">\nDo ponto de vista da **Estatística**, Machine Learning (ML) é uma extensão e uma aplicação computacional de métodos estatísticos com um forte **foco em predição** e **descoberta de padrões em dados**, muitas vezes em larga escala e com **menor ênfase na inferência causal tradicional**.\n</p>\n:::\n\n::::\n\n\n. . .\n\n\n:::: {.columns}\n\n::: {.column width=\"20%\"}\n<span style='font-size:200px;'>&#128187;</span> \n:::\n\n::: {.column width=\"80%\"}\n<p align=\"center\">\nDo ponto de vista da **Ciência da Computação**, Machine Learning (ML) é um campo que se concentra no **desenvolvimento de algoritmos** e sistemas computacionais que podem **aprender a partir de dados** para realizar tarefas **sem serem explicitamente programados** para cada uma delas.\n</p>\n:::\n\n::::\n\n\n## O que é Machine Learning?\n\n![](/images/est_cc_ML.png){fig.align=\"center\"}\n\n## As duas culturas...\n\n<br>\n\n- **Data Modeling Culture:** Domina a comunidade estatística. Nela se **assume que o modelo utilizado é correto**. Testar suposições é fundamental. **Foco em inferência e na interpretação dos parâmetros**.\n\n. . .\n\n- **Algorithmic Modeling Culture:** Domina a comunidade de machine learning. Nela **não se assume que o modelo utilizado é correto**; **o modelo é utilizado apenas para criar bons algoritmos preditivos**. Podemos interpretar os resultados, mas esse, em geral, não é o foco.\n\n\n## Exemplos práticos de aplicações de ML no dia a dia.\n\n<br>\n\n\n-\tSistemas de recomendação (Netflix, Amazon).\n-\tFiltros de spam (Gmail).\n-\tCarros autônomos (Tesla).\n-\tDiagnóstico médico (detecção de tumores).\n-\tReconhecimento facial (smartphones).\n\n\n## Como as Máquinas Aprendem? \n\n<br>\n\n::: {#fig layout-ncol=2}\n\n![](/images/bike.png){.nostretch fig-align=\"center\" width=\"800px\"}\n\n\n![](/images/aprendizadoRN.gif){.nostretch fig-align=\"center\" width=\"1200px\"}\n:::\n\n\n## Componentes do aprendizado de máquina\n\n<br>\n\n:::: {.columns}\n\n::: {.column width=\"60%\"}\n![https://vas3k.com/blog/machine_learning/](/images/fig07.png){.nostretch fig-align=\"center\" width=\"700px\"}\n:::\n\n::: {.column width=\"40%\"}\n\n<br>\n\n<p></p>\n\n- Dados\n\n- Características/Features\n\n- Algoritmos\n\n:::\n\n::::\n\n## O mapa da aprendizagem de máquina\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n![](/images/fig02a.png){fig.align=\"center\"}\n:::\n\n::: {.column width=\"60%\"}\n\n<br>\n\n<p align=\"center\">\n&#128073; Nunca há uma única maneira de resolver um problema no mundo do aprendizado de máquina. \n\n&#128073; Sempre existem vários algoritmos que se encaixam, e você deve escolher qual deles se encaixa melhor. \n\n\n&#128073; Tudo pode ser resolvido com uma rede neural? Sim, mas quem pagará por todo esse custo?\n</p>\n\n\n\n:::\n\n::::\n\n\n## O mapa da aprendizagem de máquina\n\n![](/images/fig03a.png){.nostretch fig-align=\"center\" width=\"1200px\"}\n\n\n\n## Aprendizado de Máquina Clássico\n\n\n![](/images/tipos_aprend.png){.nostretch fig-align=\"center\" width=\"1150px\"}\n\n\n\n## Aprendizado de Máquina Clássico\n\n\n\n&#128073; O aprendizado de máquina clássico é frequentemente dividido em duas categorias – **Aprendizado Supervisionado** e **Não Supervisionado**.\n\n. . .\n\n\n- **Aprendizado Supervisionado:** usa um algoritmo que precisa de exemplos rotulados para desempenhar suas tarefas. \n\n\n. . .\n\n\n- **Aprendizado Não-supervisionado:** os dados não são rotulados, não há professor e a máquina está tentando encontrar padrões por conta própria.\n\n\n\n## Aprendizado Supervisionado\n\n<br>\n\n<span style='font-size:80px;'>&#128161;</span> Claramente, a máquina aprenderá mais rápido com um professor. Por isso, é mais comum encontrarmos esse caso nas tarefas da vida real.\n\n. . .\n\n\n- Existem dois tipos de tarefas: \n\n    - **classificação:** predição de categoria de um objeto e \n    - **regressão:** predição de um ponto específico em um eixo numérico.\n    \n    \n## Tarefa de classificação\n\n<p align=\"center\">\nOs algoritmos de classificação dividem os objetos com base em um dos atributos conhecidos de antemão. \n</p>\n\n\n:::: {.columns}\n\n::: {.column width=\"60%\"}\n\n<br>\n\n- Usados nos dias de hoje para:\n\n  - Filtragem de spam;\n  - Detecção de idioma;\n  - Pesquisa por documentos semelhantes;\n  - Análise de sentimentos;\n  - Reconhecimento de caracteres;\n  - Detecção de fraude.\n\n:::\n\n::: {.column width=\"40%\"}\n\n![](/images/fig09.png){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n:::\n::::\n\n\n## Tarefa de classificação\n\n<br>\n<br>\n\n\n<p align=\"center\">\nAlgoritmos populares: **Naive Bayes**, **Decision Tree**, **Logistic Regression**, **K-Nearest Neighbours**, **Support Vector Machine**.\n</p>\n\n\n## Tarefa de regressão\n\n<p align=\"center\">\nSe a variável resposta é quantitativa, temos um problema de análise de regressão \n</p>\n\n\n:::: {.columns}\n\n::: {.column width=\"60%\"}\n\n<br>\n\n- Usados nos dias de hoje para:\n\n  - Previsões do preço das ações;\n  - Análise de demanda e volume de vendas;\n  - Diagnóstico médico.\n\n:::\n\n::: {.column width=\"40%\"}\n\n![](/images/fig10.png){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n:::\n::::\n\n## Tarefa de regressão\n\n<br>\n<br>\n\n\n<p align=\"center\">\nAlgoritmos populares: **Decision Tree**, **Regressão Linear** e **Regressão Polinomial**, **K-Nearest Neighbours**, **Support Vector Machine**.\n</p>\n\n\n\n\n## Avaliação de modelos\n\n\n<span style='font-size:80px;'>&#128161;</span>  Independente do modelo escolhido, é importante saber se um modelo de machine learning está realmente funcionando. É aí que entra a **avaliação de modelos**!\n\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n![](/images/detetive.jpg){.nostretch fig-align=\"center\" width=\"1000px\"}\n:::\n\n::: {.column width=\"60%\"}\n\n<br>\n\n<p align=\"center\">\nA **avaliação de modelos** de machine learning é como um **detetive investigando um caso**.\n</p>\n\n:::\n::::\n\n\n## Avaliação de modelos\n\n<br>\n\n<br>\n\n::: {layout-ncol=2}\n\n![](/images/over_under.png){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n![](/images/erro_over_under.png){.fragment fig-align=\"center\" width=\"1000px\"}\n\n\n:::\n\n\n\n## Avaliação de modelos\n\n\n\n<p align=\"center\" >\n<span style='font-size:70px;'>&#129300;</span> O nosso modelo é um **herói** ou um **impostor**?\n</p>\n\n![](https://media4.giphy.com/media/ek4CUx2FONgHaMz9V5/giphy-downsized-medium.gif){fig-align=\"center\" width=\"1000px\"}\n\n\n\n\n## Matriz de confusão\n\n\nPermite a visualização do **desempenho** de um **algoritmo de classificação**\n\n&nbsp;\n\n![](/images/mc.png){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n## Matriz de confusão\n\n<br>\n\n- **VP (Verdadeiro Positivo):** objeto da classe positiva classificado como positivo \n\n. . .\n\n\n- **VN (Verdadeiro Negativo):** objeto da classe negativa classificado como negativo\n\n. . .\n\n\n- **FP (Falso Positivo):** objeto da classe negativa classificado como positivo. Também conhecido como **alarme falso** ou **Erro tipo 1**\n\n\n. . .\n\n\n- **FN (Falso Negativo):** objeto da classe positiva classificado como negativo. É também conhecido como **Erro Tipo 2**\n\n\n## Matriz de confusão\n\n<br> \n\n**Exemplo:** Sejam as seguintes matrizes de confusão, obtidas de dois classificadores quaisquer.\n\n<br>\n\n::: {layout-ncol=2}\n\n![](/images/mc_cliente.png){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n![](/images/mc_paciente.png){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n\n:::\n\n\n# Métricas derivadas da matriz de confusão\n\n## Acurácia\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n![](/images/acc.jpg){.nostretch fig-align=\"center\" width=\"400px\"}\n:::\n\n::: {.column width=\"60%\"}\n\n<br>\n\n\n<p align=\"center\">\nMede a **proporção de previsões corretas** do modelo em relação ao total de previsões feitas.\n</p>\n\n:::\n::::\n\n\n<p align=\"center\">\n**É como sua nota em uma prova!**\n</p>\n\n\n## Acurácia\n\n<br>\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n![](/images/mc.png){.nostretch fig-align=\"center\" width=\"800px\"}\n:::\n\n::: {.column width=\"50%\"}\n\n<br>\n\n\n![](/images/acc_form.jpg){.nostretch fig-align=\"center\" width=\"800px\"}\n\n:::\n::::\n\n\nA **Taxa de Erro Aparente** do classificador é dada por\n\n$$TEA = 1 - ACC$$\n\n\n\n## Acurácia\n\n::: {layout-nrow=2}\n\n![](/images/mc_cliente_acc.png){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n![](/images/acc_tea_cliente.png){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n![](/images/mc_paciente_acc.png){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n![](/images/acc_tea_paciente.png){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n:::\n\n\n## Acurácia\n\n\n<br>\n\n<br>\n\n\n<p align=\"center\">\nMas será que a **acurácia** é suficiente para avaliar nossos modelos de forma **precisa**? \n</p>\n\n\n. . .\n\n\n<p align=\"center\">\nÀs vezes, uma **única métrica** não é capaz de nos contar toda a história.\n</p>\n\n\n\n## Precisão\n\n<br>\n\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n![](/images/precision.jpg){.nostretch fig-align=\"center\" width=\"400px\"}\n:::\n\n::: {.column width=\"60%\"}\n\n<br>\n\n\n<p align=\"center\">\nEla nos diz quantas das **previsões positivas** foram realmente **corretas**.\n</p>\n\n:::\n::::\n\n\n## Precisão\n\n<br>\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n![](/images/mc.png){.nostretch fig-align=\"center\" width=\"800px\"}\n:::\n\n::: {.column width=\"50%\"}\n\n<br>\n\n![](/images/precision_form.jpg){fig-align=\"center\" width=\"800px\"}\n\n:::\n::::\n\n\n\n<p align=\"center\">\nPorcentagem de verdadeiros positivos dentre todos os objetos classificados como positivos\n</p>\n\n\n\n## Precisão\n\n\n::: {layout-nrow=2 layout-valign=\"bottom\"}\n\n![](/images/mc_cliente_prec.png){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n![](/images/prec_form_clientes.jpg){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n![](/images/mc_paciente_prec.png){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n![](/images/prec_form_pacientes.jpg){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n:::\n\n\n\n## Sensibilidade\n\n\n<br>\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n![](/images/recall.jpg){.nostretch fig-align=\"center\" width=\"800px\"}\n:::\n\n::: {.column width=\"50%\"}\n\n<br>\n\n\n<p align=\"center\">\nMede a **proporção de casos positivos reais** que foram encontrados pelo modelo \n</p>\n\n\n:::\n::::\n\n## Sensibilidade\n\n<br>\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n![](/images/mc.png){.nostretch fig-align=\"center\" width=\"800px\"}\n:::\n\n::: {.column width=\"50%\"}\n\n<br>\n\n![](/images/sens_form.jpg){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n:::\n::::\n\n<p align=\"center\">\nTambém conhecida por **Recall** ou **Taxa de Verdadeiros Positivos (TVP)**\n</p>\n\n## Sensibilidade\n\n\n::: {layout-nrow=2 layout-valign=\"bottom\"}\n\n![](/images/mc_cliente_sens.png){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n![](/images/sens_form_clientes.jpg){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n![](/images/mc_paciente_sens.png){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n![](/images/sens_form_pacientes.jpg){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n:::\n\n\n## Especificidade\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n![](/images/espec.jpg){.nostretch fig-align=\"center\" width=\"600px\"}\n:::\n\n::: {.column width=\"50%\"}\n\n<br>\n\n<br>\n\n<p align=\"center\">\nAjuda a identificar a capacidade do modelo em reconhecer **corretamente as amostras negativas**   \n</p>\n\n\n:::\n::::\n\n\n## Especificidade\n\n<br>\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n![](/images/mc.png){.nostretch fig-align=\"center\" width=\"800px\"}\n:::\n\n::: {.column width=\"50%\"}\n\n<br>\n\n![](/images/espec_form.jpg){.nostretch fig-align=\"center\" width=\"800px\"}\n\n:::\n::::\n\n<p align=\"center\">\nTambém conhecida por **Taxa de Verdadeiros Negativos (TVN)**\n</p>\n\n\n## Especificidade\n\n::: {layout-nrow=2 layout-valign=\"bottom\"}\n\n![](/images/mc_cliente_espec.png){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n![](/images/espec_form_clientes.jpg){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n![](/images/mc_paciente_espec.png){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n![](/images/espec_form_pacientes.jpg){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n:::\n\n\n## Taxa de Falso Positivo\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n<br>\n\n![](/images/fpr.jpg){.nostretch fig-align=\"center\" width=\"1000px\"}\n:::\n\n::: {.column width=\"50%\"}\n\n<br>\n\n<br>\n\n<p align=\"center\">\nEla mede a **proporção de amostras negativas** classificadas como positivas pelo modelo  \n</p>\n\n\n:::\n::::\n\n\n## Taxa de Falso Positivo\n\n\n<br>\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n![](/images/mc.png){.nostretch fig-align=\"center\" width=\"800px\"}\n:::\n\n::: {.column width=\"50%\"}\n\n<br>\n\n![](/images/fpr_form.jpg){.nostretch fig-align=\"center\" width=\"500px\"}\n\n:::\n::::\n\n\n## Taxa de Falso Positivo\n\n::: {layout-nrow=2 layout-valign=\"bottom\"}\n\n![](/images/mc_cliente_espec.png){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n![](/images/fpr_form_clientes.jpg){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n![](/images/mc_paciente_espec.png){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n![](/images/fpr_form_pacientes.jpg){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n:::\n\n\n## $F_1$-Score\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n<br>\n\n![](/images/f1.jpg){.nostretch fig-align=\"center\" width=\"500px\"}\n:::\n\n::: {.column width=\"50%\"}\n\n<br>\n\n<br>\n\n<br>\n\n<p align=\"center\">\n Ele leva em consideração tanto **precisão** quanto a **sensibilidade**, dando uma medida balanceada do desempenho do modelo.  \n</p>\n\n\n:::\n::::\n\n\n## $F_1$-Score\n\n<br>\n\n<br>\n\n$$F_1 \\text{-score} = 2 \\times \\dfrac{\\text{Precisão} \\times \\text{Sensibilidade}}{\\text{Precisão} + \\text{Sensibilidade}}$$\n\n<br>\n\n<p align=\"center\">\nO $F_1$-Score é como um **equilibrista** em uma corda bamba.\n</p>\n\n\n## Curva ROC\n\n- A **Curva ROC** é como um mapa que nos guia pela **sensibilidade** e pelos **falsos positivos** do modelo em diferentes configurações. \n\n. . .\n\n- Ela nos mostra o quão bem nosso modelo pode **distinguir** entre as classes.\n\n\n![](/images/roc.jpg){.fragment fig-align=\"center\" width=\"700px\"}\n\n\n## Curva ROC\n\n\n- Representa o número de vezes que o classificador **acertou a predição** contra o número de vezes que o classificador **errou a predição**\n\n. . .\n\n\n- A área sob a curva ROC, conhecida como **AUC-ROC**, é uma métrica comumente utilizada para avaliar o desempenho global do modelo. \n\n. . . \n\n- Quanto **maior a AUC-ROC**, **melhor** é o desempenho do modelo em discriminar corretamente as classes.\n\n![](/images/auc.jpg){.fragment fig-align=\"center\" width=\"1400px\"}\n\n\n# E como avaliar modelos de predição?\n\n## Avaliação de modelos de predição\n\n<br>\n\n- Seja $d_j$, $j = 1,\\cdots, n$, a resposta desejada para o objeto $j$ e $y_j$ a resposta estimada (predita) do algoritmo, obtida a partir de uma entrada $\\mathbf{x_j}$ apresentada ao algoritmo.\n\n. . .\n\n- Seja então, $e_j = d_j - y_j$ a diferença entre o valor observado e o valor predito para o objeto $j$.\n\n\n. . .\n\n- Podemos definir as seguintes métricas para **avaliação de modelos preditivos.**\n\n## Avaliação de modelos de predição\n\n**Erro Quadrático Médio (MSE - Mean Squared Error):**\n\n$$MSE =\\dfrac{1}{n} \\displaystyle{\\sum_{j=1}^n e_j^2}$$\n\n - **Ponto forte:** Penaliza fortemente erros maiores devido ao termo quadrático. Isso significa que o MSE é sensível a outliers (valores discrepantes).\n\n\n - **Ponto fraco:** Como eleva os erros ao quadrado, a unidade da métrica resultante não é a mesma da variável original, o que dificulta a interpretação direta da magnitude do erro.\n\n\n## Avaliação de modelos de predição\n\n**Raiz do Erro Quadrático Médio (RMSE - Root Mean Squared Error):**\n\n$$RMSE =\\sqrt{\\dfrac{1}{n} \\displaystyle{\\sum_{j=1}^n e_j^2}}$$\n\n\n - **Ponto forte:** Mantém a propriedade de penalizar erros maiores, mas retorna o erro na mesma unidade da variável original, facilitando a interpretação. É uma métrica amplamente utilizada.\n\n\n - **Ponto fraco:** Ainda é sensível a outliers, pois se baseia no MSE.\n\n\n\n## Avaliação de modelos de predição\n\n**Erro Médio Absoluto (MAE - Mean Absolute Error):**\n\n$$MAE = \\dfrac{1}{n} \\displaystyle{\\sum_{j=1}^n |e_j|}$$\n\n - **Ponto forte:** É mais robusto a outliers em comparação com MSE e RMSE, pois não eleva os erros ao quadrado. Fornece uma medida direta da magnitude média dos erros na unidade original da variável.\n\n\n - **Ponto fraco:** Não penaliza erros maiores de forma tão intensa quanto o MSE e RMSE. Pode não ser ideal se erros grandes tiverem um impacto significativamente maior no seu problema.\n\n\n\n\n## Avaliação de modelos de predição\n\n**Erro Percentual Absoluto Médio (MAPE - Mean Absolute Percentage Error):**\n\n$$MAPE = \\dfrac{1}{n} \\displaystyle{\\sum_{j=1}^n |e_j/d_j|}\\times 100$$\n\n - **Ponto forte:** É fácil de interpretar, pois expressa o erro em termos percentuais. Isso pode ser útil para comparar o desempenho de modelos em diferentes escalas.\n\n\n - **Ponto fraco:** Não é definido quando os valores reais são zero. Além disso, pode ser assimétrico, penalizando mais os erros de previsão abaixo do valor real do que acima. Pode ser instável se houver valores reais muito pequenos.\n\n\n## Avaliação de modelos de predição\n\n<p align=\"center\">\n<span style='font-size:70px;'>&#129300;</span> Qual a melhor métrica?\n</p>\n\n\n\n**Em resumo:**\n\n\n- Se você se preocupa muito com grandes erros: MSE e RMSE são boas opções.\n\n. . .\n\n- Se você quer uma métrica robusta a outliers: MAE é uma boa escolha.\n\n. . .\n\n- Se a interpretabilidade em termos percentuais é importante (com cuidado com valores zero/pequenos): MAPE pode ser útil.\n\n. . .\n\n\n<p align=\"center\">\n<span style='font-size:60px;'>&#128161;</span> O ideal é analisar todas as métricas em conjunto, considerando o contexto do seu problema e utilizando validação cruzada.\n</p>\n\n\n## Qual o melhor modelo?\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n<br>\n\n\n\n<span style='font-size:70px;'>&#128073;</span> Suponha que tenhamos dados simulados utilizando o seguinte modelo:\n\n![](/images/predicao/fig01.png){.nostretch fig-align=\"center\" width=\"800px\"}\n:::\n\n::: {.column width=\"50%\"}\n\n![](/images/predicao/fig02.png){.nostretch fig-align=\"center\" width=\"800px\"}\n\n\n:::\n::::\n\n\n## Qual o melhor modelo?\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n<br>\n\n\n\n<span style='font-size:70px;'>&#128073;</span> Podemos estimar diversos modelos $y$ que predizem o verdadeiro valor de $d$\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n![](/images/predicao/fig03.png){.nostretch fig-align=\"center\" width=\"800px\"}\n\n\n:::\n::::\n\n\n\n## Qual o melhor modelo?\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n<br>\n\n\n\n<span style='font-size:70px;'>&#128073;</span> Nosso interesse está em treinar o modelo e avaliar a sua capacidade de generalização\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n![](/images/predicao/fig04.png){.nostretch fig-align=\"center\" width=\"800px\"}\n\n\n:::\n::::\n\n\n\n## Validação holdout\n\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n<br>\n\n\n\n<span style='font-size:70px;'>&#128073;</span> **Dados originais:** treinamento e teste\n\n\n<span style='font-size:70px;'>&#128073;</span> **Dados de treinamento:** treinamento e validação\n\n:::\n\n::: {.column width=\"50%\"}\n\n![](/images/predicao/houlout.png){.nostretch fig-align=\"center\" width=\"800px\"}\n\n\n:::\n::::\n\n\n\n\n## Validação holdout\n\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n<br>\n\n**Exemplo:** Vamos avaliar a relação entre Frequência Cardíaca e Idade de 270 pacientes\n\n\n![](/images/predicao/freq.png){.nostretch fig-align=\"center\" width=\"600px\"}\n\n:::\n\n::: {.column width=\"50%\"}\n\n<br>\n\n![](/images/predicao/exemplo.png){.nostretch fig-align=\"center\" width=\"1200px\"}\n\n\n:::\n::::\n\n\n\n## Validação holdout\n\n<p align=\"center\">\n<span style='font-size:60px;'>&#129300;</span> Qual o melhor modelo nesse caso?\n</p>\n\n\n![](/images/predicao/fig05.png){.nostretch fig-align=\"center\" width=\"700px\"}\n\n\n## Validação holdout\n\n\n<p align=\"center\">\n<span style='font-size:60px;'>&#128073;</span> 70% da base para treino e 30% para validação\n</p>\n\n::: {layout-ncol=2}\n![](/images/predicao/fig06.png){.nostretch fig-align=\"center\" width=\"900px\"}\n\n![](/images/predicao/fig07.png){.nostretch fig-align=\"center\" width=\"900px\"}\n:::\n\n\n\n\n## Validação cruzada k-fold\n\n<span style='font-size:70px;'>&#128073;</span> **Dados de treinamento:** $k$ partes iguais. **Treina** com $k-1$ partes, e **valida** com uma\n\n![](/images/predicao/cross_validation.png){.nostretch fig-align=\"center\" width=\"1400px\"}\n\n\n\n## Validação cruzada k-fold\n\n<br>\n\n::: {layout-ncol=2}\n![](/images/predicao/fig08.png){.nostretch fig-align=\"center\" width=\"900px\"}\n\n![](/images/predicao/fig09.png){.nostretch fig-align=\"center\" width=\"900px\"}\n:::\n\n\n## Trade-off bias-variância\n\n\nImagine que você está tentando **acertar** um alvo com dardos. Seus arremessos podem ser agrupados de três maneiras diferentes:\n\n\n- **Grupo de alto viés (bias):** Seus arremessos são **consistentemente agrupados longe do alvo**, mas **próximos uns dos outros**. Isso indica um **alto viés**, pois você está fazendo arremessos incorretos, mas de forma **consistente**.\n\n\n. . .\n\n- **Grupo de alta variância:** Seus arremessos estão **espalhados por toda a área**, **longe do alvo e uns dos outros**. Isso indica **alta variância**, pois seus arremessos são **inconsistentes e imprevisíveis**. \n\n\n\n. . .\n\n\n- **Grupo equilibrado:** Seus arremessos estão **agrupados próximo ao alvo** e também estão **próximos uns dos outros**. Isso é o **equilíbrio** entre **viés** e **variância**, onde você está acertando o alvo de forma **consistente** e **precisa**.\n\n\n\n## Trade-off bias-variância\n\n![](/images/predicao/bias_variance.png){.nostretch fig-align=\"center\" width=\"900px\"}\n\n\n## Trade-off bias-variância\n\n\n<br>\n\n\nQueremos construir modelos que não apenas performem bem nos dados de treinamento, mas que também façam previsões precisas em dados novos e não vistos.\n\n\n. . .\n\n\nO **erro total** de um **modelo preditivo** em dados não vistos pode ser **decomposto em três componentes principais**, ou seja,\n\n\n\n$$\\text{Erro Total} = \\text{Bias}^2 + \\text{Variância} + \\text{Erro Irredutível}$$\n\n\n\n## Trade-off bias-variância\n\n<br>\n\n- **Bias (Viés):** Erro devido a suposições simplificadoras no modelo. Um modelo com alto bias tende a subajustar (underfit) os dados de treinamento, perdendo relações importantes entre as variáveis.\n\n\n. . .\n\n\n- **Variância:** Sensibilidade do modelo a pequenas variações nos dados de treinamento. Um modelo com alta variância tende a sobreajustar (overfit) os dados de treinamento, aprendendo até mesmo o ruído presente neles.\n\n\n. . .\n\n- **Erro Irredutível:** Ruído inerente aos dados que não pode ser reduzido por nenhum modelo.\n\n\n## O Problema do Subajuste (Underfitting)\n\n<br>\n\nModelos com **alto bias** fazem suposições fortes sobre a forma da função que mapeia as entradas para as saídas. São tipicamente modelos mais simples, com poucos parâmetros.\n\n. . .\n\n\n- Consequências:\n\n  - Desempenho ruim tanto nos dados de treinamento quanto nos dados de teste.\n  - Incapacidade de capturar a complexidade real dos dados.\n  \n  \n## O Problema do Sobreajuste (Overfitting)\n\n<br>\n\nModelos com **alta variância** aprendem os dados de treinamento muito bem, incluindo o ruído presente neles. São tipicamente modelos mais complexos, com muitos parâmetros.\n\n\n- Consequências:\n\n  - Excelente desempenho nos dados de treinamento.\n  - Desempenho significativamente pior em dados de teste não vistos. O modelo \"decorou\" os dados de treinamento em vez de aprender padrões gerais.\n\n\n## Underfitting e Overfitting\n\n<br>\n\n![](/images/predicao/over_under_good.png){.nostretch fig-align=\"center\" width=\"1800px\"}\n\n\n## Bias vs. Variância\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n<br>\n\n<br>\n\nVoltemos ao nosso modelo simulado:\n\n\n![](/images/predicao/fig01.png){.nostretch fig-align=\"center\" width=\"600px\"}\n\n:::\n\n::: {.column width=\"50%\"}\n\n![](/images/predicao/fig02.png){.nostretch fig-align=\"center\" width=\"1200px\"}\n\n\n:::\n::::\n\n\n\n## Bias vs. Variância\n\n<p align=\"center\">\n<span style='font-size:60px;'>&#128073;</span> Vamos ajustar um modelo polinomial de **grau 2**\n</p>\n\n\n\n\n![](/images/predicao/fig12.png){.nostretch fig-align=\"center\" width=\"800px\"}\n\n\n## Bias vs. Variância\n\n::: {layout-ncol=2}\n![](/images/predicao/fig13.png){.nostretch fig-align=\"center\" width=\"900px\"}\n\n![](/images/predicao/fig14.png){.nostretch fig-align=\"center\" width=\"900px\"}\n:::\n\n\n\n\n\n## Bias vs. Variância\n\n<p align=\"center\">\n<span style='font-size:60px;'>&#128073;</span> Vamos ajustar um modelo polinomial de **grau 10**\n</p>\n\n\n\n\n![](/images/predicao/fig15.png){.nostretch fig-align=\"center\" width=\"800px\"}\n\n\n## Bias vs. Variância\n\n::: {layout-ncol=2}\n![](/images/predicao/fig16.png){.nostretch fig-align=\"center\" width=\"900px\"}\n\n![](/images/predicao/fig17.png){.nostretch fig-align=\"center\" width=\"900px\"}\n:::\n\n\n\n\n\n\n\n\n\n\n## O Tradeoff - A Balança Delicada\n\n<span style='font-size:80px;'>&#128073;</span> **Bias** e **variância** estão **inversamente relacionados**. Tentar reduzir um geralmente aumenta o outro.\n\n\n. . .\n\n- **Modelos simples** tendem a ter **alto bias e baixa variância**.\n\n- **Modelos complexos** tendem a ter **baixo bias e alta variância**.\n\n\n. . .\n\n<span style='font-size:80px;'>&#128161;</span> O objetivo é encontrar um modelo com um **bom equilíbrio** entre **bias** e **variância**, que **minimize o erro de generalização**.\n\n\n\n## O Tradeoff - A Balança Delicada\n\n<br>\n\n![](/images/predicao/bias-variance_tradeOff.png){.nostretch fig-align=\"center\" width=\"1800px\"}\n\n## Como Lidar com o Tradeoff?\n\n<br>\n\n- **Seleção de Modelos:** Experimentar diferentes tipos de modelos (lineares, não lineares, árvores, redes neurais, etc.).\n\n. . .\n\n- **Ajuste de Hiperparâmetros:**  Controlar a complexidade do modelo ajustando seus hiperparâmetros (ex: profundidade máxima de uma árvore, número de neurônios em uma camada).\n\n. . .\n\n\n- **Validação Cruzada:** Usar técnicas de validação cruzada para estimar o desempenho do modelo em dados não vistos de forma mais robusta e ajudar a identificar overfitting.\n\n. . .\n\n- **Engenharia de Features:** Criar features mais informativas pode reduzir o bias.\n\n\n## Como Lidar com o Tradeoff?\n\n<br>\n\n- **Regularização:** Técnicas como L1 e L2 adicionam uma penalidade à complexidade do modelo, ajudando a reduzir a variância (overfitting).\n\n\n. . .\n\n\n- **Mais Dados:** Em alguns casos, aumentar a quantidade de dados de treinamento pode ajudar a reduzir a variância.\n\n. . .\n\n\n- **Ensemble Methods:** Combinar múltiplos modelos (ex: Random Forest, Gradient Boosting) pode ajudar a reduzir tanto o bias quanto a variância.\n\n\n\n# Algoritmos de predição\n\n## Algoritmos de predição\n\n<br>\n\n- Algoritmos mais comuns usados para problemas de predição:\n\n  - K-Nearest Neighbors (KNN)\n  - Naive Bayes\n  - Árvores de decisão\n  - Random Forests\n  - Máquinas de Vetores de Suporte (SVM)\n  - Redes Neurais Artificiais (ANN)\n  \n\n##  K-Nearest Neighbors (KNN) \n\n<br>\n\nO KNN é um algoritmo de aprendizado supervisionado de classificação e regressão, que usa a proximidade dos objetos para classificar novas instâncias.\n\n\n. . .\n\nÉ um dos algoritmos mais simples e intuitivos de aprendizado de máquina. Utiliza a ideia do **vizinho mais próximo**, o que significa que ele determina a classe de uma instância com base nas classes de seus vizinhos mais próximos.\n\n. . .\n\nEm outras palavras, se a maioria dos vizinhos mais próximos de uma instância pertence a uma classe específica, então a instância também é classificada como pertencente a essa classe.\n\n\n## Algoritmo KNN\n\n![](/images/knn/knn.png){.nostretch fig-align=\"center\" width=\"900px\"}\n\n\n##  Algoritmo KNN\n\n<br>\n\nKNN é usado para problemas de classificação e regressão.\n\n\n. . .\n\n\n  - Em problemas de **classificação**, a classe mais comum entre os K vizinhos mais próximos é escolhida como a classe da nova instância.\n\n. . .\n\n  - Em problemas de **regressão**, a média ou mediana dos valores alvo dos K vizinhos mais próximos é escolhida como o valor alvo da nova instância.\n\n\n## A escolha do valor de K\n\n<br>\n\nO valor de K é um **parâmetro** importante em KNN. Ele determina o **número de vizinhos mais próximos** que são usados para classificar uma nova instância.\n\n. . .\n\n\nUm valor de K pequeno pode levar a um modelo muito **sensível** ao **ruído** nos dados (overfitting), enquanto um valor grande de K pode levar a uma **perda** de detalhes importantes nos dados (underfitting).\n\n\n. . .\n\nA escolha do valor K ideal é frequentemente realizada por meio de técnicas de **validação cruzada**. \n\n. . .\n\n\nK ímpar evita empates.\n\n\n\n  \n\n\n## Métricas de Distância\n\n- **Distância Euclidiana:** A mais comum. \n\n$$d_{ij} = \\displaystyle{\\sqrt{(\\mathbf{x}_i - \\mathbf{x}_j)^t(\\mathbf{x}_i - \\mathbf{x}_j)}} = \\sqrt{\\displaystyle{\\sum_{k=1}^p(x_{ik} - x_{jk})^2}}$$\n\n- **Distância de Minkowski:** Soma das diferenças absolutas entre as coordenadas. \n\n$$d_{ij} = \\left( \\displaystyle{\\sum_{k=1}^P} |X_{ik} - X_{jk}|^{\\lambda}\\right)^{\\frac{1}{\\lambda}}$$\n\n## Métricas de Distância\n\n<br>\n\n- Para a distância de Minkowski:\n\n  - Se $\\lambda = 1$, temos a chamada **métrica de Manhattan**. É também conhecida como *city block*.  \n  - Se $\\lambda = 2$, temos a distância euclidiana.\n  - A métrica de Minkowski é menos afetada pela presença de valores discrepantes na amostra do que a distância Euclidiana.\n\n. . .\n\n\n- Se os dados forem textuais: usar cosseno\n\n\n## Vantagens e Desvantagens\n\n<br>\n\n:::: {.columns}\n\n::: {.column width=\"10%\"}\n<span style='font-size:130px;'>&#128077;</span>\n:::\n\n::: {.column width=\"90%\"}\n  -\tSimples de entender e implementar.\n  -\tNão faz muitas suposições sobre os dados (não paramétrico).\n  -\tÚtil para dados complexos e não lineares.\n  -\tPode ser usado tanto para classificação quanto para regressão.\n:::\n\n::::\n\n## Vantagens e Desvantagens\n\n<br>\n\n:::: {.columns}\n\n::: {.column width=\"10%\"}\n\n<br>\n\n<span style='font-size:130px;'>&#128078;</span>\n:::\n\n::: {.column width=\"90%\"}\n  -\tComputacionalmente caro para grandes conjuntos de dados (cálculo de distância para todos os pontos).\n  -\tSensível à escala dos dados (variáveis com escalas maiores podem dominar o cálculo da distância) - importância da normalização/padronização.\n  -\tDesempenho pode degradar em dados com muitas dimensões (maldição da dimensionalidade).\n  - Escolha do valor de k pode ser crucial e não é trivial.\n\n:::\n\n::::\n\n\n\n## Pré-processamento de Dados para KNN\n\n\n<br>\n\n:::: {.columns}\n\n::: {.column width=\"10%\"}\n\n<span style='font-size:130px;'>&#128187;</span>\n:::\n\n::: {.column width=\"90%\"}\n  -\t**Escalonamento de features:** Padronização (média zero, desvio padrão um) ou normalização (escala entre 0 e 1) para garantir que todas as features contribuam igualmente para o cálculo da distância.\n  -\t**Tratamento de valores ausentes:** Imputação ou remoção.\n  - **Seleção de features:** Reduzir a dimensionalidade para melhorar o desempenho.\n\n\n:::\n\n::::\n\n\n## Exemplo: Compra de um computador\n\n\n![](/images/knn/tabela.jpg){.nostretch fig-align=\"center\" width=\"1300px\"}\n\n## Exemplo: Compra de um computador\n\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n![](/images/joao.png){.nostretch fig-align=\"center\" width=\"1300px\"}\n:::\n\n::: {.column width=\"60%\"}\n\n<br>\n\nJoão possui as seguintes características\n\n- menos de 30 anos\n- renda média\n- é estudante\n- possuí um bom crédito na praça!\n\n\n:::\n\n::::\n\n\n## Exemplo: Compra de um computador \n\n<p align=\"center\">\nJoão **compraria** ou **não compraria** o computador?\n</p>\n\n\n![](https://media2.giphy.com/media/XeH1MFu4x3etVsllUN/giphy.gif){.nostretch fig-align=\"center\" width=\"1100px\"}  \n\n\n\n## Exemplo: Compra de um computador\n\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n![](/images/joao.png){.nostretch fig-align=\"center\" width=\"1300px\"}\n:::\n\n::: {.column width=\"60%\"}\n\n<br>\n\n<p align=\"center\" style=\"font-size: 76px\">**Quem é o João?**</p>\n\n&nbsp;\n&nbsp;\n\n::: {.fragment}\n<p align=\"center\" style=\"font-size: 56px\">$x_0 = (\\leq 30, \\text{ Média}, \\text{ Sim}, \\text{ Bom})$</p>\n:::\n\n\n:::\n\n::::\n\n\n## Exemplo: Compra de um computador \n\n<p align=\"center\">\nUsando o classificador KNN com k = 5\n</p>\n\n\n![](/images/knn/tab_dist.jpg){.nostretch fig-align=\"center\" width=\"1100px\"}\n\n\n\n## Exemplo: Compra de um computador \n\n<br>\n\nTemos então que os **5 vizinhos** mais próximos a João são\n\n \\s\\s\n\n:::: {.columns}\n\n::: {.column width=\"10%\"}\n<span style='font-size:130px;'>&#x274C;</span>\n:::\n\n::: {.column width=\"90%\"}\n\n \\s\\s\n\n- <p style=\"color: red\">$x_2 = \\{\\leq 30, \\text{ Alta}, \\text{ Sim}, \\text{ Bom}\\}$</p>\n- <p style=\"color: red\">$x_8 = \\{\\leq 30, \\text{Média}, \\text{ Não}, \\text{ Bom}\\}$</p>\n\n:::\n\n::::\n\n. . .\n\n:::: {.columns}\n\n::: {.column width=\"10%\"}\n\n<span style='font-size:130px;'>&#x2705;</span>\n:::\n\n::: {.column width=\"90%\"}\n\n\n \n- <p style=\"color: green\">$x_9 = \\{\\leq 30, \\text{ Baixa}, \\text{ Sim}, \\text{ Bom}\\}$</p>\n- <p style=\"color: green\">$x_{10} = \\{> 40, \\text{ Média}, \\text{ Sim}, \\text{ Excelente}\\}$</p>\n- <p style=\"color: green\">$x_{11} = \\{\\leq 30, \\text{ Média}, \\text{ Sim}, \\text{ Excelente}\\}$</p>\n:::\n\n::::\n\n\n## Exemplo: Compra de um computador \n\n<br>\n\n<br>\n\n\n<details>\n  <summary align=\"center\" style='font-size:80px;'>**João comprará o computador?**</summary>\n  <p align=\"center\" style=\"color: green; font-size:80px;\"> **De acordo com o KNN: SIM!** </p>\n</details>\n\n\n## KNN para classificação no R e Python\n\n\n\n\n::: {.panel-tabset}\n\n### R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\nlibrary(Metrics)\n\nset.seed(12345)\ndata(iris)\niris_split <- initial_split(iris, strata = Species)\ntrain_data <- training(iris_split)\ntest_data <- testing(iris_split)\n\nknn_spec <- nearest_neighbor(neighbors = 5) %>% \n  set_engine(\"kknn\") %>%\n  set_mode(\"classification\")\n\nknn_fit <- workflow() %>%\n  add_model(knn_spec) %>%\n  add_formula(Species ~ .) %>%\n  fit(data = train_data)\n\nsp_predict <- predict(knn_fit, test_data)\n\nMetrics::accuracy(test_data$Species, sp_predict$.pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.974359\n```\n\n\n:::\n:::\n\n\n### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\niris = load_iris()\nX_train, X_test, y_train, y_test = train_test_split(\n    iris.data, iris.target, stratify=iris.target, random_state=12345\n)\n\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>\n```\n\n:::\n\n```{.python .cell-code}\ny_pred = knn.predict(X_test)\naccuracy_score(y_test, y_pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0.9473684210526315\n```\n\n\n:::\n:::\n\n\n:::\n\n## KNN para regressão no R e Python\n\n\n::: {.panel-tabset}\n\n### R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\nlibrary(Metrics)\n\ndata(\"mtcars\")\nset.seed(12345)\nmtcars_split <- initial_split(mtcars, strata = mpg)\ntrain_data <- training(mtcars_split)\ntest_data <- testing(mtcars_split)\n\nknn_spec <- nearest_neighbor(neighbors = 5) %>%\n  set_engine(\"kknn\") %>%\n  set_mode(\"regression\")\n\nknn_fit <- workflow() %>%\n  add_model(knn_spec) %>%\n  add_formula(mpg ~ .) %>%\n  fit(data = train_data)\n\nmpg_predict <- predict(knn_fit, test_data)\n\nMetrics::mse(test_data$mpg, mpg_predict$.pred) # MSE\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 6.069807\n```\n\n\n:::\n:::\n\n\n### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_squared_error\n\ndata = fetch_california_housing()\nX_train, X_test, y_train, y_test = train_test_split(\n    data.data, data.target, random_state=12345\n)\n\nknn_reg = KNeighborsRegressor(n_neighbors=5)\nknn_reg.fit(X_train, y_train)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div>\n```\n\n:::\n\n```{.python .cell-code}\ny_pred = knn_reg.predict(X_test)\nmean_squared_error(y_test, y_pred, squared=True)  # MSE\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n1.1408296168142682\n```\n\n\n:::\n:::\n\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}