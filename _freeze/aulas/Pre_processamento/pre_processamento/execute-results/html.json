{
  "hash": "ce59e324bfdd0123c305c205a5d4ec05",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Pré-processamento de dados\"\nformat: \n  revealjs:\n    width: 1600\n    height: 900\n    footer: \"\"\n    theme: quartomonothemer.scss\n    slide-number: c/t\n    show-slide-number: all\nincremental: false\ncode-link: true\nbibliography: references.bib\ntitle-slide-attributes:\n    data-background-image: /images/back.jpeg\n    data-background-size: cover\n    data-background-opacity: \"0.3\"\n---\n\n\n# Introdução\n\n\n## Pré-processamento de dados\n\n\n&#128161; **Pré-processamento** de dados se define como um conjunto de técnicas e procedimentos aplicados aos dados **antes** de sua utilização em um modelo ou algoritmo de análise. \n\n\n. . .\n\n\nÉ uma etapa fundamental na análise de dados, pois visa garantir que os dados estejam **corretos**, **completos**, **coerentes** e em um **formato** apropriado para serem analisados. \n\n## Pré-processamento de dados\n\n\n:::: {.columns}\n::: {.column width=\"40%\"}\n![](/images/preprocess.jpeg){fig-align=\"center\"}\n:::\n\n::: {.column width=\"60%\"}\n\n<br>\n\n<p align=\"center\"> \nO pré-processamento de dados inclui diversas atividades, como **limpeza de dados**, **transformação de dados**, **redução de dimensão**, **seleção de recursos**, **normalização** e **amostragem**. \n</p>\n:::\n::::\n\n<p align=\"center\"> \n&#128073; O **objetivo geral** do pré-processamento de dados é **aumentar a qualidade** e a **precisão da análise** de dados, **minimizando a influência de ruídos** e **inconsistências** nos resultados finais.\n</p>\n\n\n## Importância do pré-processamento\n\n\n\nO pré-processamento de dados é uma etapa importante e crítica no processo de análise de dados. Algumas razões pelas quais é importante realizar o pré-processamento são:\n\n\n. . .\n\n\n\n&#128073; **Melhoria da qualidade dos dados:** O pré-processamento de dados pode ajudar a melhorar a qualidade dos dados, eliminando dados duplicados, ausentes ou inconsistentes. Isso resulta em dados mais precisos e confiáveis para análise.\n\n\n. . .\n\n\n&#128073; **Ajuste dos dados para a análise:** Muitos modelos e algoritmos de análise de dados requerem que os dados estejam em um formato específico. Na etapa do pré-processamento de dados ajusta-se os dados para que estejam em um formato adequado para a análise.\n\n  \n## Importância do pré-processamento\n\n\n\n&#128073; **Eliminação de ruídos:** Os dados geralmente contêm ruídos, como outliers e valores extremos, que podem afetar negativamente a precisão dos resultados finais. Nesta etapa, elimina-se esses ruídos, tornando os resultados mais precisos.\n  \n\n\n. . .\n\n\n&#128073; **Redução da complexidade dos dados:** Podemos reduzir a complexidade dos dados, eliminando variáveis desnecessárias e reduzindo o número de dimensões do conjunto de dados. Isso torna mais fácil a análise e interpretação dos dados.\n\n\n. . .\n\n\n\n&#128073; **Melhoria do desempenho do modelo:** O pré-processamento de dados pode ajudar a melhorar o desempenho do modelo, ao remover dados redundantes, normalizar os dados e selecionar os recursos mais importantes. Isso resulta em modelos mais precisos e confiáveis.\n  \n\n\n## Importância do pré-processamento\n\n\n\n![[Fonte: Forbes](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/?sh=34ce9abe6f63)](/images/time.jpg){fig-align=\"center\" .r-stretch}\n\n\n\n## Importância do pré-processamento\n\n![[Fonte: Giphy](https://gph.is/g/Eq2rpxa)](https://media3.giphy.com/media/9u514UZd57mRhnBCEk/giphy.gif){fig-align=\"center\" .r-stretch}\n\n\n## O que há de errado nessa base?\n\n<br>\n\n<style type=\"text/css\">\n.tg  {border-collapse:collapse;border-spacing:0;}\n.tg td{border-color:black;border-style:solid;border-width:1px;font-family:\"Montserrat\", sans-serif !default;;font-size:14px;\n  overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg th{border-color:black;border-style:solid;border-width:1px;font-family:\"Montserrat\", sans-serif !default;;font-size:14px;\n  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg .tg-34fe{background-color:#c0c0c0;border-color:inherit;text-align:center;vertical-align:top; font-size:30px}\n.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top; font-size:30px}\n</style>\n<table class=\"tg\">\n<thead>\n  <tr>\n    <th class=\"tg-34fe\">Usuário</th>\n    <th class=\"tg-34fe\">Idade</th>\n    <th class=\"tg-34fe\">Cidade</th>\n    <th class=\"tg-34fe\">Data</th>\n    <th class=\"tg-34fe\">Salário</th>\n    <th class=\"tg-34fe\">Npáginas</th>\n    <th class=\"tg-34fe\">Nsessões</th>\n    <th class=\"tg-34fe\">Nprodutos</th>\n    <th class=\"tg-34fe\">Clique</th>\n    <th class=\"tg-34fe\">Comprou</th>\n  </tr>\n</thead>\n<tbody>\n  <tr>\n    <td class=\"tg-c3ow\">user1</td>\n    <td class=\"tg-c3ow\">22</td>\n    <td class=\"tg-c3ow\">Belo Horizonte</td>\n    <td class=\"tg-c3ow\">22/10/21</td>\n    <td class=\"tg-c3ow\">1200</td>\n    <td class=\"tg-c3ow\">5</td>\n    <td class=\"tg-c3ow\">2</td>\n    <td class=\"tg-c3ow\">5</td>\n    <td class=\"tg-c3ow\">no</td>\n    <td class=\"tg-c3ow\">no</td>\n  </tr>\n  <tr>\n    <td class=\"tg-c3ow\">user2</td>\n    <td class=\"tg-c3ow\">1</td>\n    <td class=\"tg-c3ow\">São paulo</td>\n    <td class=\"tg-c3ow\">20/09/22</td>\n    <td class=\"tg-c3ow\">5000</td>\n    <td class=\"tg-c3ow\">21</td>\n    <td class=\"tg-c3ow\">4</td>\n    <td class=\"tg-c3ow\">11</td>\n    <td class=\"tg-c3ow\">yes</td>\n    <td class=\"tg-c3ow\">yes</td>\n  </tr>\n  <tr>\n    <td class=\"tg-c3ow\">user3</td>\n    <td class=\"tg-c3ow\">41</td>\n    <td class=\"tg-c3ow\">BH</td>\n    <td class=\"tg-c3ow\">23 de dezembro 2022</td>\n    <td class=\"tg-c3ow\">12000</td>\n    <td class=\"tg-c3ow\">2</td>\n    <td class=\"tg-c3ow\">1</td>\n    <td class=\"tg-c3ow\">3</td>\n    <td class=\"tg-c3ow\">NA</td>\n    <td class=\"tg-c3ow\">yes</td>\n  </tr>\n  <tr>\n    <td class=\"tg-c3ow\">user4</td>\n    <td class=\"tg-c3ow\">32</td>\n    <td class=\"tg-c3ow\">Miami</td>\n    <td class=\"tg-c3ow\">22/10/01</td>\n    <td class=\"tg-c3ow\">50000</td>\n    <td class=\"tg-c3ow\">NA</td>\n    <td class=\"tg-c3ow\">5</td>\n    <td class=\"tg-c3ow\">2</td>\n    <td class=\"tg-c3ow\">yes</td>\n    <td class=\"tg-c3ow\">no</td>\n  </tr>\n  <tr>\n    <td class=\"tg-c3ow\">user5</td>\n    <td class=\"tg-c3ow\">20</td>\n    <td class=\"tg-c3ow\">Tokyo</td>\n    <td class=\"tg-c3ow\">23/01/25</td>\n    <td class=\"tg-c3ow\">12220</td>\n    <td class=\"tg-c3ow\">5</td>\n    <td class=\"tg-c3ow\">5</td>\n    <td class=\"tg-c3ow\">8</td>\n    <td class=\"tg-c3ow\">no</td>\n    <td class=\"tg-c3ow\">yes</td>\n  </tr>\n  <tr>\n    <td class=\"tg-c3ow\">user6</td>\n    <td class=\"tg-c3ow\">28</td>\n    <td class=\"tg-c3ow\">NY</td>\n    <td class=\"tg-c3ow\">March 14, 2018</td>\n    <td class=\"tg-c3ow\">250000</td>\n    <td class=\"tg-c3ow\">8</td>\n    <td class=\"tg-c3ow\">NA</td>\n    <td class=\"tg-c3ow\">NA</td>\n    <td class=\"tg-c3ow\">no</td>\n    <td class=\"tg-c3ow\">yes</td>\n  </tr>\n  <tr>\n  </tr>\n</tbody>\n</table>\n\n\n\n\n## Principais problemas com dados reais\n\n<br>\n\n\n![](/images/tipos.png){fig-align=\"center\" .r-stretch}\n\n\n## Tipos de dados\n\nOs dados podem ser classificados em três tipos principais: **estruturados**, **semiestruturados** e **não estruturados**\n\n\n&#128073; **Estruturados**\n\nSão dados organizados em uma estrutura definida, como tabelas, colunas e linhas em um banco de dados. \n\n- **Exemplos:** informações de vendas, cadastros de clientes, registros de transações financeiras, entre outros.\n\n\n. . .\n\n&#128187; Para dados estruturados, a técnica de pré-processamento mais comum é a **limpeza de dados**, além da **seleção de atributos relevantes**, **normalização** e **transformação** de dados.\n\n\n\n## Tipos de dados\n\n&#128073; **Semiestruturados**\n\nSão dados que não possuem uma estrutura rígida como os dados estruturados, mas possuem algumas formas de organização, como marcadores, tags ou atributos. \n\n- **Exemplos:** arquivos XML, JSON, HTML, entre outros.\n\n\n\n . . .\n \n\n&#128187; Para dados semiestruturados, a técnica de pré-processamento mais comum é a **extração de informações relevantes**, que envolve a identificação de padrões e estruturas em dados como XML, JSON ou HTML, além da **extração de dados** a partir dessas estruturas. \n\n\n\n## Tipos de dados\n\n&#128073; **Não estruturados**\n\nSão dados que não possuem uma estrutura definida e estão em formato livre, como texto, imagens, vídeos, áudios, e-mails, redes sociais, entre outros. \n\n. . .\n\n&#128187; Exigem o uso de técnicas mais avançadas de **processamento de linguagem natural**, **reconhecimento de padrões** e **aprendizado de máquina**. \n\n\n. . .\n\nCom o aumento da quantidade de dados gerados diariamente, a análise de **dados semiestruturados** e **não estruturados** tem se tornado cada vez mais importante para empresas que desejam obter insights valiosos sobre seus clientes, mercado e tendências. \n\n\n\n## Processo de preparação da base de dados\n\n<br>\n\n![](/images/pre.png){fig-align=\"center\" .r-stretch}\n\n\n\n## Limpeza de dados\n  \n\n&#129300; O que é limpeza de dados? &#129529;\n  \n\n- **Limpeza de dados** é o processo de **identificar**, **remover** ou **corrigir dados imprecisos**, **incompletos**, **inconsistentes**, **duplicados** ou **irrelevantes** em um conjunto de dados. \n\n. . .\n\n\n- É uma etapa **importante** no processo de análise de dados, uma vez que **dados sujos** podem **afetar negativamente** a **qualidade** e **confiabilidade** dos resultados da análise.\n\n\n\n\n\n## Identificação de problemas\n  \n&#128073; Existem várias técnicas para identificar problemas de limpeza de dados em um conjunto de dados. Algumas das técnicas mais comuns incluem:\n  \n  \n  - **Análise visual:** pode-se inspecionar o conjunto de dados para identificar erros óbvios, como valores ausentes, valores que não fazem sentido ou valores extremos.\n  \n  \n  \n![[Fonte:Nagwa](https://www.nagwa.com/en/explainers/845148137695/)](/images/outlier.png){fig-align=\"center\" .r-stretch}  \n  \n  \n\n## Identificação de problemas\n\n  \n  - **Estatística descritiva:** realizar uma boa análise descritiva. Valores extremos ou valores que estão muito longe do intervalo interquartil, por exemplo, podem ser indicativos de problemas de limpeza de dados.\n\n\n![[Fonte:Statistics Cartoons by Ben Shabad](https://davidmlane.com/ben/cartoons.html)](/images/outlier2.png){fig-align=\"center\" .r-stretch}  \n\n\n## Identificação de problemas\n\n  - **Gráficos de distribuição:** analisar os gráficos de distribuição para cada variável e observar padrões incomuns na distribuição dos valores, como bimodalidade, assimetria ou outliers.\n\n\n![](/images/assimetrica.png){fig-align=\"center\" .r-stretch}  \n\n## Identificação de problemas\n\n  \n  - **Análise de correlação:** analisar as correlações entre as variáveis e procurar relações que não fazem sentido ou que não deveriam existir.\n\n\n![[Fonte:Medium](https://euleralencar.medium.com/o-que-é-a-correlação-espúria-819b77482764)](/images/espurias.png){fig-align=\"center\" .r-stretch}  \n\n\n\n\n\n## Identificação de problemas\n\n  - **Análise de consistência:** comparar valores em diferentes variáveis para ver se eles são consistentes entre si. \n      - Por exemplo, se uma pessoa é descrita como tendo 2 metros de altura e 30 kg de peso, pode haver um problema de limpeza de dados.\n\n\n\n![](/images/inconsistentes.png){fig-align=\"center\"}  \n\n\n\n\n## Tratamento de dados faltantes\n\n\n![[Fonte: Giphy](https://gph.is/2Tz7gn7)](https://media2.giphy.com/media/3s0OTExhi8qzSC3nHC/giphy.gif){fig-align=\"center\" .r-stretch}\n\n\n## Tratamento de dados faltantes\n\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n<br>\n\n> “The idea of imputation is both seductive and dangerous”. \n\n<p align=\"center\"> @madow1983incomplete </p>\n:::\n\n::: {.column width=\"50%\"}\n![](/images/missing.jpeg){fig-align=\"center\" width=\"700\"}\n:::\n::::\n\n\n<p align=\"center\">\nA escolha do método de tratamento de valor ausente **depende do tipo de valor ausente** identificado. Basicamente, existem dois tipos de valores ausentes: **aleatórios** e **não aleatórios**\n</p>\n\n\n\n## Mecanismo gerador dos dados faltantes\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n![](/images/dice.png){fig-align=\"center\" width=\"400\"}\n:::\n\n::: {.column width=\"50%\"}\n<br>\n<p align=\"center\">\n**MCAR (missing completely at random):** ocorrem de forma **completamente aleatória** e **não estão relacionados** com as outras variáveis do conjunto de dados.\n</p>\n:::\n::::\n\n\n<p align=\"center\">\n&#128073; Por exemplo, em uma pesquisa por telefone algumas das respostas não foram registradas devido a problemas técnicos que ocorreram aleatoriamente durante a coleta dos dados.\n</p>\n\n\n## Mecanismo gerador dos dados faltantes\n\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n<br>\n<p align=\"center\">\n**MNAR (missing not at random):** são valores ausentes que **estão relacionados** com outras variáveis do conjunto de dados e podem levar a **enviesamento** na análise dos dados.\n</p>\n\n:::\n\n::: {.column width=\"50%\"}\n![](/images/not_randon.jpeg){fig-align=\"center\" width=\"700\"}\n:::\n::::\n\n\n<p align=\"center\">\n&#128073; Por exemplo, em uma pesquisa sobre saúde mental, as pessoas que sofrem de depressão tendem a não responder perguntas sobre sua condição de saúde mental.\n</p>\n\n\n\n\n## Como identificar o mecanismo gerador dos dados faltantes?\n\n\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n![](/images/margin_plot.png){fig-align=\"center\" width=\"600\"}\n:::\n\n::: {.column width=\"50%\"}\n<br>\n<p align=\"center\">\nPara identificar **valores ausentes MCAR**, uma técnica é analisar a **distribuição de valores ausentes** em relação às **outras variáveis** do conjunto de dados.\n</p>\n:::\n::::\n\n\n<p align=\"center\">\n&#128073; Se **não houver correlação** entre a **ausência de valores** e outras variáveis, é provável que os valores ausentes **sejam MCAR**.\n</p>\n  \n\n\n\n\n## Como identificar o mecanismo gerador dos dados faltantes?\n\n\n&#128073; Também é possível realizar testes estatísticos para verificar se a distribuição dos valores ausentes é aleatória ou não.\n\n\n. . .\n\n  \n&#128577; Já a identificação de **valores ausentes MNAR** é mais complexa, pois eles estão relacionados a outras variáveis do conjunto de dados e, portanto, é mais difícil determinar se eles são **completamente aleatórios** ou **não**. \n\n\n## Como identificar o mecanismo gerador dos dados faltantes?\n\n&#128073; Algumas técnicas para identificar valores ausentes MNAR incluem:\n  \n. . .\n  \n  - **Análise de padrões de resposta:** é possível analisar como objetos com valores ausentes se diferenciam daqueles que não têm valores ausentes, em termos dos atributos. \n  \n  \n:::: {.columns}\n::: {.column width=\"50%\"}\n\n![](/images/margin_plot_2.png){fig-align=\"center\" width=\"600\"}\n:::\n\n::: {.column width=\"50%\"}\n<br>\n<p align=\"center\">\nSe os indivíduos com **valores ausentes** são **significativamente diferentes** em relação a essas variáveis, é provável que os **valores ausentes sejam MNAR**.\n</p>\n:::\n::::\n  \n  \n  \n\n## Como identificar o mecanismo gerador dos dados faltantes?\n\n<br>\n  \n  - **Análise de correlação:** é possível analisar a correlação entre as variáveis com valores ausentes e outras variáveis no conjunto de dados. \n      - Se houver uma correlação significativa entre as variáveis, é possível que os valores ausentes sejam MNAR.\n\n\n\n## Como identificar o mecanismo gerador dos dados faltantes?\n\n<br>\n  \n  - **Análise visual:** é possível realizar análises gráficas para verificar se há algum padrão de valores ausentes que sugira que eles não são aleatórios. \n\n    - Por exemplo, pode-se criar um gráfico de dispersão de uma variável em relação a outra, marcando as observações com valores ausentes. Se houver um padrão na localização dos valores ausentes no gráfico, é possível que eles sejam MNAR.\n\n\n\n## Tratamento de valores ausentes completamente aleatórios\n  \n<br>\n\n<p></p>\n\n\nO tratamento de **valores ausentes completamente aleatórios (MCAR)** é relativamente simples, pois os valores ausentes são **independentes** das demais variáveis e podem ser tratados **sem viés**.\n\n\n## Tratamento de valores ausentes completamente aleatórios\n\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n<p align=\"center\">\n**Exclusão de registros com valores ausentes:** Se a proporção de valores ausentes é pequena em relação ao tamanho do conjunto de dados, é possível excluir os registros que contêm valores ausentes sem comprometer a análise.\n</p>\n\n:::\n\n::: {.column width=\"50%\"}\n<p></p>\n![](/images/delete.jpeg){fig-align=\"center\" width=\"600\"}\n:::\n::::\n  \n<p align=\"center\">\nNo entanto, isso pode levar a uma **perda de informações valiosas** e **reduzir o tamanho** do conjunto de dados.\n</p> \n\n  \n\n## Tratamento de valores ausentes completamente aleatórios\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n<p align=\"center\">\n**Imputação de valores:** Se o número de valores ausentes é grande, é possível imputar os valores ausentes usando métodos estatísticos, como a média, mediana ou regressão.\n</p>\n\n:::\n\n::: {.column width=\"50%\"}\n<p></p>\n![](/images/imputacao.png){fig-align=\"center\" width=\"600\"}\n:::\n::::\n  \n<p align=\"center\">\nEsses métodos são **simples** e **rápidos**, mas podem **introduzir um viés nos resultados**, dependendo da **distribuição dos valores ausentes** e da escolha do método de imputação.\n</p> \n\n\n\n## Tratamento de valores ausentes completamente aleatórios\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n<p></p>\n![](/images/imput_ML.png){fig-align=\"center\" width=\"600\"}\n\n\n:::\n\n::: {.column width=\"50%\"}\n<p align=\"center\">\n**Modelagem com técnicas de aprendizado de máquina:** As técnicas de aprendizado de máquina podem ajudar a prever valores ausentes com base em outros dados disponíveis.\n</p>\n:::\n::::\n  \n<p align=\"center\">\n**Mais precisa** do que a imputação de valores, mas também pode ser **mais complexa** e exigir um **conjunto de dados de treinamento grande** o suficiente para o **modelo aprender a relação entre as variáveis**.\n</p> \n  \n\n  \n  \n## Tratamento de valores ausentes não aleatórios\n  \n<br>\n<p></p>\n\nO tratamento de **valores ausentes não aleatórios (MNAR)** é **mais complexo** do que o tratamento de **valores ausentes completamente aleatórios (MCAR)**, pois os valores ausentes estão **relacionados** a outras variáveis do conjunto de dados e podem levar a um **viés na análise** se não forem tratados adequadamente.\n\n\n  \n## Tratamento de valores ausentes não aleatórios  \n\n  \n  - **Modelagem com técnicas de aprendizado de máquina:** Como os valores ausentes MNAR estão relacionados a outras variáveis do conjunto de dados, a modelagem com técnicas de aprendizado de máquina pode ser uma abordagem útil para prever os valores ausentes com base nas informações disponíveis. \n\n. . . \n  \n  - **Imputação baseada em modelos:** A imputação baseada em modelos é uma técnica que envolve a construção de um modelo estatístico para prever os valores ausentes com base nas informações disponíveis. \n\n    - Essa abordagem requer um conhecimento prévio da relação entre as variáveis e pode ser mais complexa do que outros métodos de imputação.\n\n  \n## Tratamento de valores ausentes não aleatórios\n\n<br>\n\n  - **Análise de sensibilidade:** A análise de sensibilidade é uma técnica que envolve testar diferentes cenários e valores de imputação para avaliar o impacto nos resultados da análise. \n\n    - Essa abordagem pode ajudar a identificar os valores mais plausíveis para a imputação e a avaliar a robustez dos resultados.\n\n\n## Tratamento de valores ausentes não aleatórios\n\nUma vez que os valores ausentes estão **relacionados** a outras variáveis do conjunto de dados, há um **padrão de ausência** definido em MNAR, que pode ser importante. \n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n<p></p>\nUma maneira de **reter esse padrão de ausência** é adicionando uma **variável binária**, indicando se a **característica foi imputada**.\n\n:::\n\n::: {.column width=\"50%\"}\n<p></p>\n![](/images/imput_bin.png){fig-align=\"center\" width=\"800\"}\n:::\n::::\n\n\n\n  \n## Tratamento de valores inconsistentes\n  \n\nO tratamento de valores inconsistentes é importante para garantir a qualidade e a confiabilidade dos dados <span style='font-size:50px;'>&#8594;</span> podem afetar negativamente a análise e a interpretação dos resultados.\n\n\n  \n![](/images/inconsistente.jpg){fig-align=\"center\" width=\"600\"}\n\n## Tratamento de valores inconsistentes\n\nAlgumas técnicas comuns para lidar com valores inconsistentes incluem:\n  \n  - **Identificação de valores inconsistentes:** Verifica-se os valores em cada variável, comparando-os com os valores esperados ou com outras fontes de dados. Também é possível usar técnicas de detecção de outliers para identificar valores inconsistentes automaticamente.\n\n. . .\n  \n  - **Correção manual:** Para valores inconsistentes que podem ser facilmente corrigidos, a correção manual pode ser uma abordagem eficaz. \n\n    - Isso pode incluir a revisão manual dos dados e a correção de erros, como erros de digitação ou valores fora do intervalo esperado.\n\n\n## Tratamento de valores inconsistentes\n  \n  - **Imputação de valores:** Para valores inconsistentes que não podem ser facilmente corrigidos, a imputação de valores pode ser uma abordagem útil. \n\n    - Isso envolve a substituição de valores inconsistentes por valores estimados com base em outras informações disponíveis no conjunto de dados.\n\n. . .\n  \n  - **Exclusão de registros:** Para valores inconsistentes que não podem ser corrigidos e não podem ser imputados com precisão, a exclusão de registros pode ser uma abordagem apropriada. \n\n    - Isso envolve a remoção dos registros com valores inconsistentes do conjunto de dados.\n\n\n## Tratamento de ruídos\n\n![[Fonte: Giphy](https://gph.is/g/ZPBYYOp)](https://media2.giphy.com/media/QFuBzoQdijNFztFEp6/giphy.gif){fig-align=\"center\" .r-stretch}\n\n\n## Tratamento de ruídos\n\n**Ruído**, no contexto da **estatística e análise de dados**, refere-se a qualquer tipo de **interferência** ou **distorção** que pode obscurecer ou alterar a interpretação dos dados coletados. \n\n\n. . .\n\nEsse fenômeno pode surgir de **diversas fontes**, como erros de entrada de dados, erros de medição, valores atípicos, variabilidade aleatória ou viés e influências externas que **não estão diretamente relacionadas ao fenômeno em estudo**.\n\n. . .\n\nO ruído pode ser considerado um **fator indesejado** que compromete a **precisão** e a **confiabilidade** das análises estatísticas.\n\n## Tratamento de ruídos\n\n\n\n![](/images/ruido2.png){fig-align=\"center\" width=\"600\"}\n\n## Tratamento de ruídos\n\n<br>\n\n- **Identificação e remoção de valores atípicos:** valores que são muito diferentes dos outros valores no conjunto de dados podem ser identificados como valores atípicos. \n\n  - Esses valores podem ser removidos do conjunto de dados ou tratados separadamente para minimizar o impacto no resultado da análise.\n\n. . .\n  \n- **Correção de erros de entrada de dados:** erros de entrada de dados podem ser corrigidos por meio da revisão manual dos dados ou por meio de algoritmos de detecção e correção automática de erros.\n\n## Tratamento de ruídos\n\n<br>\n\n- **Normalização ou padronização de dados:** a normalização ou a padronização de dados pode ser usada para tornar os dados comparáveis e interpretáveis, especialmente quando os dados têm unidades diferentes ou escalas diferentes.\n\n. . .\n  \n\n- **Utilização de técnicas de agrupamento:** técnicas de agrupamento, como análise de cluster, podem ser usadas para identificar padrões em um conjunto de dados e reduzir o impacto do ruído.\n\n\n\n\n## Tratamento de ruídos\n\n  - **Utilização de técnicas de suavização de dados:** técnicas de suavização, como média móvel ou suavização exponencial, podem ser usadas para reduzir o impacto do ruído nos dados.\n  \n  \n![](/images/suavizacao.png){fig-align=\"center\" width=\"400\"}  \n  \n## Como identificar um valor atípico?\n  \n  \n  - **Gráfico box-plot**\n  \n. . .\n  \n  - **Z-score:** valores com um z-score maior do que um limite (geralmente 3) são considerados valores atípicos.\n\n. . .\n  \n  - **Intervalo interquartil (IQR):** valores abaixo de Q1 - 1,5 x IQR ou acima de Q3 + 1,5 x IQR são considerados valores atípicos.\n\n\n. . .\n\n  - **Método de DBSCAN:** é um algoritmo de clusterização que agrupa pontos de dados que estão próximos uns dos outros e identifica valores que não estão próximos a nenhum cluster, o que pode ser um sinal de valores atípicos.\n\n\n\n## Como identificar um valor atípico?\n\n<br>\n\nQuaisquer que sejam as técnicas empregadas, a **documentação** e o **registro das etapas de limpeza de dados** são **essenciais** para garantir a **reprodutibilidade**, **transparência**, **colaboração**, **auditabilidade** e **controle de qualidade em análises de dados**.\n\n\n  \n## Integração de dados\n  \n:::: {.columns}\n::: {.column width=\"50%\"}\n\n<br>\n<br>\n**Integração de dados** é o processo de **combinar dados de múltiplas fontes** em um **único conjunto de dados** **coerente** e **integrado**. \n\n:::\n\n::: {.column width=\"50%\"}\n<p></p>\n<p align=\"center\">\n![](/images/Data-Integration.jpg){fig-align=\"center\" width=\"500\"}\n</p>\n:::\n::::\n\n<p align=\"center\">\nO **objetivo da integração de dados** é criar um conjunto de dados mais **completo** e **preciso**, permitindo análises mais **abrangentes** e **informadas**.\n</p> \n\n  \n## Integração de dados\n  \n  - **Fusão de dados:** é o processo de combinar dois ou mais conjuntos de dados com base em uma chave comum. \n\n    -  Por exemplo, dados de clientes de uma empresa podem ser fundidos com dados de vendas, com base no número de identificação de cliente.\n\n. . .\n  \n  - **Análise de correspondência:** é uma técnica de integração de dados que permite combinar informações de diferentes fontes, com base em uma análise de correspondência de variáveis. \n\n    - Por exemplo, dados de vendas de uma empresa podem ser combinados com dados demográficos, com base em correspondências de variáveis, como localização geográfica ou faixa etária.\n\n## Integração de dados\n\n<br>\n<br>\n\n<p align=\"center\">  \n<span style='font-size:100px;'>&#128161;</span> Independentemente da técnica usada, é importante lembrar que a **integração de dados** pode ser **complexa** e **demorada** e pode envolver a **identificação** e **correção de inconsistências nos dados**. \n</p>\n\n\n\n  \n## Redução de dados\n  \n\n\n\n<br>\n<br>\n<span style='font-size:100px;'>&#128161;</span> A **redução de dados** é uma técnica usada para **diminuir a dimensão** de um conjunto de dados, ou seja, reduzir o número de variáveis ou características que compõem o conjunto de dados. \n\n\n\n\n\n\n## Redução de dados\n\n\n- Existem várias razões para reduzir os dados:\n  \n  - **Simplificar** a análise de dados, tornando-a mais fácil e mais rápida de ser executada;\n  - **Reduzir** o tempo de processamento e armazenamento dos dados;\n  - **Melhorar** a qualidade dos dados, eliminando variáveis irrelevantes ou redundantes que possam afetar negativamente a análise;\n  - **Preparar** os dados para a entrada em um modelo de aprendizado de máquina.\n\n\n\n## Análise de Componentes Principais\n  \n\n![](/images/pca.png){fig-align=\"center\" width=\"500\"}\n\n## Amostragem\n\n![](/images/sampling.png){fig-align=\"center\" width=\"500\"}\n  \n## Seleção de atributos\n\n- **Seleção de atributos** é um processo de pré-processamento de dados que envolve a **escolha dos atributos** (variáveis) **mais relevantes** para a análise. \n\n\n. . .\n\n\n- O objetivo da seleção de atributos é **reduzir a dimensionalidade dos dados**, eliminando características **irrelevantes** e **redundantes**, e, assim, melhorar a **precisão** e a **eficiência** da análise.\n\n\n\n## Seleção de atributos\n  \n\n**Seleção baseada em filtro:** Essa técnica usa métricas estatísticas para avaliar a relevância dos atributos e seleciona aqueles que têm maior correlação com a variável de interesse. \n\n  - **Métodos de filtragem:** coeficiente de correlação, ganho de informação e o teste de qui-quadrado.\n\n![](/images/fig01.png)\n\n## Seleção de atributos\n\n\n**Seleção baseada em wrapper:** Essa técnica envolve a seleção de atributos por meio de um modelo de aprendizado de máquina, que é treinado em um conjunto de atributos selecionados. O modelo é avaliado usando validação cruzada e as atributos são selecionados com base no desempenho do modelo.\n\n  - **Métodos wrapper:** Forward stepwise selection, Backward Elimination, Bi-directional stepwise selection & elimination.\n\n![](/images/fig02.png)\n\n## Seleção de atributos\n\n**Seleção baseada em incorporação:** Essa técnica envolve a seleção de atributos durante o processo de treinamento do modelo de aprendizado de máquina. O modelo é treinado com todas os atributos e, em seguida, os atributos são removidos com base em sua importância para o modelo.\n\n  - **Métodos de incorporação:** Regressão LASSO, Árvores de decisão...\n\n![](/images/fig03.png)\n\n\n## Transformação de dados\n\n![[Fonte: Giphy](http://gph.is/1Vp16TL)](https://media3.giphy.com/media/P4TqKx6NHyLnO/giphy.gif){fig-align=\"center\" .r-stretch}\n\n\n\n## Transformação de dados\n  \nAs bases de dados brutas e integradas a partir de **bases distintas** podem sofrer, além de **valores ausentes**, **ruídos** e **inconsistências**, de dados não ou pouco **padronizados**.\n\n. . .\n\n- Por exemplo, pode haver valores de um mesmo atributo escritos em maiúsculo e outros em minúsculo, e os formatos e as unidades podem ser diferentes.\n\n. . .\n  \n- Outro tipo de problema encontrado é a **não uniformidade dos atributos**, ou seja, alguns atributos podem ser **numéricos**, outros **categóricos**, e os **domínios de cada atributo podem ser muito diferentes**.\n\n\n## Transformação de dados\n\n\nComo podemos resolver esses problemas?\n\n. . .  \n\n- **Padronização:** Resolver as diferenças de unidades e escalas dos dados.\n    - **Capitalização:** é usual padronizar as fontes,\tnormalmente para maiúsculo.\n    - **Padronização de formatos:** observar e padronizar o formato de cada atributo da base, principalmente quando diferentes bases precisam ser integradas.\n    - **Conversão de unidades:** todos os dados devem ser convertidos e padronizados em uma mesma unidade de medida.\n    - **Normalização:** tornar os dados mais apropriados à aplicação de algum algoritmo de mineração.\n\n\n\n## Tipos de normalização\n  \n  - **Normalização Max-Min:** Realiza uma transformação linear nos dados originais\n\n\n$$X' = \\dfrac{X - \\min(X)}{\\max(X) - \\min(X)}$$\n\n\n. . .\n\n\n\n  - **Normalização pelo escore-z:** Útil quando os valores máximo e mínimo de um atributo forem desconhecidos ou quando existe outliers.\n      \n$$X' = \\dfrac{X - \\bar{X}}{s_X}$$ \n  \n  \n  \n## Tipos de normalização\n\n  \n  - **Normalização pelo escalonamento decimal:** Move a casa decimal de um atributo $X$.\n\n$$X' = \\dfrac{X}{10^j}$$\n\t\t\t\n  em que $j$ é o menor inteiro tal que $\\max(|X'|)< 1$.\n\n\n\n. . .\n\n  \n  - **Normalização pela distância interquartilica:** Toma o valor do atributo, subtrai a mediana e divide pela distância interquartílica ($DIQ = Q_3 - Q_1$)\t\n\n$$X' =  \\dfrac{X - Q_2}{DIQ}$$\n\n\n\n\n## Exemplo de uso das diferentes normalizações\n<br>\n<style type=\"text/css\">\n.tg  {border-collapse:collapse;border-spacing:0;}\n.tg td{border-color:black;border-style:solid;border-width:1px;font-family:\"Montserrat\", sans-serif !default;font-size:30px;\n  overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg th{border-color:black;border-style:solid;border-width:1px;font-family:\"Montserrat\", sans-serif !default;font-size:50px;\n  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg .tg-34fe{background-color:#c0c0c0;border-color:inherit;text-align:center;vertical-align:top}\n.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}\n</style>\n<table class=\"tg\">\n<thead>\n  <tr>\n    <th class=\"tg-34fe\">ID</th>\n    <th class=\"tg-34fe\">Valor original</th>\n    <th class=\"tg-34fe\">Max-Min</th>\n    <th class=\"tg-34fe\">Escore-z</th>\n    <th class=\"tg-34fe\">Escalonamento decimal</th>\n    <th class=\"tg-34fe\">Distância interquartílica</th>\n  </tr>\n</thead>\n<tbody>\n  <tr>\n    <td class=\"tg-c3ow\">1</td>\n    <td class=\"tg-c3ow\">67</td>\n    <td class=\"tg-c3ow\">0,85</td>\n    <td class=\"tg-c3ow\">0,73</td>\n    <td class=\"tg-c3ow\">0,67</td>\n    <td class=\"tg-c3ow\">0,40</td>\n  </tr>\n  <tr>\n    <td class=\"tg-c3ow\">2</td>\n    <td class=\"tg-c3ow\">43</td>\n    <td class=\"tg-c3ow\">0,33</td>\n    <td class=\"tg-c3ow\">-0,92</td>\n    <td class=\"tg-c3ow\">0,43</td>\n    <td class=\"tg-c3ow\">-0,80</td>\n  </tr>\n  <tr>\n    <td class=\"tg-c3ow\">3</td>\n    <td class=\"tg-c3ow\">58</td>\n    <td class=\"tg-c3ow\">0,65</td>\n    <td class=\"tg-c3ow\">0,11</td>\n    <td class=\"tg-c3ow\">0,58</td>\n    <td class=\"tg-c3ow\">-0,05</td>\n  </tr>\n  <tr>\n    <td class=\"tg-c3ow\">4</td>\n    <td class=\"tg-c3ow\">28</td>\n    <td class=\"tg-c3ow\">0,00</td>\n    <td class=\"tg-c3ow\">-1,96</td>\n    <td class=\"tg-c3ow\">0,28</td>\n    <td class=\"tg-c3ow\">-1,55</td>\n  </tr>\n  <tr>\n    <td class=\"tg-c3ow\">5</td>\n    <td class=\"tg-c3ow\">74</td>\n    <td class=\"tg-c3ow\">1,00</td>\n    <td class=\"tg-c3ow\">1,21</td>\n    <td class=\"tg-c3ow\">0,74</td>\n    <td class=\"tg-c3ow\">0,75</td>\n  </tr>\n  <tr>\n    <td class=\"tg-c3ow\">6</td>\n    <td class=\"tg-c3ow\">65</td>\n    <td class=\"tg-c3ow\">0,80</td>\n    <td class=\"tg-c3ow\">0,59</td>\n    <td class=\"tg-c3ow\">0,65</td>\n    <td class=\"tg-c3ow\">0,30</td>\n  </tr>\n  <tr>\n    <td class=\"tg-c3ow\">7</td>\n    <td class=\"tg-c3ow\">70</td>\n    <td class=\"tg-c3ow\">0,91</td>\n    <td class=\"tg-c3ow\">0,94</td>\n    <td class=\"tg-c3ow\">0,70</td>\n    <td class=\"tg-c3ow\">0,55</td>\n  </tr>\n  <tr>\n    <td class=\"tg-c3ow\">8</td>\n    <td class=\"tg-c3ow\">42</td>\n    <td class=\"tg-c3ow\">0,30</td>\n    <td class=\"tg-c3ow\">-0,99</td>\n    <td class=\"tg-c3ow\">0,42</td>\n    <td class=\"tg-c3ow\">-0,85</td>\n  </tr>\n  <tr>\n    <td class=\"tg-c3ow\">9</td>\n    <td class=\"tg-c3ow\">57</td>\n    <td class=\"tg-c3ow\">0,63</td>\n    <td class=\"tg-c3ow\">0,04</td>\n    <td class=\"tg-c3ow\">0,57</td>\n    <td class=\"tg-c3ow\">-0,10</td>\n  </tr>\n  <tr>\n    <td class=\"tg-c3ow\">10</td>\n    <td class=\"tg-c3ow\">60</td>\n    <td class=\"tg-c3ow\">0,70</td>\n    <td class=\"tg-c3ow\">0,25</td>\n    <td class=\"tg-c3ow\">0,60</td>\n    <td class=\"tg-c3ow\">0,05</td>\n  </tr>\n  <tr>\n  </tr>\n</tbody>\n</table>\n\n## Transformação de dados\n\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n&#128073; **Transformação logarítmica:** Usada para reduzir a assimetria e a variância dos dados. \n\n\n\n:::\n\n::: {.column width=\"50%\"}\n \n\n::: {.cell}\n::: {.cell-output-display}\n![](pre_processamento_files/figure-revealjs/unnamed-chunk-1-1.png){width=960}\n:::\n:::\n\n\n:::\n::::\n\n<p align=\"center\"> \nÉ especialmente **útil** quando os dados estão distribuídos de **forma exponencial** ou quando há um **grande intervalo de valores** entre as observações.\n</p>\n\n\n\n\n\n\n## Transformação de dados\n\nA **transformação logarítmica** é definida pela seguinte equação:\n\n$$\ny = \\log(x)\n$$\n\nonde $x$ é a variável a ser transformada e $y$ é a variável transformada. \n\n. . .\n\nTrata-se de uma transformação **monotônica**, isto é, não afeta a **ordem dos dados**. Isso é importante para modelos preditivos porque garante que a transformação não afete a capacidade do modelo de capturar a relação entre as variáveis.\n\n\n\n## Transformação de dados\n\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n&#128073; **Transformação de raiz quadrada:** Similar à transformação logarítmica, com o benefício de manter a escala original dos dados, facilitando a interpretação. \n\n\n\n:::\n\n::: {.column width=\"50%\"}\n \n\n::: {.cell}\n::: {.cell-output-display}\n![](pre_processamento_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n:::\n::::\n\n<p align=\"center\"> \nA transformação logarítmica é mais adequada para **dados com caudas longas** e **uma grande variação**, enquanto a **transformação da raiz quadrada** é mais adequada para **dados com uma variação moderada**. Além disso, a o uso de logarítmos tem o efeito de estabilizar a variância dos dados, enquanto a o uso da raiz quadrada tem o efeito de reduzir a variância dos dados.\n</p>\n\n\n\n## Transformação de dados\n\nA transformação de raiz quadrada é definida pela seguinte equação:\n\n\n$$\ny = \\sqrt x\n$$\n\n\nonde $x$ é a variável a ser transformada e $y$ é a variável transformada. \n\n\n. . .\n\nAssim como a transformação logarítimica, a transformação de raiz quadrada é uma transformação monotônica, o que significa que não afeta a ordem dos dados.\n\n\n## Transformação de dados\n\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n&#128073; A **transformação de Box-Cox** é uma técnica para transformar variáveis em modelos preditivos que é amplamente utilizada para melhorar a qualidade da modelagem e a precisão das previsões. \n\n\n\n:::\n\n::: {.column width=\"50%\"}\n \n\n::: {.cell}\n::: {.cell-output-display}\n![](pre_processamento_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n:::\n::::\n\n<p align=\"center\"> \nÉ uma **técnica paramétrica** que depende de um **parâmetro lambda** que é estimado a partir dos dados, podendo ser usada apenas com **variáveis não negativas**. \n</p>\n\n\n\n\n\n## Transformação de dados\n\nA transformação de Box-Cox é definida pela seguinte equação:\n\n\n$$\ny = \n  \\begin{cases}\n      \\dfrac{(x^\\lambda - 1)}{\\lambda}, & se \\ \\lambda \\neq  0 \\\\\n      \\log(x), & se \\ \\lambda = 0 \n  \\end{cases}\n$$\n\n\nonde $x$ é a variável a ser transformada e $y$ é a variável transformada. \n\n. . .\n\nEsta é uma técnica de transformação de dados útil usada para estabilizar a variância, tornar os dados mais semelhantes à distribuição normal.\n  \n  - Por exemplo, quando um atributo tem a aparência de uma curva normal mas está descolado para a direita ou esquerda. \n  \n  \n\n\n## Transformação de dados\n\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n<br>\n&#128073; A **transformação Yeo-Johnson** é uma técnica de transformação semelhante à transformação de Box-Cox. \n:::\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](pre_processamento_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n:::\n::::\n<p align=\"center\"> \nNo entanto, a transformação Yeo-Johnson é mais flexível porque pode ser usada para **variáveis que podem assumir valores negativos**. \n</p>\n\n\n## Transformação de dados\n\nA transformação Yeo-Johnson é definida pela seguinte equação:\n\n\n$$\ny = \n  \\begin{cases}\n      \\dfrac{(x + 1)^\\lambda - 1}{\\lambda}, & se \\ x \\geq  0, \\ \\lambda \\neq 0 \\\\\n      \\ln(x + 1), & se \\ x \\geq 0 \\ \\lambda = 0 \\\\\n      \\dfrac{-((-x + 1)^{(2 - \\lambda)} - 1)}{(2 - \\lambda)}, & se \\ x <  0, \\ \\lambda \\neq 2 \\\\\n      -\\ln(-x+1) & se \\ x <  0, \\ \\lambda = 2 \n  \\end{cases}\n$$\n\n\nonde $x$ é a variável a ser transformada e $y$ é a variável transformada.\n\n\n\n## Discretização de dados\n\n**Discretização** é o processo de transformar uma **variável contínua** em uma **variável categórica ou discreta**. \n\n- É útil quando se deseja agrupar valores contínuos em categorias ou intervalos para simplificar a análise ou reduzir o efeito de valores extremos. \n\n\n![](/images/discretizacao.png){fig-align=\"center\" width=\"500\"}\n\n## Discretização de dados\n\n<br>\n\nTécnicas comuns de discretização:\n\n. . .\n\n  - **Discretização equi-probabilística:** Essa técnica envolve a divisão dos dados em intervalos de tamanho igual, de modo que cada intervalo contenha aproximadamente a mesma quantidade de observações.\n\n. . .\n\n  - **Discretização equi-distante:** Nessa técnica, os dados são divididos em intervalos de tamanho igual, com base em uma distância predefinida.\n\n## Discretização de dados\n\n<br>\n\n  - **Discretização por quartis:** Os dados são divididos em quartis, com base nos valores de corte que dividem os dados em quatro partes iguais.\n  \n  \n. . . \n\n\n\n  - **Discretização por frequência:** Os dados são divididos em intervalos com base na frequência de observações em cada intervalo.\n\n\n## Discretização de dados\n\n\n  - **Binarização:** A binarização é uma técnica de transformação de dados que converte valores quantitativos em valores binários (0 ou 1) com base em um valor de corte.\n  \n\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n![](/images/fig05.png){fig-align=\"center\" width=\"500\"} \n\n\n\n:::\n\n::: {.column width=\"50%\"}\n![](/images/fig08.png){fig-align=\"center\" width=\"1000\"}\n:::\n::::\n\n\n\n## References {visibility=\"uncounted\"}\n\n::: {#refs}\n:::",
    "supporting": [
      "pre_processamento_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}