{
  "hash": "a5160b8c61fbce4b2563a378002fe0c6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Desbalanceamento de Classes: Um Problema Real em Ciência de Dados\"\nformat:\n  html:\n    toc: true\n    code-fold: false\n    code-summary: \"Mostrar código\"\n    embed-resources: true\nexecute: \n  eval: true \n  message: false\n  warning: false  \n---\n\n\nHoje vamos conversar sobre um desafio comum e muitas vezes subestimado em projetos de ciência de dados e aprendizagem de máquina: o desbalanceamento de classes. Esse problema ocorre quando as classes de interesse em um conjunto de dados não são representadas igualmente. Por exemplo, em um problema de detecção de fraude, a maioria das transações será legítima (classe majoritária), enquanto pouquíssimas serão fraudulentas (classe minoritária).\n\n\n::: {.cell}\n\n:::\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](desbalanceamento_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n\n## Quando o desbalanceamento se torna um problema?\n\n\nNão existe uma regra universal para definir a partir de qual proporção um conjunto de dados é \"desbalanceado\". A verdade é que a definição de desbalanceamento é contextual e depende do problema que você está resolvendo.\n\nNo entanto, para efeitos práticos, se a sua classe de interesse (geralmente a minoritária) representa menos de 40% do seu conjunto de dados, já é um indício de que a base de dados é desbalanceada e podemos pensar em estratégias para lidar com isso. Quanto menor essa proporção, mais crítico se torna o problema. Cenários com 1:100 (1% da classe minoritária), como detecção de fraudes ou doenças raras, são considerados severamente desbalanceados e exigem tratamento específico. Proporções ainda mais extremas, como 1:1000 ou menos, são comuns em domínios como a detecção de ataques cibernéticos.\n\n<style>\n  table {\n    width: 100%;\n    border-collapse: collapse;\n    margin: 20px 0;\n  }\n  th, td {\n    border: 1px solid #ddd;\n    padding: 8px;\n    text-align: center; /* Centraliza o texto nas células */\n  }\n  th {\n    background-color: #f2f2f2;\n  }\n</style>\n\n<p>A tabela a seguir apresenta os nomes e as faixas geralmente aceitas para diferentes graus de <strong>desbalanceamento de classes</strong>:</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>Porcentagem de dados pertencentes à classe minoritária</th>\n      <th>Grau de desequilíbrio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20%-40% do conjunto de dados</td>\n      <td>Leve</td>\n    </tr>\n    <tr>\n      <td>1%-20% do conjunto de dados</td>\n      <td>Moderado</td>\n    </tr>\n    <tr>\n      <td>&lt;1% do conjunto de dados</td>\n      <td>Extremo</td>\n    </tr>\n  </tbody>\n</table>\n\n\n\n\n\n\n## Consequências do desbalanceamento de classes\n\nO desbalanceamento de classes pode ter um impacto significativo na performance dos seus modelos, levando a conclusões enganosas. Aqui estão as principais consequências:\n\n- **Viés para a Classe Majoritária:** Modelos de aprendizagem de máquina tendem a ser otimizados para a acurácia geral. Quando há um desbalanceamento, eles podem aprender a prever a classe majoritária com alta frequência para minimizar o erro total. Isso resulta em uma acurácia inflacionada, que não reflete a capacidade real do modelo de identificar a classe minoritária, geralmente a de maior interesse (ex: fraudes, doenças raras).\n\n\n- **Baixo Desempenho na Classe Minoritária:** A consequência direta do viés é que o modelo terá dificuldade em identificar corretamente as instâncias da classe minoritária. Isso se traduz em métricas como precisão, recall e F1-score muito baixas para essa classe, indicando que o modelo é ineficaz para o objetivo principal.\n\n- **Modelos Inúteis na Prática:** Um modelo que não consegue identificar a classe minoritária, mesmo com uma alta acurácia geral, é frequentemente inútil em cenários reais. Em muitos problemas, a classe minoritária é a que carrega o maior valor ou risco (fraudes, doenças, defeitos). Mesmo um desbalanceamento \"moderado\" pode significar a perda de oportunidades cruciais ou a falha na detecção de eventos importantes.\n\n\n\n\n\n## Como lidar com o desbalanceamento?\n\n\nLidar com o desbalanceamento de classes é um passo crucial para construir modelos preditivos eficazes, especialmente quando a classe minoritária é a de maior interesse. Felizmente, existem diversas estratégias que podemos empregar para mitigar esse problema. Vamos explorar as principais, acompanhadas de exemplos práticos em R.\n\n\n### 1. Reamostragem (Resampling)\n\nA reamostragem é uma das abordagens mais diretas e populares, focando em alterar a proporção das classes no seu conjunto de dados de treinamento. \n\n\n\n![](/images/under_over.png){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n\nExistem duas vertentes principais, que também podem trabalhar simultaneamente:\n\n\n- **Oversampling (Sobreamostragem):** A ideia do oversampling é aumentar o número de instâncias da classe minoritária, tornando-a mais \"visível\" para o algoritmo de aprendizado. Uma técnica amplamente utilizada é o **SMOTE (Synthetic Minority Over-sampling Technique)**. O **SMOTE** não duplica as amostras existentes; ele cria novos **exemplos sintéticos** da classe minoritária, baseando-se nas similaridades entre os exemplos minoritários existentes (seus vizinhos mais próximos). Isso ajuda a expandir a representação da classe minoritária sem introduzir *overfitting* por repetição exata de dados.\n\n\n\n![](/images/smote.png){.nostretch fig-align=\"center\" width=\"1000px\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Exemplo de SMOTE em R\n# Primeiramente, instale o pacote 'smotefamily' se ainda não tiver:\n# install.packages(\"smotefamily\")\nlibrary(smotefamily)\nlibrary(tidyverse) \nlibrary(ROSE)\n\ndata(hacide)\n\n# Gerar o gráfico de barras\nggplot(dados_treino, aes(x = target, fill = target)) +\n  geom_bar() +\n  # Adicionar rótulos de contagem em cima das barras\n  geom_text(stat = 'count', aes(label = after_stat(count)), vjust = -0.5) +\n  labs(\n    title = \"Distribuição das Classes em Dados Sintéticos Desbalanceados\",\n    x = \"Classe\",\n    y = \"Contagem de Amostras\",\n    fill = \"Classe\"\n  ) +\n  scale_fill_manual(values = c(\"1\" = \"#FD800D\", \"0\" = \"#2077B5\")) + # Cores personalizadas\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5)) # Centraliza o título\n```\n\n::: {.cell-output-display}\n![](desbalanceamento_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Preparando os dados para smotefamily::SMOTE()\n# A função SMOTE() do smotefamily espera:\n# - X: um dataframe de variáveis preditoras (apenas numéricas)\n# - target: um vetor da variável target\n# - K: número de vizinhos (padrão é 5)\n# - dup_size: um fator de duplicação para a classe minoritária.\n#             Se a minoritária é 100 e queremos que ela tenha 300 (3x), dup_size seria 2 (100 + 2*100 = 300)\n\n# Separando as features (X) da variável target\nX_features <- dados_treino %>% dplyr::select(-target)\ny_target <- dados_treino$target\n\n# Aplicando SMOTE usando smotefamily\n# Queremos que a classe '1' (minoritária) tenha aproximadamente 33 vezes o número original de exemplos.\n# O número original é 43. Queremos aproximadamente 1450.\n# O fator de duplicação (dup_size) é o número de cópias sintéticas *além* das originais.\n# Então, para ir de 43 para 1450, precisamos de aproximadamente 1400 novas amostras, o que é 33x o original.\n# Se target='1' tem 43 amostras, e você quer 'dup_size=33', você terá 43 (originais) + 33*43 (sintéticas) = 1462 amostras '1'.\ndados_smote <- SMOTE(X = X_features, target = y_target, K = 5, dup_size = 33)\n\n# O resultado vem como uma lista, precisamos extrair o dataframe balanceado\ndados_smote_df <- dados_smote$data\n\n\n# Gerar o gráfico de barras\nggplot(dados_smote_df, aes(x = class, fill = class)) +\n  geom_bar() +\n  # Adicionar rótulos de contagem em cima das barras\n  geom_text(stat = 'count', aes(label = after_stat(count)), vjust = -0.5) +\n  labs(\n    title = \"Distribuição das classes após SMOTE\",\n    x = \"Classe\",\n    y = \"Contagem de Amostras\",\n    fill = \"Classe\"\n  ) +\n  scale_fill_manual(values = c(\"1\" = \"#FD800D\", \"0\" = \"#2077B5\")) + # Cores personalizadas\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5)) # Centraliza o título\n```\n\n::: {.cell-output-display}\n![](desbalanceamento_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n:::\n\n\n\n\n\n- **Undersampling (Subamostragem):** Em contraste com o oversampling, o undersampling visa reduzir o número de instâncias da classe majoritária para equilibrar as proporções. A forma mais simples é a subamostragem aleatória, onde instâncias da classe majoritária são removidas aleatoriamente até que o balanço desejado seja atingido. Embora possa ser eficaz, a principal desvantagem é a potencial perda de informações importantes contidas nas amostras descartadas da classe majoritária. Por isso, deve ser usado com cautela, especialmente em datasets menores.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Exemplo de Undersampling aleatório em R\n# Instale o pacote 'ROSE' se ainda não tiver:\n# install.packages(\"ROSE\")\nlibrary(ROSE)\n\n# Usando os mesmos 'dados' desbalanceados criados anteriormente\n# Aplicando Undersampling: o método \"under\" do ovun.balance tentará equilibrar as classes\n# reduzindo a majoritária para o mesmo número de exemplos da minoritária.\ndados_under <- ovun.sample(target ~ ., data = dados_treino, method = \"under\")$data\n\n# Gerar o gráfico de barras\nggplot(dados_under, aes(x = target, fill = target)) +\n  geom_bar() +\n  # Adicionar rótulos de contagem em cima das barras\n  geom_text(stat = 'count', aes(label = after_stat(count)), vjust = -0.5) +\n  labs(\n    title = \"Distribuição das classes após undersampling\",\n    x = \"Classe\",\n    y = \"Contagem de Amostras\",\n    fill = \"Classe\"\n  ) +\n  scale_fill_manual(values = c(\"1\" = \"#FD800D\", \"0\" = \"#2077B5\")) + # Cores personalizadas\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5)) # Centraliza o título\n```\n\n::: {.cell-output-display}\n![](desbalanceamento_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n- **Oversampling e undersampling combinados:** A combinação de oversampling e undersampling é frequentemente a estratégia mais eficaz, especialmente em casos de desbalanceamento severo. A ideia é aumentar a classe minoritária (com SMOTE, por exemplo) e, ao mesmo tempo, reduzir a classe majoritária, mas sem perder informações cruciais. Isso permite um controle mais fino sobre a proporção final das classes e pode resultar em modelos mais robustos.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Exemplo de Oversampling e Undersampling simultâneos com ROSE\n# Instale o pacote 'ROSE' se ainda não tiver:\n# install.packages(\"ROSE\")\nlibrary(ROSE)\n\n# Usando os mesmos 'dados' desbalanceados criados anteriormente\n# Aplicando reamostragem híbrida: tentando balancear as classes\n# 'method = \"both\"' usa uma combinação de oversampling e undersampling.\ndados_hibrido <- ovun.sample(target ~ ., data = dados_treino, method = \"both\")$data\n\n# Gerar o gráfico de barras\nggplot(dados_hibrido, aes(x = target, fill = target)) +\n  geom_bar() +\n  # Adicionar rótulos de contagem em cima das barras\n  geom_text(stat = 'count', aes(label = after_stat(count)), vjust = -0.5) +\n  labs(\n    title = \"Distribuição das classes após combinação de over e undersampling\",\n    x = \"Classe\",\n    y = \"Contagem de Amostras\",\n    fill = \"Classe\"\n  ) +\n  scale_fill_manual(values = c(\"1\" = \"#FD800D\", \"0\" = \"#2077B5\")) + # Cores personalizadas\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5)) # Centraliza o título\n```\n\n::: {.cell-output-display}\n![](desbalanceamento_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n### 2. Mudança no Algoritmo: Ajustes Intrínsecos para o Desbalanceamento\n\n\nAlguns algoritmos de aprendizado de máquina oferecem mecanismos internos ou parâmetros que podem ser ajustados para lidar com o desbalanceamento, sem a necessidade de reamostrar o conjunto de dados diretamente. Esses algoritmos permitem atribuir \"custos\" diferentes a erros de classificação. Por exemplo, em um problema de detecção de doenças raras, um falso negativo (não detectar a doença quando ela existe) pode ter um custo muito maior (ex: vida humana) do que um falso positivo (diagnosticar a doença quando ela não existe). Ao definir uma matriz de custos, o algoritmo será penalizado mais severamente por cometer erros na classe minoritária, incentivando-o a classificá-la corretamente.\n\n- Algoritmos de Cost-Sensitive Learning:\n    - Árvores de Decisão \n    - Máquinas de Vetor de Suporte \n    - Boosting Algorithms\n    - Redes Neurais Artificiais \n    - Regressão Logística\n\n#### Exemplo Prático: Random Forest com pesos de classe\n\nVamos primeiro treinar um modelo de `Random Forest` padrão para ver como ele se comporta sem nenhuma consideração de custo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(randomForest)\nlibrary(caret)\nlibrary(pROC)\n# Treinar o modelo Random Forest\n# ntree: número de árvores na floresta\n# importance: calcula a importância das variáveis (opcional, mas útil)\nmodelo_rf_base <- randomForest(target ~ ., data = dados_treino, ntree = 500, classwt = NULL, importance = TRUE)\n\n# Fazer previsões no conjunto de teste\n# type=\"prob\" para obter as probabilidades das classes\npredicoes_rf_base <- predict(modelo_rf_base, newdata = dados_teste, type = \"class\")\n\n# Avaliar o modelo\nmc_rf_base <- confusionMatrix(predicoes_rf_base, dados_teste$target, positive = \"1\")\nmc_rf_base\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 482  17\n         1   1   0\n                                          \n               Accuracy : 0.964           \n                 95% CI : (0.9437, 0.9785)\n    No Information Rate : 0.966           \n    P-Value [Acc > NIR] : 0.656554        \n                                          \n                  Kappa : -0.0038         \n                                          \n Mcnemar's Test P-Value : 0.000407        \n                                          \n            Sensitivity : 0.0000          \n            Specificity : 0.9979          \n         Pos Pred Value : 0.0000          \n         Neg Pred Value : 0.9659          \n             Prevalence : 0.0340          \n         Detection Rate : 0.0000          \n   Detection Prevalence : 0.0020          \n      Balanced Accuracy : 0.4990          \n                                          \n       'Positive' Class : 1               \n                                          \n```\n\n\n:::\n:::\n\n\nNote que temos uma acurácia geral alta, mas um `Recall (Sensitivity)` baixo para a classe \"p\" (minoritária), indicando que o modelo tem dificuldade em detectá-la. Agora, vamos treinar outro modelo `Random Forest`, mas desta vez, aplicando pesos de classe para dar mais importância à classe minoritária. \n\n\nNo nosso banco de dados de treinamento, \n\n\n::: {.cell}\n\n```{.r .cell-code}\nfreq_classes <- table(dados_treino$target)\nfreq_classes\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n   0    1 \n1457   43 \n```\n\n\n:::\n:::\n\n\na proporção é 1457 indivíduos na \"0\" e 43 na classe \"1\", a classe \"0\" tem aproximadamente 34 vezes mais amostras. Para dar mais peso à classe \"1\", poderíamos usar:\n\n\n`Pesos 0 = 1`\n\n`Pesos 1 = (Número de amostras '0') / (Número de amostras '1')`\n\nOu, mais genericamente, a frequência inversa:\n\n`Pesos 0 = 1 / Frequência de 0`\n\n`Pesos 1 = 1 / Frequência de 1`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Definir os pesos de classe\n# Dar um peso maior à classe '1' (minoritária)\n\npesos_classes <- 1 / freq_classes\npesos_classes <- pesos_classes / min(pesos_classes) # Normaliza para que o menor peso seja 1\n\n# Treinar o modelo Random Forest com pesos de classe\nmodelo_rf_custo <- randomForest(target ~ .,\n                                data = dados_treino,\n                                ntree = 500,\n                                classwt = pesos_classes, # AQUI aplicamos os pesos de classe!\n                                importance = TRUE)\n\n# Fazer previsões no conjunto de teste\npredicoes_rf_custo <- predict(modelo_rf_custo, newdata = dados_teste, type = \"class\")\n\n# Avaliar o modelo\nmc_rf_custo <- confusionMatrix(predicoes_rf_custo, dados_teste$target, positive = \"1\")\nmc_rf_custo\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 483  17\n         1   0   0\n                                          \n               Accuracy : 0.966           \n                 95% CI : (0.9461, 0.9801)\n    No Information Rate : 0.966           \n    P-Value [Acc > NIR] : 0.5640325       \n                                          \n                  Kappa : 0               \n                                          \n Mcnemar's Test P-Value : 0.0001042       \n                                          \n            Sensitivity : 0.000           \n            Specificity : 1.000           \n         Pos Pred Value :   NaN           \n         Neg Pred Value : 0.966           \n             Prevalence : 0.034           \n         Detection Rate : 0.000           \n   Detection Prevalence : 0.000           \n      Balanced Accuracy : 0.500           \n                                          \n       'Positive' Class : 1               \n                                          \n```\n\n\n:::\n:::\n\n\n\n### 3. Mudança nas métricas de avaliação\n\n\nComo discutido anteriormente, a `acurácia` é uma métrica extremamente enganosa em conjuntos de dados desbalanceados. É absolutamente essencial mudar o foco para métricas que forneçam uma imagem mais fiel do desempenho do seu modelo, especialmente na classe minoritária.\n\n - `Precisão (Precision)`: Responde à pergunta: \"Das vezes que meu modelo previu a classe positiva, quantas estavam realmente corretas?\".\n\n - `Recall (Sensibilidade/Revocação)`: Responde à pergunta: \"Das vezes que a classe positiva realmente ocorreu, quantas meu modelo conseguiu detectar?\". Para a classe minoritária, o `recall` é frequentemente a métrica mais crítica, pois indica a capacidade do modelo de \"encontrar\" as instâncias raras.\n\n - `F1-Score`: É a média harmônica da `Precisão` e do `Recall`. É uma métrica útil quando você precisa de um equilíbrio entre não ter muitos falsos positivos (`precisão`) e não perder muitos positivos reais (`recall`).\n\n- Curvas `ROC (Receiver Operating Characteristic)` e `PR (Precision-Recall)`:\n    - A `AUC-ROC` avalia a capacidade do modelo de distinguir entre as classes em diferentes limiares de decisão.\n    - A `AUC-PR` é frequentemente preferível à `AUC-ROC` para conjuntos de dados altamente desbalanceados. Ela se concentra especificamente na relação entre Precisão e Recall, que são métricas mais informativas sobre o desempenho da classe minoritária quando há um grande desequilíbrio. Uma alta `AUC-PR` indica um bom desempenho na identificação da classe positiva sem um excesso de falsos positivos.\n\n\n## Conclusão\n\nLidar com o desbalanceamento de classes é mais do que apenas uma tarefa técnica; é uma questão de garantir que seus modelos sejam úteis e confiáveis no mundo real, especialmente para os eventos raros, mas críticos. A chave é identificar o problema cedo (lembre-se: se a classe minoritária está abaixo de 40%, já é um alerta!), compreender suas consequências e aplicar as técnicas mais adequadas de reamostragem (incluindo a abordagem híbrida), ajuste de algoritmo ou avaliação de métricas.\n\nNão existe uma solução única que sirva para todos os casos. A escolha da melhor abordagem depende do seu conjunto de dados, do algoritmo que você está usando e, fundamentalmente, do objetivo de negócio. A experimentação e a validação cuidadosa são sempre os melhores caminhos!",
    "supporting": [
      "desbalanceamento_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}