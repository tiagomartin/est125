{
  "hash": "a086cd3a33204ba44391c97e1ce0202c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Desvendando o pacote tidymodels\"\nformat:\n  html:\n    toc: true\n    code-fold: false\n    code-summary: \"Mostrar código\"\n    embed-resources: true\nexecute: \n  eval: false   \n---\n\nHoje vamos desvendar um dos pacotes mais poderosos e versáteis no universo do R para quem trabalha com **Ciência de Dados**: o **`tidymodels`**. Se você já se aventurou em construir modelos preditivos, sabe que o processo pode ser um pouco… artesanal. O `tidymodels` chega para organizar essa bagunça e transformar a construção de modelos em algo mais intuitivo, padronizado e, claro, *tidy*!\n\n---\n\n## O que é o `tidymodels`?\n\nPense no `tidymodels` como uma **coleção de pacotes** que trabalham em conjunto para oferecer uma estrutura unificada e consistente para o *machine learning* em R. Assim como o `tidyverse` revolucionou a manipulação de dados, o `tidymodels` faz o mesmo para a modelagem. Ele segue a filosofia *tidy* do R, o que significa que as funções são projetadas para serem encadeadas, facilitando a leitura e a escrita do código.\n\nEle cobre todas as etapas do fluxo de trabalho de *machine learning*, desde a preparação dos dados até a avaliação do modelo, passando pela seleção de modelos e ajuste de hiperparâmetros.\n\n---\n\n## Por que usar o `tidymodels`?\n\n1.  **Consistência**: Esqueça a necessidade de aprender sintaxes diferentes para cada algoritmo. O `tidymodels` oferece uma interface unificada.\n2.  **Organização**: Ele incentiva a criação de um fluxo de trabalho claro e modular, o que facilita a replicação e a manutenção do seu código.\n3.  **Flexibilidade**: Embora padronizado, ele é incrivelmente flexível, permitindo que você experimente diferentes modelos e abordagens.\n4.  **Integração**: Nascido e criado no ecossistema *tidy*, ele se integra perfeitamente com pacotes como `dplyr` e `ggplot2`.\n\n---\n\n## Componentes Chave do `tidymodels`\n\nO `tidymodels` é composto por diversos pacotes que desempenham funções específicas. Os principais que você precisa conhecer são:\n\n* `rsample`: Para criar amostras de dados (treino/teste, validação cruzada).\n* `recipes`: Para pré-processamento de dados (transformações, engenharia de *features*).\n* `parsnip`: Para especificar e ajustar diferentes tipos de modelos (regressão linear, árvores, SVMs, etc.) com uma sintaxe consistente.\n* `tune`: Para ajuste de hiperparâmetros de modelos.\n* `workflows`: Para empacotar modelos e *recipes* em um único objeto.\n* `yardstick`: Para medir o desempenho do modelo com diversas métricas.\n* `dials`: Para gerenciar espaços de *tuning* de hiperparâmetros.\n\n---\n\n## Mãos na Massa: Um Exemplo Prático!\n\n\nO conjunto de dados da Ames Housing é um conjunto de dados bem conhecido no campo da aprendizagem de máquina e análise de dados. Ele contém vários recursos e atributos de casas residenciais em **Ames**, **Iowa**, **EUA**. O conjunto de dados é frequentemente usado para tarefas de regressão, principalmente para prever os preços da habitação.\n\n\nPrimeiro, vamos carregar os pacotes necessários:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Configurações para reprodutibilidade\nset.seed(123)\n```\n:::\n\n\n\n### 1. Preparação dos Dados com `rsample`\n\n\nO pacote rsample é o seu ponto de partida para a divisão estratégica dos seus dados. É fundamental para garantir que seu modelo seja avaliado de forma imparcial e que generalize bem para dados novos.\n\n\n### Por que usar?\n\n- **Separação Treino/Teste:** Essencial para avaliar a capacidade de generalização do modelo. O modelo é treinado apenas nos dados de treino e avaliado no conjunto de teste \"invisível\".\n- **Validação Cruzada (Cross-Validation):** Uma técnica mais robusta para estimar o desempenho do modelo e ajustar hiperparâmetros. Ajuda a reduzir a variância da estimativa de desempenho em comparação com uma única divisão treino/teste.\n- **Reamostragem (Bootstrapping):** Útil para estimar a incerteza das estimativas do modelo.\n\n\n### Como usar?\n\n`initial_split()`: Para dividir seus dados em conjuntos de treino e teste.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(ames)\n\n# Cria um conjunto de dados tibble para o tidymodels\names_tbl <- as_tibble(ames)\n\n# Divisão dos dados em treino e teste\nsplit_data <- initial_split(ames_tbl, prop = 0.80)\ntrain_data <- training(split_data)\ntest_data  <- testing(split_data)\n\n# Verificando as dimensões\ndim(train_data)\ndim(test_data)\n```\n:::\n\n\n`vfold_cv()`: Para criar conjuntos para validação cruzada.\n\n\n::: {.cell}\n\n```{.r .cell-code}\names_folds <- vfold_cv(train_data, v = 10, strata = Sale_Price) # 10-fold cross-validation\names_folds\n```\n:::\n\n\n\n### 2. Pré-processamento e Engenharia de Features com `recipes`\n\nO pacote `recipes` oferece uma sintaxe declarativa e encadeável para definir todas as etapas de pré-processamento e engenharia de features que você deseja aplicar aos seus dados.\n\n### Por que usar?\n\n- **Padronização e Consistência:** Garante que as mesmas transformações sejam aplicadas consistentemente nos conjuntos de treino, teste e novos dados.\n- **Evitar Vazamento de Dados (Data Leakage):** As operações de pré-processamento (como normalização) são \"treinadas\" apenas nos dados de treino e depois aplicadas aos dados de teste, evitando que informações do conjunto de teste influenciem o pré-processamento.\n- **Replicabilidade:** Facilita a reprodução de todas as etapas de preparação dos dados.\n- **Engenharia de Features:** Permite criar novas variáveis a partir das existentes (e.g., interações, polinômios).\n\n\n### Como usar?\n\n- `recipe(formula, data)`: Define a base da receita.\n\n- `step_*()`: Adiciona as etapas de pré-processamento.\n    - `step_normalize()`: Normaliza variáveis numéricas (média 0, desvio padrão 1).\n    - `step_dummy()`: Cria variáveis dummy (one-hot encoding) para variáveis categóricas.\n    - `step_impute_mean()` / `step_impute_knn()`: Lida com valores ausentes.\n    - `step_log()`: Aplica transformação logarítmica.\n    - `step_other()`: Agrupa níveis raros de fatores em uma categoria \"outros\".\n    - `step_interact()`: Cria interações entre variáveis.\n    - `step_zv()`: Remove variáveis com variância zero.\n\n- Mais `steps` do pacote `recipes` podem ser encontrados [aqui](https://www.tidymodels.org/find/recipes/).\n\n\n::: {.cell}\n\n```{.r .cell-code}\names_recipe <-\n  recipe(Sale_Price ~ ., data = ames) %>%\n  step_log(Sale_Price, base = 10) %>% # Transformar a variável resposta\n  step_other(Neighborhood, threshold = 0.05) %>% # Agrupar bairros raros\n  step_dummy(all_nominal_predictors()) %>% # Dummy para todas as variáveis categóricas\n  step_impute_knn(all_predictors()) %>% # Imputar valores ausentes com KNN\n  step_normalize(all_numeric_predictors()) %>%  # Normalizar variáveis numéricas\n  step_zv(all_predictors()) # Remover variáveis com variância zero\n  \n# Uma receita é uma \"planta\". Para aplicá-la, você precisa `prep()` e `bake()`.\n# `prep()` calcula as estatísticas necessárias para as transformações (e.g., média para normalização).\n# `bake()` aplica essas transformações aos dados.\nprepared_recipe <- prep(ames_recipe, training = ames)\nbaked_data <- bake(prepared_recipe, new_data = ames)\n```\n:::\n\n\n\n### 3. Especificação do Modelo com `parsnip`\n\n\nO pacote `parsnip` fornece uma interface consistente para especificar diferentes tipos de modelos de machine learning, independentemente do \"motor\" (o pacote R que realmente implementa o algoritmo) que você deseja usar.\n\n\n### Por que usar?\n\n- **Interface Unificada:** Você usa a mesma sintaxe para especificar uma regressão linear, uma árvore de decisão, um SVM, uma rede neural, etc.\n- **Flexibilidade de Motores:** Permite alternar facilmente entre diferentes implementações do mesmo algoritmo (e.g., glmnet ou keras para regressão logística).\n- **Separação de Preocupações:** Você define o tipo de modelo e seu modo (classificação/regressão) antes de se preocupar com os detalhes do fitting.\n\n\n### Como usar?\n\n- `model_type()`: Função para o tipo de modelo (e.g., `linear_reg()`, `rand_forest()`, `boost_tree()`, `svm_rbf()`).\n\n- `set_engine()`: Define qual pacote será usado para implementar o modelo (e.g., `\"lm\"`, `\"ranger\"`, `\"xgboost\"`, `\"kernlab\"`).\n\n- `set_mode()`: Define se é um problema de `\"regression\"` ou `\"classification\"`.\n\n- `set_args()`: Define hiperparâmetros que podem ser ajustados ou passados diretamente (e.g., `trees = 1000` para `rand_forest`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Regressão Linear\nlm_spec <- linear_reg() %>%\n  set_engine(\"lm\") %>%\n  set_mode(\"regression\")\n\n# Árvore de Decisão de Classificação\ntree_spec <- decision_tree(cost_complexity = tune()) %>% # `tune()` indica um hiperparâmetro para ajuste\n  set_engine(\"rpart\") %>%\n  set_mode(\"classification\")\n\n\n# Especificar Random Forest com mtry para ajuste\nrf_spec <- rand_forest(mtry = tune(), trees = 1000, min_n = tune()) %>%\n  set_engine(\"ranger\") %>%\n  set_mode(\"regression\")\n```\n:::\n\n\n\n### 4. `workflows`: Combinando `recipes` e `parsnip`\n\n\nO pacote `workflows` é a \"cola\" do `tidymodels`. Ele permite que você empacote uma *recipe* e uma especificação de modelo em um único objeto, tornando o processo de *fitting* e previsão mais eficiente e menos propenso a erros.\n\n### Por que usar?\n\n- **Consolidação:** Reúne todas as etapas de pré-processamento e o modelo em um único objeto coerente.\n- **Facilita o `fit()` e `predict()`:** Você treina e faz previsões no workflow como um todo, em vez de gerenciar a recipe e o modelo separadamente.\n- **Integridade:** Garante que o pré-processamento correto seja aplicado antes do treinamento e das previsões.\n\n\n### Como usar?\n\n- `workflow()`: Inicia o objeto de workflow.\n\n- `add_recipe()`: Adiciona a recipe criada.\n\n- `add_model()`: Adiciona a especificação do modelo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Usando a recipe e o modelo da sessão anterior\names_workflow <-\n  workflow() %>%\n  add_recipe(ames_recipe) %>%\n  add_model(rf_spec)\n\names_workflow # Visualize o workflow\n```\n:::\n\n\n\n### 5. Ajuste de Hiperparâmetros com `tune` (Opcional, mas Altamente Recomendado!)\n\n\nO pacote `tune` é o coração do `tidymodels` para encontrar os melhores hiperparâmetros para o seu modelo. Ele trabalha em conjunto com `rsample` para realizar o tuning de forma sistemática.\n\n### Por que usar?\n\n- **Otimização do Modelo:** Encontrar os hiperparâmetros ideais pode melhorar significativamente o desempenho do seu modelo.\n- **Metodologias Robustas:** Suporta *tuning* por grade (`tune_grid`) e tuning Bayesiano (`tune_bayes`), que são métodos eficientes para explorar o espaço de hiperparâmetros.\n- **Validação Cruzada Integrada:** O `tune` se integra perfeitamente com os *folds* de validação cruzada do `rsample` para avaliar o desempenho de cada combinação de hiperparâmetros de forma robusta.\n\n\n### Como usar?\n\n- Defina os hiperparâmetros a serem ajustados com `tune()` na especificação do modelo (`parsnip`).\n\n- `tune_grid()`: Realiza uma busca em grade (grid search) sobre um conjunto predefinido de hiperparâmetros.\n\n- `tune_bayes()`: Realiza uma busca Bayesiana, que é mais eficiente para espaços de hiperparâmetros grandes.\n\n- `collect_metrics()`: Coleta as métricas de desempenho para cada combinação de hiperparâmetros.\n\n- `select_best()` / `select_by_one_std_err()`: Ajuda a escolher o melhor conjunto de hiperparâmetros.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Realizar o ajuste de hiperparâmetros\ntune_results <-\n  ames_workflow %>%\n  tune_grid(\n    resamples = ames_folds,\n    grid = 10 # Tentar 10 combinações aleatórias de mtry e min_n\n  )\n\n# Analisar os resultados do tuning\ntune_results %>% collect_metrics()\ntune_results %>% show_best(metric =\"rmse\")\n\n# Selecionar o melhor modelo e finalizar o workflow\nbest_params <- tune_results %>% select_best(metric =\"rmse\")\nfinal_workflow <- ames_workflow %>% finalize_workflow(best_params)\n```\n:::\n\n\n\n\n### 6. Treinamento Final do Modelo com `fit`\n\nApós todas as etapas de preparação e, opcionalmente, ajuste de hiperparâmetros, `fit()` é a função que treina o modelo final nos dados de treino completos (ou no conjunto de dados completo se você estiver fazendo um treinamento final antes da implantação).\n\n### Por que usar?\n\n- **Cria o Modelo Final:** É o passo onde o algoritmo de machine learning aprende os padrões dos dados.\n- **Integração com o Workflow:** Treina o `workflow` completo, garantindo que a recipe seja preparada e aplicada aos dados de treino antes do modelo ser ajustado.\n\n\n### Como usar?\n\n- `fit(workflow, data)`: Treina o workflow com os dados especificados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Usando o workflow finalizado do tuning (ou o workflow original se não houver tuning)\nfinal_model <- fit(final_workflow, data = train_data)\n```\n:::\n\n\n\n### 7. Fazendo Previsões com `predict`\n\n\nA função `predict()` é usada para gerar previsões em novos dados, sejam eles o conjunto de teste ou dados de produção.\n\n### Por que usar?\n\n- **Avaliação de Desempenho:** Previsões no conjunto de teste são cruciais para avaliar o quão bem o modelo generaliza.\n- **Aplicação em Produção:** Uma vez que o modelo é implantado, `predict()` é usado para gerar novas previsões.\n\n\n### Como usar?\n\n-`predict(trained_model, new_data)`: Gera previsões para um novo conjunto de dados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredictions <- predict(final_model, new_data = test_data) %>%\n  bind_cols(test_data) # Juntando com os valores reais para avaliação\n```\n:::\n\n\n\n### 8. Avaliação de Desempenho com `yardstick`\n\nO pacote `yardstick` fornece uma ampla gama de métricas para avaliar o desempenho do seu modelo, tanto para problemas de regressão quanto de classificação.\n\n### Por que usar?\n\n- **Métricas Abrangentes:** Oferece métricas padrão e avançadas (e.g., RMSE, R-quadrado, AUC, acurácia, precisão, recall, F1-score).\n- **Consistência:** As funções de métricas têm uma interface consistente.\n- **Pronto para `dplyr`:** As funções `metric_set()` e `metrics()` se integram bem com o `tidyverse`.\n\n\n### Como usar?\n\n- `metric_set()`: Cria um conjunto de métricas para avaliação.\n\n- `metrics(data, truth, estimate)`: Calcula as métricas para um conjunto de dados.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Para regressão\npredictions %>%\n  metrics(truth = Sale_Price, estimate = .pred)\n\n# Para classificação \n# classification_metrics <- metric_set(accuracy, roc_auc, sens, spec)\n# predictions_class %>% classification_metrics(truth = actual_class, estimate = .pred_class, .pred_positive_prob)\n```\n:::\n\n\n\n\n\n### Conclusão\n\nEntender cada uma dessas etapas e o papel de cada pacote no `tidymodels` é a chave para construir fluxos de trabalho de *machine learning* eficientes, robustos e reproduzíveis em R. A beleza está na modularidade e na capacidade de encadear essas operações, transformando um processo complexo em algo sistemático e elegante.\n\nAo dominar essas etapas, você estará bem equipado para enfrentar uma variedade de desafios de modelagem de dados!\n\n",
    "supporting": [
      "tidymodels_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}